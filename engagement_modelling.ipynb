{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e42fc71",
   "metadata": {},
   "source": [
    "# Modlling for engagement \n",
    "\n",
    "now we have the features and the lables, we are ready for modelling \n",
    "- Classification vs regression\n",
    "- 9 vs 5 vs 3 scales lables \n",
    "- 2.5 vs 5 s window (as is features, average featuers and concatenate features)\n",
    "- Two-stream Fusion on RGB + Flow \n",
    "\n",
    "This should be done over:\n",
    "- different network artchictures\n",
    "- cross different familys cross-validation \n",
    "\n",
    "Later on:\n",
    "- Handcrafted features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243c294",
   "metadata": {},
   "source": [
    "### imports and vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dacd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler as resample\n",
    "\n",
    "lables_path = './labels/'\n",
    "features_path = './features/'\n",
    "results_path = './modelling_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2f46d",
   "metadata": {},
   "source": [
    "### Keras modeling class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cebbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 03:03:00.691559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-27 03:03:00.702440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sharifa/catkin_ws/devel/lib:/usr/local/cuda-11.0/lib64\n",
      "2021-10-27 03:03:00.704080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sharifa/catkin_ws/devel/lib:/usr/local/cuda-11.0/lib64\n",
      "2021-10-27 03:03:00.704114: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-27 03:03:00.705065: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "from hpbandster.core.worker import Worker\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.BinaryCrossentropy(name='BinaryCrossentropy')\n",
    "]\n",
    "\n",
    "class KerasWorker(Worker):\n",
    "    def __init__(self, input_shape, output_shape, problemType,\n",
    "                 x_train, y_train, x_validation, y_validation,\n",
    "                 x_test, y_test, shared_directory, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.input_shape = (input_shape, )\n",
    "            self.num_classes = output_shape\n",
    "            self.batch_size = 64\n",
    "            self.save_dic = shared_directory\n",
    "            \n",
    "            self.problemType = problemType\n",
    "\n",
    "            self.x_train, self.y_train = x_train, y_train\n",
    "            self.x_validation, self.y_validation = x_validation, y_validation\n",
    "            self.x_test, self.y_test = x_test, y_test\n",
    "\n",
    "    def compute(self, config, budget, working_directory, *args, **kwargs):\n",
    "            model = Sequential()\n",
    "            model.add(Dense(units=config['start_neurons_units'],\n",
    "                            # activation=config['start_neurons_activation'],\n",
    "                            activation='relu',\n",
    "                            input_shape=self.input_shape))\n",
    "\n",
    "\n",
    "            if config['num_dense_layers'] > 1:\n",
    "                model.add(Dense(units=config['dense1_units'],\n",
    "                                # activation=config['dense1_activation'],\n",
    "                                activation='relu',\n",
    "                                input_shape=self.input_shape))\n",
    "                model.add(Dropout(config['dropout1_rate']))\n",
    "\n",
    "            if config['num_dense_layers'] > 2:\n",
    "                model.add(Dense(units=config['dense2_units'],\n",
    "                                # activation=config['dense2_activation'],\n",
    "                                activation='relu',\n",
    "                                input_shape=self.input_shape))\n",
    "                model.add(Dropout(config['dropout2_rate']))\n",
    "\n",
    "            model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "            if config['optimizer'] == 'Adam':\n",
    "                    optimizer = tf.keras.optimizers.Adam(lr=config['lr'])\n",
    "            else:\n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=config['lr'], momentum=config['sgd_momentum'])\n",
    "            \n",
    "            if self.problemType == 'classification':\n",
    "                loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "                the_metrics = METRICS.append(tfa.metrics.MatthewsCorrelationCoefficient(num_classes=self.num_classes))\n",
    "                the_columns = ['loss','tp','fp','tn','fn','acc','prec','rec','auc','BC','MCC']\n",
    "                #val_metric = 'accuracy'\n",
    "                val_metric = 'val_loss'\n",
    "            else:\n",
    "                loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "                the_metrics=['mean_squared_error', 'mean_absolute_error', \n",
    "                             'mean_absolute_percentage_error', 'cosine_proximity',\n",
    "                            'mean_squared_logarithmic_error']\n",
    "                the_columns = the_metrics\n",
    "                val_metric = 'mean_squared_error'\n",
    "                \n",
    "            model.compile(\n",
    "                loss=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                metrics=the_metrics\n",
    "            )\n",
    "\n",
    "            # model.summary()\n",
    "            _history = model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=int(budget),\n",
    "                              verbose=0,\n",
    "                              validation_data=(self.x_validation, self.y_validation))\n",
    "\n",
    "            print(_history.history.keys())\n",
    "            val_acc_per_epoch = _history.history[val_metric]\n",
    "            best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1 \\\n",
    "                         if self.problemType == 'classification' \\\n",
    "                         else val_acc_per_epoch.index(min(val_acc_per_epoch)) + 1\n",
    "            print('Best epoch: %d' % (best_epoch,))\n",
    "\n",
    "            model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=best_epoch,\n",
    "                              verbose=0,\n",
    "                              validation_data=(self.x_validation, self.y_validation))\n",
    "\n",
    "            train_score = model.evaluate(self.x_train, self.y_train, verbose=0)\n",
    "            val_score = model.evaluate(self.x_validation, self.y_validation, verbose=0)\n",
    "            test_score = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "\n",
    "            resultsDF = pd.DataFrame([train_score,val_score,test_score],\n",
    "                                     columns=the_metrics,\n",
    "                                     index=[\"train_score\", \"val_score\", \"test_score\"],)\n",
    "            # print(resultsDF)\n",
    "            test_predictions_baseline = model.predict(self.x_test)\n",
    "            np.savetxt(os.path.join(self.save_dic,'testing_finalResults_true.out'), self.y_test, delimiter=',')\n",
    "            np.savetxt(os.path.join(self.save_dic,'testing_finalResults_pred.out'), test_predictions_baseline, delimiter=',')\n",
    "\n",
    "            return ({\n",
    "                'loss': test_score,  \n",
    "                'info':  resultsDF.to_dict('index')\n",
    "            })\n",
    "\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "            \"\"\"\n",
    "            It builds the configuration space with the needed hyperparameters.\n",
    "            It is easily possible to implement different types of hyperparameters.\n",
    "            Beside float-hyperparameters on a log scale, it is also able to handle categorical input parameter.\n",
    "            :return: ConfigurationsSpace-Object\n",
    "            \"\"\"\n",
    "            cs = CS.ConfigurationSpace()\n",
    "\n",
    "            lr = CSH.UniformFloatHyperparameter('lr', lower=1e-6, upper=1e-1, default_value='1e-2', log=True)\n",
    "\n",
    "            # For demonstration purposes, we add different optimizers as categorical hyperparameters.\n",
    "            # To show how to use conditional hyperparameters with ConfigSpace, we'll add the optimizers 'Adam' and 'SGD'.\n",
    "            # SGD has a different parameter 'momentum'.\n",
    "            optimizer = CSH.CategoricalHyperparameter('optimizer', ['Adam', 'SGD'])\n",
    "\n",
    "            sgd_momentum = CSH.UniformFloatHyperparameter('sgd_momentum', lower=0.0, upper=0.99, default_value=0.9, log=False)\n",
    "\n",
    "            cs.add_hyperparameters([lr, optimizer, sgd_momentum])\n",
    "\n",
    "\n",
    "\n",
    "            num_dense_layers =  CSH.UniformIntegerHyperparameter('num_dense_layers', lower=1, upper=3, default_value=2)\n",
    "\n",
    "            start_neurons_units = CSH.UniformIntegerHyperparameter('start_neurons_units', lower=32, upper=512, default_value=32, log=True)\n",
    "            dense1_units = CSH.UniformIntegerHyperparameter('dense1_units', lower=8, upper=128, default_value=16, log=True)\n",
    "            dense2_units = CSH.UniformIntegerHyperparameter('dense2_units', lower=4, upper=64, default_value=8, log=True)\n",
    "\n",
    "            cs.add_hyperparameters([num_dense_layers, start_neurons_units, dense1_units, dense2_units])\n",
    "\n",
    "            # start_neurons_activation = CSH.CategoricalHyperparameter('start_neurons_activation', ['relu', 'tanh', 'sigmoid'])\n",
    "            # dense1_activation = CSH.CategoricalHyperparameter('dense1_activation', ['relu', 'tanh', 'sigmoid'])\n",
    "            # dense2_activation = CSH.CategoricalHyperparameter('dense2_activation', ['relu', 'tanh', 'sigmoid'])\n",
    "            # start_neurons_activation = CSH.CategoricalHyperparameter('start_neurons_activation', ['relu'])\n",
    "            # dense1_activation = CSH.CategoricalHyperparameter('dense1_activation', ['relu'])\n",
    "            # dense2_activation = CSH.CategoricalHyperparameter('dense2_activation', ['relu'])\n",
    "            #\n",
    "            # cs.add_hyperparameters([start_neurons_activation, dense1_activation, dense2_activation])\n",
    "\n",
    "            dropout1_rate = CSH.UniformFloatHyperparameter('dropout1_rate', lower=0.0, upper=0.9, default_value=0.5, log=False)\n",
    "            dropout2_rate = CSH.UniformFloatHyperparameter('dropout2_rate', lower=0.0, upper=0.9, default_value=0.5, log=False)\n",
    "\n",
    "            cs.add_hyperparameters([dropout1_rate, dropout2_rate])\n",
    "\n",
    "\n",
    "            # The hyperparameter sgd_momentum will be used,if the configuration\n",
    "            # contains 'SGD' as optimizer.\n",
    "            cond = CS.EqualsCondition(sgd_momentum, optimizer, 'SGD')\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            # You can also use inequality conditions:\n",
    "            cond = CS.GreaterThanCondition(dense1_units, num_dense_layers, 1)\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            cond = CS.GreaterThanCondition(dense2_units, num_dense_layers, 2)\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            return cs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83f4f9",
   "metadata": {},
   "source": [
    "### help functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1b61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub_dataset_twostream(familiesSet, label_folder, feature_folder):\n",
    "    # append all rows of subjects, and their lables\n",
    "    allFrames = np.array([])\n",
    "    allLables = np.array([])\n",
    "    \n",
    "    rgb_feature_folder = feature_folder.replace(featureType,'rgb')\n",
    "    flow_feature_folder = feature_folder.replace(featureType,'flow')\n",
    "    for this_family in familiesSet:\n",
    "        onlyfiles = [f for f in os.listdir(rgb_feature_folder) if\n",
    "                       os.path.isfile(os.path.join(rgb_feature_folder, f))\n",
    "                       and f.startswith(this_family + '_')]\n",
    "        onlyfiles.sort()\n",
    "\n",
    "        for this_file in onlyfiles:\n",
    "            this_lable_file = this_file.replace('_'+this_file.split('_')[4],'')+'.npy'\n",
    "            currLabel = np.load(os.path.join(label_folder,this_lable_file))\n",
    "            \n",
    "            rgb_currData = np.load(os.path.join(rgb_feature_folder,this_file))    \n",
    "            flow_currData = np.load(os.path.join(flow_feature_folder,this_file.replace('rgb','flow')))\n",
    "            \n",
    "            currData = np.hstack((rgb_currData, flow_currData))\n",
    "            \n",
    "            if allFrames.shape[0] ==0:\n",
    "                allFrames = currData\n",
    "                allLables = currLabel\n",
    "            else:\n",
    "                allFrames = np.vstack((allFrames, currData))\n",
    "                allLables = np.hstack((allLables, currLabel))\n",
    "\n",
    "    return allFrames, allLables\n",
    "\n",
    "def load_sub_dataset(familiesSet, label_folder, feature_folder, featureType):\n",
    "    # append all rows of subjects, and their lables\n",
    "    allFrames = np.array([])\n",
    "    allLables = np.array([])\n",
    "    \n",
    "    if featureType == 'twostream':\n",
    "        return load_sub_dataset_twostream(familiesSet, label_folder, feature_folder)\n",
    "    \n",
    "    for this_family in familiesSet:\n",
    "        # F10_Interaction_1_P27_rgb.npy\n",
    "        onlyfiles = [f for f in os.listdir(feature_folder) if\n",
    "                       os.path.isfile(os.path.join(feature_folder, f))\n",
    "                       and f.startswith(this_family + '_')]\n",
    "        onlyfiles.sort()\n",
    "\n",
    "        for this_file in onlyfiles:\n",
    "            currData = np.load(os.path.join(feature_folder,this_file))\n",
    "            this_lable_file = this_file.replace('_'+this_file.split('_')[4],'')+'.npy'\n",
    "            currLabel = np.load(os.path.join(label_folder,this_lable_file))\n",
    "            \n",
    "            if allFrames.shape[0] ==0:\n",
    "                allFrames = currData\n",
    "                allLables = currLabel\n",
    "            else:\n",
    "                allFrames = np.vstack((allFrames, currData))\n",
    "                allLables = np.hstack((allLables, currLabel))\n",
    "\n",
    "    return allFrames, allLables\n",
    "\n",
    "def load_dataset_selectedSubj(trainSubjs, valSubjs, testSubjs, label_folder, feature_folder,\\\n",
    "                              prblemType, featureType, num_classes):\n",
    "    #simple sampeling method\n",
    "    #TODO: SMOTE, DeepSMOTE, DeepFake?\n",
    "    sm = resample()\n",
    "    # load all train\n",
    "    trainX, trainy = load_sub_dataset(trainSubjs, label_folder, feature_folder, featureType)\n",
    "    trainX, trainy = shuffle(trainX, trainy)\n",
    "    trainX, trainy = sm.fit_resample(trainX, trainy)\n",
    "    print(trainX.shape, Counter(trainy))\n",
    "    # train_class_weight = sumary_data(trainy)\n",
    "\n",
    "    # load validation\n",
    "    valX, valy = load_sub_dataset(valSubjs, label_folder, feature_folder, featureType)\n",
    "    valX, valy = shuffle(valX, valy)\n",
    "    valX, valy = sm.fit_resample(valX, valy)\n",
    "    print(valX.shape, Counter(valy))\n",
    "    # val_class_weight = sumary_data(valy)\n",
    "\n",
    "\n",
    "    # load all test\n",
    "    testX, testy = load_sub_dataset(testSubjs, label_folder, feature_folder, featureType)\n",
    "    testX, testy = sm.fit_resample(testX, testy)\n",
    "    print(testX.shape, Counter(testy))\n",
    "    # test_class_weight = sumary_data(testy)\n",
    "\n",
    "    # one hot encode y\n",
    "    if prblemType == 'classification':\n",
    "        trainy = tf.keras.utils.to_categorical(trainy,  num_classes=num_classes)\n",
    "        valy = tf.keras.utils.to_categorical(valy,  num_classes=num_classes)\n",
    "        testy = tf.keras.utils.to_categorical(testy,  num_classes=num_classes)\n",
    "    \n",
    "    return trainX, trainy, valX, valy , testX, testy, num_classes\n",
    "    \n",
    "def create_modlling(label_folder,feature_folder,result_folder, prblemType, featureType, num_classes):    \n",
    "    # repeat experiment\n",
    "    temp = {}\n",
    "    all_trainSubjs = [['F' + str(i) for i in [1, 2, 3, 4, 5, 6, 8]]]\n",
    "    all_valSubjs = [['F' + str(i) for i in [11, 17]]]\n",
    "    all_testSubjs = [['F' + str(i) for i in [7, 10, 13]]]\n",
    "    \n",
    "    min_budget = 9\n",
    "    max_budget = 243\n",
    "    n_iterations = 50\n",
    "    num_workers = 12\n",
    "\n",
    "    for r in range(len(all_trainSubjs)):\n",
    "        shared_directory = result_folder + '_'+ str(r) \n",
    "        if os.path.exists(shared_directory):\n",
    "            print(shared_directory,' already processed')\n",
    "            continue\n",
    "        \n",
    "        print(shared_directory,' under processing')\n",
    "        classType = os.path.basename(shared_directory)\n",
    "\n",
    "        host = hpns.nic_name_to_host('lo')\n",
    "        result_logger = hpres.json_result_logger(directory=shared_directory, overwrite=True)\n",
    "        NS = hpns.NameServer(run_id=classType, host=host, port=0, working_directory=shared_directory)\n",
    "        ns_host, ns_port = NS.start()\n",
    "    \n",
    "        # load data\n",
    "        trainSubjs = all_trainSubjs[r]\n",
    "        valSubjs = all_valSubjs[r]\n",
    "        testSubjs = all_testSubjs[r]\n",
    "        \n",
    "        trainX, trainy, valX, valy, testX, testy, num_classes = \\\n",
    "            load_dataset_selectedSubj(trainSubjs, valSubjs, testSubjs, \\\n",
    "                                      label_folder, feature_folder, prblemType, featureType, num_classes)\n",
    "        \n",
    "        \n",
    "        n_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], num_classes        \n",
    "        \n",
    "        workers = []\n",
    "        for i in range(num_workers):\n",
    "            worker = KerasWorker(n_features, n_outputs, prblemType, \\\n",
    "                                 trainX, trainy, valX, valy, testX, testy, \\\n",
    "                                 shared_directory,\n",
    "                                 run_id=classType,host=host, nameserver=ns_host, nameserver_port=ns_port,\n",
    "                                 id=i)\n",
    "            worker.run(background=True)\n",
    "            workers.append(worker)\n",
    "\n",
    "        bohb = BOHB(configspace=worker.get_configspace(),\n",
    "                  run_id=classType,\n",
    "                  host=host,\n",
    "                  nameserver=ns_host,\n",
    "                  nameserver_port=ns_port,\n",
    "                  result_logger=result_logger,\n",
    "                  min_budget=min_budget, max_budget=max_budget\n",
    "                    )\n",
    "        res = bohb.run(n_iterations=1,  min_n_workers=num_workers)\n",
    "\n",
    "        id2config = res.get_id2config_mapping()\n",
    "        incumbent = res.get_incumbent_id()\n",
    "\n",
    "        print('Best found configuration:', id2config[incumbent]['config'])\n",
    "        # print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "        # print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "        # print('Total budget corresponds to %.1f full function evaluations.' % (\n",
    "        #             sum([r.budget for r in res.get_all_runs()]) / max_budget))\n",
    "\n",
    "        # store results\n",
    "        with open(os.path.join(shared_directory, 'results.pkl'), 'wb') as fh:\n",
    "            pickle.dump(res, fh)\n",
    "\n",
    "        # shutdown\n",
    "        bohb.shutdown(shutdown_workers=True)\n",
    "        NS.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b9729",
   "metadata": {},
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9e58a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "Working on:  classification rgb 9 2.5 none\n",
      "./modelling_results/rgb_classification_9_2.5_none_0  already processed\n",
      "Working on:  classification rgb 9 5 conc\n",
      "./modelling_results/rgb_classification_9_5_conc_0  under processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146e8be0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146e83d0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146e8910; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146e7b50; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146efe80; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 wait_for_workers trying to get the condition\n",
      "03:03:01 DISPATCHER: started the 'discover_worker' thread\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146ef9a0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146fd6a0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146fdbb0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146ea520; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e146919a0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e14691040; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4e14691d90; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36197>\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 DISPATCHER: started the 'job_runner' thread\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 DISPATCHER: Pyro daemon running on 127.0.0.1:44579\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 WORKER: start listening for jobs\n",
      "03:03:01 DISPATCHER: Starting worker discovery\n",
      "03:03:01 DISPATCHER: Found 11 potential workers, 0 currently in the pool.\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32410, 2048) Counter({2.0: 4630, 4.0: 4630, 3.0: 4630, 0.0: 4630, -1.0: 4630, 1.0: 4630, -2.0: 4630})\n",
      "(7875, 2048) Counter({2.0: 1125, -1.0: 1125, 0.0: 1125, 3.0: 1125, -2.0: 1125, 1.0: 1125, 4.0: 1125})\n",
      "(4790, 2048) Counter({0.0: 958, 1.0: 958, 2.0: 958, 3.0: 958, 4.0: 958})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "03:03:01 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:03:02 HBMASTER: number of workers changed to 11\n",
      "03:03:02 HBMASTER: only 11 worker(s) available, waiting for at least 12.\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:03:02 adjust_queue_size: lock accquired\n",
      "03:03:02 HBMASTER: adjusted queue size to (10, 11)\n",
      "03:03:02 DISPATCHER: Finished worker discovery\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 DISPATCHER: A new worker triggered discover_worker\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:03:02 HBMASTER: only 11 worker(s) available, waiting for at least 12.\n",
      "03:03:02 DISPATCHER: Starting worker discovery\n",
      "03:03:02 DISPATCHER: Found 12 potential workers, 11 currently in the pool.\n",
      "03:03:02 DISPATCHER: discovered new worker, hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:03:02 HBMASTER: number of workers changed to 12\n",
      "03:03:02 adjust_queue_size: lock accquired\n",
      "03:03:02 HBMASTER: adjusted queue size to (11, 12)\n",
      "03:03:02 DISPATCHER: Finished worker discovery\n",
      "03:03:02 DISPATCHER: A new worker triggered discover_worker\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 12 -> waiting!\n",
      "03:03:02 Enough workers to start this run!\n",
      "03:03:02 DISPATCHER: Starting worker discovery\n",
      "03:03:02 HBMASTER: starting run at 1635318182.0676858\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "03:03:02 DISPATCHER: Finished worker discovery\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n",
      "03:03:02 WORKER: start processing job (0, 0, 0)\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:03:02 WORKER: args: ()\n",
      "03:03:02 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "03:03:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.8511547904270457, 'dropout2_rate': 0.47959250611337995, 'lr': 3.6396972042835516e-06, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 310, 'dense1_units': 9, 'sgd_momentum': 0.9541767163975498}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 WORKER: start processing job (0, 0, 1)\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 10 -> waiting!\n",
      "03:03:02 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "03:03:02 WORKER: args: ()\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "03:03:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.629956392741512, 'dropout2_rate': 0.5764094335358415, 'lr': 2.9669292244281816e-06, 'num_dense_layers': 3, 'optimizer': 'SGD', 'start_neurons_units': 131, 'dense1_units': 22, 'dense2_units': 38, 'sgd_momentum': 0.1329328717949083}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "/home/sharifa/engagement_modeling/eng_env/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:03:02 WORKER: start processing job (0, 0, 2)\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 9 -> waiting!\n",
      "03:03:02 WORKER: args: ()\n",
      "03:03:02 HBMASTER: trying submitting job (0, 0, 3) to dispatcher\n",
      "03:03:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.14771813360964037, 'dropout2_rate': 0.7362432574402716, 'lr': 0.0003805934843190477, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 140, 'dense1_units': 65, 'sgd_momentum': 0.8624740407267049}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 3) to dispatcher\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 3)\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 3) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 8 -> waiting!\n",
      "03:03:02 HBMASTER: trying submitting job (0, 0, 4) to dispatcher\n",
      "03:03:02 WORKER: start processing job (0, 0, 3)\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 4) to dispatcher\n",
      "03:03:02 WORKER: args: ()\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 4)\n",
      "03:03:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.06518279991428408, 'dropout2_rate': 0.18274240253539345, 'lr': 2.534769878848808e-06, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 254, 'sgd_momentum': 0.1803727699145558}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 4) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 WORKER: start processing job (0, 0, 4)\n",
      "03:03:02 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:03:02 WORKER: args: ()\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 7 -> waiting!\n",
      "03:03:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.8504328504994124, 'dropout2_rate': 0.7954865284921956, 'lr': 0.003939891333182719, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 152, 'sgd_momentum': 0.7525563986580538}, 'budget': 9.0, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:02 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "03:03:02 done sampling a new configuration.\n",
      "03:03:02 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "2021-10-27 03:03:02.798426: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "03:03:02 WORKER: start processing job (0, 0, 5)\n",
      "03:03:02 HBMASTER: schedule new run for iteration 0\n",
      "03:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 6 -> waiting!\n",
      "03:03:02 WORKER: args: ()\n",
      "03:03:02 HBMASTER: trying submitting job (0, 0, 6) to dispatcher\n",
      "03:03:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.8246339575153093, 'dropout2_rate': 0.871763439121914, 'lr': 9.179744630693924e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 259}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:02 HBMASTER: submitting job (0, 0, 6) to dispatcher\n",
      "03:03:02 DISPATCHER: trying to submit job (0, 0, 6)\n",
      "03:03:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:02 HBMASTER: job (0, 0, 6) submitted to dispatcher\n",
      "03:03:02 DISPATCHER: Trying to submit another job.\n",
      "03:03:02 start sampling a new configuration.\n",
      "03:03:02 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:03:03 done sampling a new configuration.\n",
      "03:03:03 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:03:03 WORKER: start processing job (0, 0, 6)\n",
      "03:03:03 HBMASTER: schedule new run for iteration 0\n",
      "03:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 5 -> waiting!\n",
      "03:03:03 WORKER: args: ()\n",
      "03:03:03 HBMASTER: trying submitting job (0, 0, 7) to dispatcher\n",
      "03:03:03 WORKER: kwargs: {'config': {'dropout1_rate': 0.03523877787664873, 'dropout2_rate': 0.7779206855959242, 'lr': 1.4269196589991194e-05, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 127, 'dense1_units': 88, 'dense2_units': 4}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:03 HBMASTER: submitting job (0, 0, 7) to dispatcher\n",
      "03:03:03 DISPATCHER: trying to submit job (0, 0, 7)\n",
      "03:03:03 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:03 HBMASTER: job (0, 0, 7) submitted to dispatcher\n",
      "03:03:03 DISPATCHER: Trying to submit another job.\n",
      "03:03:03 start sampling a new configuration.\n",
      "03:03:03 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:03:03 done sampling a new configuration.\n",
      "/home/sharifa/engagement_modeling/eng_env/lib/python3.8/site-packages/keras/backend.py:4846: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n",
      "03:03:03 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:03:03 WORKER: start processing job (0, 0, 7)\n",
      "03:03:03 HBMASTER: schedule new run for iteration 0\n",
      "03:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 4 -> waiting!\n",
      "03:03:03 WORKER: args: ()\n",
      "03:03:03 HBMASTER: trying submitting job (0, 0, 8) to dispatcher\n",
      "03:03:03 WORKER: kwargs: {'config': {'dropout1_rate': 0.6677922289496803, 'dropout2_rate': 0.43708431541834775, 'lr': 2.197418221837256e-06, 'num_dense_layers': 3, 'optimizer': 'SGD', 'start_neurons_units': 33, 'dense1_units': 14, 'dense2_units': 6, 'sgd_momentum': 0.05223228276533275}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:03 HBMASTER: submitting job (0, 0, 8) to dispatcher\n",
      "03:03:03 DISPATCHER: trying to submit job (0, 0, 8)\n",
      "03:03:03 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:03 HBMASTER: job (0, 0, 8) submitted to dispatcher\n",
      "03:03:03 DISPATCHER: Trying to submit another job.\n",
      "03:03:03 start sampling a new configuration.\n",
      "03:03:03 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:03:03 done sampling a new configuration.\n",
      "03:03:03 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:03:03 WORKER: start processing job (0, 0, 8)\n",
      "03:03:03 HBMASTER: schedule new run for iteration 0\n",
      "03:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 3 -> waiting!\n",
      "03:03:03 WORKER: args: ()\n",
      "03:03:03 HBMASTER: trying submitting job (0, 0, 9) to dispatcher\n",
      "03:03:03 WORKER: kwargs: {'config': {'dropout1_rate': 0.24063248456691538, 'dropout2_rate': 0.28111314128296966, 'lr': 0.030664990274012982, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 66, 'sgd_momentum': 0.24326393886100112}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:03 HBMASTER: submitting job (0, 0, 9) to dispatcher\n",
      "03:03:03 DISPATCHER: trying to submit job (0, 0, 9)\n",
      "03:03:03 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:03 HBMASTER: job (0, 0, 9) submitted to dispatcher\n",
      "03:03:03 DISPATCHER: Trying to submit another job.\n",
      "03:03:03 start sampling a new configuration.\n",
      "03:03:03 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n",
      "03:03:03 done sampling a new configuration.\n",
      "03:03:03 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n",
      "03:03:03 WORKER: start processing job (0, 0, 9)\n",
      "03:03:03 HBMASTER: schedule new run for iteration 0\n",
      "03:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 2 -> waiting!\n",
      "03:03:03 WORKER: args: ()\n",
      "03:03:03 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "03:03:03 WORKER: kwargs: {'config': {'dropout1_rate': 0.6030828800944451, 'dropout2_rate': 0.0703249900223229, 'lr': 0.0010285025420046395, 'num_dense_layers': 2, 'optimizer': 'Adam', 'start_neurons_units': 197, 'dense1_units': 51}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:03 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "03:03:04 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "03:03:04 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:04 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "03:03:04 DISPATCHER: Trying to submit another job.\n",
      "03:03:04 start sampling a new configuration.\n",
      "03:03:04 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:03:04 done sampling a new configuration.\n",
      "03:03:04 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:03:04 WORKER: start processing job (0, 0, 10)\n",
      "03:03:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:03:04 HBMASTER: schedule new run for iteration 0\n",
      "03:03:04 WORKER: args: ()\n",
      "03:03:04 HBMASTER: trying submitting job (0, 0, 11) to dispatcher\n",
      "03:03:04 WORKER: kwargs: {'config': {'dropout1_rate': 0.8195178175748332, 'dropout2_rate': 0.42695679197067304, 'lr': 0.010248348545451586, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 105, 'dense1_units': 48, 'sgd_momentum': 0.3581326048964492}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:03:04 HBMASTER: submitting job (0, 0, 11) to dispatcher\n",
      "03:03:04 DISPATCHER: trying to submit job (0, 0, 11)\n",
      "03:03:04 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:03:04 HBMASTER: job (0, 0, 11) submitted to dispatcher\n",
      "03:03:04 DISPATCHER: Trying to submit another job.\n",
      "03:03:04 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:03:04 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:04 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:03:04 WORKER: start processing job (0, 0, 11)\n",
      "03:03:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:03:04 WORKER: args: ()\n",
      "03:03:04 WORKER: kwargs: {'config': {'dropout1_rate': 0.48984438405972436, 'dropout2_rate': 0.4502004269710746, 'lr': 5.563167418066458e-06, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 494, 'dense1_units': 18, 'sgd_momentum': 0.2097443115985959}, 'budget': 9.0, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:02 DISPATCHER: Starting worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:02 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:04:03 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 8\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:23 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "03:04:23 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "03:04:23 DISPATCHER: job (0, 0, 1) finished\n",
      "03:04:23 DISPATCHER: register_result: lock acquired\n",
      "03:04:23 DISPATCHER: job (0, 0, 1) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064 finished\n",
      "03:04:24 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'dropout1_rate': 0.629956392741512, 'dropout2_rate': 0.5764094335358415, 'lr': 2.9669292244281816e-06, 'num_dense_layers': 3, 'optimizer': 'SGD', 'start_neurons_units': 131, 'dense1_units': 22, 'dense2_units': 38, 'sgd_momentum': 0.1329328717949083}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.2400901317596436, 'info': {'train_score': {0: 2.2233974933624268}, 'val_score': {0: 2.228863477706909}, 'test_score': {0: 2.2400901317596436}}}\n",
      "exception: None\n",
      "\n",
      "03:04:24 job_callback for (0, 0, 1) started\n",
      "03:04:24 job_callback for (0, 0, 1) got condition\n",
      "03:04:24 DISPATCHER: Trying to submit another job.\n",
      "03:04:24 Only 1 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:24 HBMASTER: Trying to run another job!\n",
      "03:04:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:24 job_callback for (0, 0, 1) finished\n",
      "03:04:24 start sampling a new configuration.\n",
      "03:04:24 done sampling a new configuration.\n",
      "03:04:24 HBMASTER: schedule new run for iteration 0\n",
      "03:04:24 HBMASTER: trying submitting job (0, 0, 12) to dispatcher\n",
      "03:04:24 HBMASTER: submitting job (0, 0, 12) to dispatcher\n",
      "03:04:24 DISPATCHER: trying to submit job (0, 0, 12)\n",
      "03:04:24 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:24 HBMASTER: job (0, 0, 12) submitted to dispatcher\n",
      "03:04:24 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:24 DISPATCHER: Trying to submit another job.\n",
      "03:04:24 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:04:24 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:04:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:24 WORKER: start processing job (0, 0, 12)\n",
      "03:04:24 WORKER: args: ()\n",
      "03:04:24 WORKER: kwargs: {'config': {'dropout1_rate': 0.1718208214209649, 'dropout2_rate': 0.31895400296122667, 'lr': 0.0002090746530280218, 'num_dense_layers': 2, 'optimizer': 'Adam', 'start_neurons_units': 33, 'dense1_units': 22}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:04:26 WORKER: done with job (0, 0, 6), trying to register it.\n",
      "03:04:26 WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "03:04:26 DISPATCHER: job (0, 0, 6) finished\n",
      "03:04:26 DISPATCHER: register_result: lock acquired\n",
      "03:04:26 DISPATCHER: job (0, 0, 6) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064 finished\n",
      "03:04:26 job_id: (0, 0, 6)\n",
      "kwargs: {'config': {'dropout1_rate': 0.03523877787664873, 'dropout2_rate': 0.7779206855959242, 'lr': 1.4269196589991194e-05, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 127, 'dense1_units': 88, 'dense2_units': 4}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.137537956237793, 'info': {'train_score': {0: 1.9813966751098633}, 'val_score': {0: 2.1350769996643066}, 'test_score': {0: 2.137537956237793}}}\n",
      "exception: None\n",
      "\n",
      "03:04:27 job_callback for (0, 0, 6) started\n",
      "03:04:27 job_callback for (0, 0, 6) got condition\n",
      "03:04:27 DISPATCHER: Trying to submit another job.\n",
      "03:04:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:27 Only 2 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:27 HBMASTER: Trying to run another job!\n",
      "03:04:27 job_callback for (0, 0, 6) finished\n",
      "03:04:27 start sampling a new configuration.\n",
      "03:04:27 done sampling a new configuration.\n",
      "03:04:27 HBMASTER: schedule new run for iteration 0\n",
      "03:04:27 HBMASTER: trying submitting job (0, 0, 13) to dispatcher\n",
      "03:04:27 HBMASTER: submitting job (0, 0, 13) to dispatcher\n",
      "03:04:27 DISPATCHER: trying to submit job (0, 0, 13)\n",
      "03:04:27 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:27 HBMASTER: job (0, 0, 13) submitted to dispatcher\n",
      "03:04:27 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:27 DISPATCHER: Trying to submit another job.\n",
      "03:04:27 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:04:27 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:04:27 WORKER: start processing job (0, 0, 13)\n",
      "03:04:27 WORKER: args: ()\n",
      "03:04:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:27 WORKER: kwargs: {'config': {'dropout1_rate': 0.8470504741144611, 'dropout2_rate': 0.6235575138453934, 'lr': 0.0011028145452650958, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 175, 'sgd_momentum': 0.331482424701076}, 'budget': 9.0, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:31 WORKER: done with job (0, 0, 3), trying to register it.\n",
      "03:04:31 WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "03:04:31 DISPATCHER: job (0, 0, 3) finished\n",
      "03:04:31 DISPATCHER: register_result: lock acquired\n",
      "03:04:31 DISPATCHER: job (0, 0, 3) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064 finished\n",
      "03:04:31 job_id: (0, 0, 3)\n",
      "kwargs: {'config': {'dropout1_rate': 0.06518279991428408, 'dropout2_rate': 0.18274240253539345, 'lr': 2.534769878848808e-06, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 254, 'sgd_momentum': 0.1803727699145558}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.1567330360412598, 'info': {'train_score': {0: 2.176905870437622}, 'val_score': {0: 2.1472904682159424}, 'test_score': {0: 2.1567330360412598}}}\n",
      "exception: None\n",
      "\n",
      "03:04:31 job_callback for (0, 0, 3) started\n",
      "03:04:31 job_callback for (0, 0, 3) got condition\n",
      "03:04:31 DISPATCHER: Trying to submit another job.\n",
      "03:04:31 Only 3 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:31 HBMASTER: Trying to run another job!\n",
      "03:04:32 job_callback for (0, 0, 3) finished\n",
      "03:04:32 start sampling a new configuration.\n",
      "03:04:32 done sampling a new configuration.\n",
      "03:04:32 HBMASTER: schedule new run for iteration 0\n",
      "03:04:32 HBMASTER: trying submitting job (0, 0, 14) to dispatcher\n",
      "03:04:32 HBMASTER: submitting job (0, 0, 14) to dispatcher\n",
      "03:04:32 DISPATCHER: trying to submit job (0, 0, 14)\n",
      "03:04:32 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:32 HBMASTER: job (0, 0, 14) submitted to dispatcher\n",
      "03:04:32 DISPATCHER: Trying to submit another job.\n",
      "03:04:32 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:04:32 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:32 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:04:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:32 WORKER: start processing job (0, 0, 14)\n",
      "03:04:32 WORKER: args: ()\n",
      "03:04:32 WORKER: kwargs: {'config': {'dropout1_rate': 0.677073356730952, 'dropout2_rate': 0.583699508683521, 'lr': 0.01002492827889681, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 144, 'dense1_units': 8, 'sgd_momentum': 0.9557495175319882}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:04:37 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "03:04:37 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "03:04:37 DISPATCHER: job (0, 0, 0) finished\n",
      "03:04:37 DISPATCHER: register_result: lock acquired\n",
      "03:04:37 DISPATCHER: job (0, 0, 0) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064 finished\n",
      "03:04:37 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8511547904270457, 'dropout2_rate': 0.47959250611337995, 'lr': 3.6396972042835516e-06, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 310, 'dense1_units': 9, 'sgd_momentum': 0.9541767163975498}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.1644506454467773, 'info': {'train_score': {0: 2.1443426609039307}, 'val_score': {0: 2.169542074203491}, 'test_score': {0: 2.1644506454467773}}}\n",
      "exception: None\n",
      "\n",
      "03:04:37 job_callback for (0, 0, 0) started\n",
      "03:04:37 DISPATCHER: Trying to submit another job.\n",
      "03:04:37 job_callback for (0, 0, 0) got condition\n",
      "03:04:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:37 Only 4 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:37 HBMASTER: Trying to run another job!\n",
      "03:04:37 job_callback for (0, 0, 0) finished\n",
      "03:04:37 start sampling a new configuration.\n",
      "03:04:38 done sampling a new configuration.\n",
      "03:04:38 HBMASTER: schedule new run for iteration 0\n",
      "03:04:38 HBMASTER: trying submitting job (0, 0, 15) to dispatcher\n",
      "03:04:38 HBMASTER: submitting job (0, 0, 15) to dispatcher\n",
      "03:04:38 DISPATCHER: trying to submit job (0, 0, 15)\n",
      "03:04:38 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:38 HBMASTER: job (0, 0, 15) submitted to dispatcher\n",
      "03:04:38 DISPATCHER: Trying to submit another job.\n",
      "03:04:38 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n",
      "03:04:38 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:38 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n",
      "03:04:38 WORKER: start processing job (0, 0, 15)\n",
      "03:04:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:38 WORKER: args: ()\n",
      "03:04:38 WORKER: kwargs: {'config': {'dropout1_rate': 0.2658707926403801, 'dropout2_rate': 0.6694248038712984, 'lr': 6.8728806579344335e-06, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 418, 'dense1_units': 66, 'dense2_units': 24}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:04:38 WORKER: done with job (0, 0, 7), trying to register it.\n",
      "03:04:38 WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "03:04:38 DISPATCHER: job (0, 0, 7) finished\n",
      "03:04:38 DISPATCHER: register_result: lock acquired\n",
      "03:04:38 DISPATCHER: job (0, 0, 7) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064 finished\n",
      "03:04:38 job_id: (0, 0, 7)\n",
      "kwargs: {'config': {'dropout1_rate': 0.6677922289496803, 'dropout2_rate': 0.43708431541834775, 'lr': 2.197418221837256e-06, 'num_dense_layers': 3, 'optimizer': 'SGD', 'start_neurons_units': 33, 'dense1_units': 14, 'dense2_units': 6, 'sgd_momentum': 0.05223228276533275}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.1918554306030273, 'info': {'train_score': {0: 2.1801376342773438}, 'val_score': {0: 2.1771492958068848}, 'test_score': {0: 2.1918554306030273}}}\n",
      "exception: None\n",
      "\n",
      "03:04:38 job_callback for (0, 0, 7) started\n",
      "03:04:38 DISPATCHER: Trying to submit another job.\n",
      "03:04:38 job_callback for (0, 0, 7) got condition\n",
      "03:04:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:39 Only 5 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:39 HBMASTER: Trying to run another job!\n",
      "03:04:39 job_callback for (0, 0, 7) finished\n",
      "03:04:39 start sampling a new configuration.\n",
      "03:04:39 done sampling a new configuration.\n",
      "03:04:39 HBMASTER: schedule new run for iteration 0\n",
      "03:04:39 HBMASTER: trying submitting job (0, 0, 16) to dispatcher\n",
      "03:04:39 HBMASTER: submitting job (0, 0, 16) to dispatcher\n",
      "03:04:39 DISPATCHER: trying to submit job (0, 0, 16)\n",
      "03:04:39 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:39 HBMASTER: job (0, 0, 16) submitted to dispatcher\n",
      "03:04:39 DISPATCHER: Trying to submit another job.\n",
      "03:04:39 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:04:39 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:39 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:04:39 WORKER: start processing job (0, 0, 16)\n",
      "03:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:39 WORKER: args: ()\n",
      "03:04:39 WORKER: kwargs: {'config': {'dropout1_rate': 0.19373867663113675, 'dropout2_rate': 0.17747063361100654, 'lr': 0.0023522921483048686, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 164, 'dense1_units': 14, 'sgd_momentum': 0.5463312841632599}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:04:48 WORKER: done with job (0, 0, 11), trying to register it.\n",
      "03:04:48 WORKER: registered result for job (0, 0, 11) with dispatcher\n",
      "03:04:48 DISPATCHER: job (0, 0, 11) finished\n",
      "03:04:48 DISPATCHER: register_result: lock acquired\n",
      "03:04:48 DISPATCHER: job (0, 0, 11) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064 finished\n",
      "03:04:49 job_id: (0, 0, 11)\n",
      "kwargs: {'config': {'dropout1_rate': 0.48984438405972436, 'dropout2_rate': 0.4502004269710746, 'lr': 5.563167418066458e-06, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 494, 'dense1_units': 18, 'sgd_momentum': 0.2097443115985959}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.1950080394744873, 'info': {'train_score': {0: 2.1822376251220703}, 'val_score': {0: 2.197822093963623}, 'test_score': {0: 2.1950080394744873}}}\n",
      "exception: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:49 job_callback for (0, 0, 11) started\n",
      "03:04:49 DISPATCHER: Trying to submit another job.\n",
      "03:04:49 job_callback for (0, 0, 11) got condition\n",
      "03:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:49 Only 6 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:49 HBMASTER: Trying to run another job!\n",
      "03:04:49 job_callback for (0, 0, 11) finished\n",
      "03:04:49 start sampling a new configuration.\n",
      "03:04:49 done sampling a new configuration.\n",
      "03:04:49 HBMASTER: schedule new run for iteration 0\n",
      "03:04:49 HBMASTER: trying submitting job (0, 0, 17) to dispatcher\n",
      "03:04:49 HBMASTER: submitting job (0, 0, 17) to dispatcher\n",
      "03:04:49 DISPATCHER: trying to submit job (0, 0, 17)\n",
      "03:04:49 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:49 HBMASTER: job (0, 0, 17) submitted to dispatcher\n",
      "03:04:49 DISPATCHER: Trying to submit another job.\n",
      "03:04:49 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:49 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:04:49 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:04:49 WORKER: start processing job (0, 0, 17)\n",
      "03:04:49 WORKER: args: ()\n",
      "03:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:49 WORKER: kwargs: {'config': {'dropout1_rate': 0.47955964076404806, 'dropout2_rate': 0.21422353214408393, 'lr': 4.363499868999658e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 126, 'dense1_units': 78, 'sgd_momentum': 0.3784332014223267}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:04:50 WORKER: done with job (0, 0, 8), trying to register it.\n",
      "03:04:50 WORKER: registered result for job (0, 0, 8) with dispatcher\n",
      "03:04:50 DISPATCHER: job (0, 0, 8) finished\n",
      "03:04:50 DISPATCHER: register_result: lock acquired\n",
      "03:04:50 DISPATCHER: job (0, 0, 8) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064 finished\n",
      "03:04:50 job_id: (0, 0, 8)\n",
      "kwargs: {'config': {'dropout1_rate': 0.24063248456691538, 'dropout2_rate': 0.28111314128296966, 'lr': 0.030664990274012982, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 66, 'sgd_momentum': 0.24326393886100112}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 3.2132201194763184, 'info': {'train_score': {0: 0.3113260269165039}, 'val_score': {0: 4.701865196228027}, 'test_score': {0: 3.2132201194763184}}}\n",
      "exception: None\n",
      "\n",
      "03:04:50 job_callback for (0, 0, 8) started\n",
      "03:04:50 job_callback for (0, 0, 8) got condition\n",
      "03:04:50 DISPATCHER: Trying to submit another job.\n",
      "03:04:51 Only 7 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:04:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:04:51 HBMASTER: Trying to run another job!\n",
      "03:04:51 job_callback for (0, 0, 8) finished\n",
      "03:04:51 start sampling a new configuration.\n",
      "03:04:51 done sampling a new configuration.\n",
      "03:04:51 HBMASTER: schedule new run for iteration 0\n",
      "03:04:51 HBMASTER: trying submitting job (0, 0, 18) to dispatcher\n",
      "03:04:51 HBMASTER: submitting job (0, 0, 18) to dispatcher\n",
      "03:04:51 DISPATCHER: trying to submit job (0, 0, 18)\n",
      "03:04:51 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:04:51 HBMASTER: job (0, 0, 18) submitted to dispatcher\n",
      "03:04:51 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:04:51 DISPATCHER: Trying to submit another job.\n",
      "03:04:51 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:04:51 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:04:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:04:51 WORKER: start processing job (0, 0, 18)\n",
      "03:04:51 WORKER: args: ()\n",
      "03:04:51 WORKER: kwargs: {'config': {'dropout1_rate': 0.39298666907123103, 'dropout2_rate': 0.413969287882117, 'lr': 0.013797724343189554, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 37}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:05:01 WORKER: done with job (0, 0, 4), trying to register it.\n",
      "03:05:01 WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "03:05:01 DISPATCHER: job (0, 0, 4) finished\n",
      "03:05:01 DISPATCHER: register_result: lock acquired\n",
      "03:05:01 DISPATCHER: job (0, 0, 4) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064 finished\n",
      "03:05:01 job_id: (0, 0, 4)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8504328504994124, 'dropout2_rate': 0.7954865284921956, 'lr': 0.003939891333182719, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 152, 'sgd_momentum': 0.7525563986580538}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.359539031982422, 'info': {'train_score': {0: 0.5025227665901184}, 'val_score': {0: 3.656550168991089}, 'test_score': {0: 2.359539031982422}}}\n",
      "exception: None\n",
      "\n",
      "03:05:01 job_callback for (0, 0, 4) started\n",
      "03:05:01 DISPATCHER: Trying to submit another job.\n",
      "03:05:01 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "03:05:01 job_callback for (0, 0, 4) got condition\n",
      "03:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:05:02 Only 8 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:05:02 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "03:05:02 DISPATCHER: job (0, 0, 10) finished\n",
      "03:05:02 HBMASTER: Trying to run another job!\n",
      "03:05:02 job_callback for (0, 0, 4) finished\n",
      "03:05:02 DISPATCHER: register_result: lock acquired\n",
      "03:05:02 start sampling a new configuration.\n",
      "03:05:02 DISPATCHER: job (0, 0, 10) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064 finished\n",
      "03:05:02 done sampling a new configuration.\n",
      "03:05:02 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8195178175748332, 'dropout2_rate': 0.42695679197067304, 'lr': 0.010248348545451586, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 105, 'dense1_units': 48, 'sgd_momentum': 0.3581326048964492}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.780957818031311, 'info': {'train_score': {0: 0.7001145482063293}, 'val_score': {0: 3.2294723987579346}, 'test_score': {0: 1.780957818031311}}}\n",
      "exception: None\n",
      "\n",
      "03:05:02 HBMASTER: schedule new run for iteration 0\n",
      "03:05:02 job_callback for (0, 0, 10) started\n",
      "03:05:02 DISPATCHER: Trying to submit another job.\n",
      "03:05:02 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "03:05:02 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "03:05:02 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "03:05:02 DISPATCHER: jobs to submit = 0, number of idle workers = 2 -> waiting!\n",
      "03:05:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:05:02 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "03:05:02 DISPATCHER: Trying to submit another job.\n",
      "03:05:02 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:05:02 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:05:02 job_callback for (0, 0, 10) got condition\n",
      "03:05:02 Only 9 run(s) for budget 9.000000 available, need more than 11 -> can't build model!\n",
      "03:05:02 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:05:02 WORKER: start processing job (0, 0, 19)\n",
      "03:05:02 HBMASTER: Trying to run another job!\n",
      "03:05:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:05:02 WORKER: args: ()\n",
      "03:05:02 job_callback for (0, 0, 10) finished\n",
      "03:05:02 start sampling a new configuration.\n",
      "03:05:02 WORKER: kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:05:02 done sampling a new configuration.\n",
      "03:05:02 HBMASTER: schedule new run for iteration 0\n",
      "03:05:02 HBMASTER: trying submitting job (0, 0, 20) to dispatcher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:05:02 HBMASTER: submitting job (0, 0, 20) to dispatcher\n",
      "03:05:02 DISPATCHER: trying to submit job (0, 0, 20)\n",
      "03:05:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:05:02 HBMASTER: job (0, 0, 20) submitted to dispatcher\n",
      "03:05:02 DISPATCHER: Trying to submit another job.\n",
      "03:05:02 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:05:02 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:05:03 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:05:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:05:03 WORKER: start processing job (0, 0, 20)\n",
      "03:05:03 WORKER: args: ()\n",
      "03:05:03 DISPATCHER: Starting worker discovery\n",
      "03:05:03 WORKER: kwargs: {'config': {'dropout1_rate': 0.4299894822575599, 'dropout2_rate': 0.6953353649250353, 'lr': 0.09607535038915281, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 60, 'sgd_momentum': 0.5883115623139403}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:05:03 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:05:04 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "03:05:04 DISPATCHER: job (0, 0, 2) finished\n",
      "03:05:04 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "03:05:04 DISPATCHER: Finished worker discovery\n",
      "03:05:04 DISPATCHER: register_result: lock acquired\n",
      "03:05:04 DISPATCHER: job (0, 0, 2) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064 finished\n",
      "03:05:04 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'dropout1_rate': 0.14771813360964037, 'dropout2_rate': 0.7362432574402716, 'lr': 0.0003805934843190477, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 140, 'dense1_units': 65, 'sgd_momentum': 0.8624740407267049}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.6998295783996582, 'info': {'train_score': {0: 0.9060466289520264}, 'val_score': {0: 2.433129072189331}, 'test_score': {0: 1.6998295783996582}}}\n",
      "exception: None\n",
      "\n",
      "03:05:04 job_callback for (0, 0, 2) started\n",
      "03:05:04 job_callback for (0, 0, 2) got condition\n",
      "03:05:04 DISPATCHER: Trying to submit another job.\n",
      "03:05:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:05:04 HBMASTER: Trying to run another job!\n",
      "03:05:04 job_callback for (0, 0, 2) finished\n",
      "03:05:04 start sampling a new configuration.\n",
      "03:05:04 done sampling a new configuration.\n",
      "03:05:04 HBMASTER: schedule new run for iteration 0\n",
      "03:05:04 HBMASTER: trying submitting job (0, 0, 21) to dispatcher\n",
      "03:05:04 HBMASTER: submitting job (0, 0, 21) to dispatcher\n",
      "03:05:04 DISPATCHER: trying to submit job (0, 0, 21)\n",
      "03:05:04 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:05:04 HBMASTER: job (0, 0, 21) submitted to dispatcher\n",
      "03:05:04 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:05:04 DISPATCHER: Trying to submit another job.\n",
      "03:05:04 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:05:04 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:05:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:05:04 WORKER: start processing job (0, 0, 21)\n",
      "03:05:04 WORKER: args: ()\n",
      "03:05:05 WORKER: kwargs: {'config': {'dropout1_rate': 0.10982361449576163, 'dropout2_rate': 0.8535354738774755, 'lr': 1.2504755970780503e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 128, 'dense1_units': 17, 'sgd_momentum': 0.7291925767839834}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:05:10 WORKER: done with job (0, 0, 9), trying to register it.\n",
      "03:05:10 WORKER: registered result for job (0, 0, 9) with dispatcher\n",
      "03:05:10 DISPATCHER: job (0, 0, 9) finished\n",
      "03:05:10 DISPATCHER: register_result: lock acquired\n",
      "03:05:10 DISPATCHER: job (0, 0, 9) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064 finished\n",
      "03:05:10 job_id: (0, 0, 9)\n",
      "kwargs: {'config': {'dropout1_rate': 0.6030828800944451, 'dropout2_rate': 0.0703249900223229, 'lr': 0.0010285025420046395, 'num_dense_layers': 2, 'optimizer': 'Adam', 'start_neurons_units': 197, 'dense1_units': 51}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 8.241739273071289, 'info': {'train_score': {0: 0.1690116822719574}, 'val_score': {0: 10.75802993774414}, 'test_score': {0: 8.241739273071289}}}\n",
      "exception: None\n",
      "\n",
      "03:05:10 job_callback for (0, 0, 9) started\n",
      "03:05:10 DISPATCHER: Trying to submit another job.\n",
      "03:05:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:05:10 job_callback for (0, 0, 9) got condition\n",
      "03:05:10 HBMASTER: Trying to run another job!\n",
      "03:05:10 job_callback for (0, 0, 9) finished\n",
      "03:05:10 start sampling a new configuration.\n",
      "03:05:10 done sampling a new configuration.\n",
      "03:05:10 HBMASTER: schedule new run for iteration 0\n",
      "03:05:10 HBMASTER: trying submitting job (0, 0, 22) to dispatcher\n",
      "03:05:10 HBMASTER: submitting job (0, 0, 22) to dispatcher\n",
      "03:05:10 DISPATCHER: trying to submit job (0, 0, 22)\n",
      "03:05:10 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:05:10 HBMASTER: job (0, 0, 22) submitted to dispatcher\n",
      "03:05:10 DISPATCHER: Trying to submit another job.\n",
      "03:05:10 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:05:10 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n",
      "03:05:10 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n",
      "03:05:10 WORKER: start processing job (0, 0, 22)\n",
      "03:05:10 WORKER: args: ()\n",
      "03:05:10 WORKER: kwargs: {'config': {'dropout1_rate': 0.4462281291753331, 'dropout2_rate': 0.3403209823427116, 'lr': 6.569625001299828e-05, 'num_dense_layers': 2, 'optimizer': 'Adam', 'start_neurons_units': 62, 'dense1_units': 60}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:05:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:05:14 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "03:05:14 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "03:05:14 DISPATCHER: job (0, 0, 5) finished\n",
      "03:05:14 DISPATCHER: register_result: lock acquired\n",
      "03:05:14 DISPATCHER: job (0, 0, 5) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064 finished\n",
      "03:05:14 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8246339575153093, 'dropout2_rate': 0.871763439121914, 'lr': 9.179744630693924e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 259}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.8345935344696045, 'info': {'train_score': {0: 0.8764417171478271}, 'val_score': {0: 2.154524326324463}, 'test_score': {0: 1.8345935344696045}}}\n",
      "exception: None\n",
      "\n",
      "03:05:14 job_callback for (0, 0, 5) started\n",
      "03:05:14 DISPATCHER: Trying to submit another job.\n",
      "03:05:14 job_callback for (0, 0, 5) got condition\n",
      "03:05:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:05:14 HBMASTER: Trying to run another job!\n",
      "03:05:14 job_callback for (0, 0, 5) finished\n",
      "03:05:14 start sampling a new configuration.\n",
      "03:05:14 done sampling a new configuration.\n",
      "03:05:14 HBMASTER: schedule new run for iteration 0\n",
      "03:05:14 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "03:05:14 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "03:05:14 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "03:05:14 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:05:14 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "03:05:14 DISPATCHER: Trying to submit another job.\n",
      "03:05:14 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:05:14 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "03:05:15 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "03:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:05:15 WORKER: start processing job (0, 0, 23)\n",
      "03:05:15 WORKER: args: ()\n",
      "03:05:15 WORKER: kwargs: {'config': {'dropout1_rate': 0.2767239625501162, 'dropout2_rate': 0.3186810451349372, 'lr': 7.302761679724997e-05, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 78, 'dense1_units': 65, 'dense2_units': 7}, 'budget': 9.0, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 8\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:05:36 WORKER: done with job (0, 0, 13), trying to register it.\n",
      "03:05:36 WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "03:05:36 DISPATCHER: job (0, 0, 13) finished\n",
      "03:05:36 DISPATCHER: register_result: lock acquired\n",
      "03:05:36 DISPATCHER: job (0, 0, 13) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064 finished\n",
      "03:05:36 job_id: (0, 0, 13)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8470504741144611, 'dropout2_rate': 0.6235575138453934, 'lr': 0.0011028145452650958, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 175, 'sgd_momentum': 0.331482424701076}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.717134952545166, 'info': {'train_score': {0: 1.2330749034881592}, 'val_score': {0: 1.952843427658081}, 'test_score': {0: 1.717134952545166}}}\n",
      "exception: None\n",
      "\n",
      "03:05:36 job_callback for (0, 0, 13) started\n",
      "03:05:36 DISPATCHER: Trying to submit another job.\n",
      "03:05:36 job_callback for (0, 0, 13) got condition\n",
      "03:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:05:36 HBMASTER: Trying to run another job!\n",
      "03:05:36 job_callback for (0, 0, 13) finished\n",
      "03:05:36 start sampling a new configuration.\n",
      "03:05:36 done sampling a new configuration.\n",
      "03:05:36 HBMASTER: schedule new run for iteration 0\n",
      "03:05:36 HBMASTER: trying submitting job (0, 0, 24) to dispatcher\n",
      "03:05:36 HBMASTER: submitting job (0, 0, 24) to dispatcher\n",
      "03:05:36 DISPATCHER: trying to submit job (0, 0, 24)\n",
      "03:05:36 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:05:36 HBMASTER: job (0, 0, 24) submitted to dispatcher\n",
      "03:05:36 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:05:36 DISPATCHER: Trying to submit another job.\n",
      "03:05:36 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:05:36 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:05:36 WORKER: start processing job (0, 0, 24)\n",
      "03:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:05:37 WORKER: args: ()\n",
      "03:05:37 WORKER: kwargs: {'config': {'dropout1_rate': 0.5311178348095051, 'dropout2_rate': 0.5424385870606458, 'lr': 0.08343787975024503, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 41, 'dense1_units': 82, 'dense2_units': 7}, 'budget': 9.0, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 8\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:00 WORKER: done with job (0, 0, 17), trying to register it.\n",
      "03:06:00 WORKER: registered result for job (0, 0, 17) with dispatcher\n",
      "03:06:00 DISPATCHER: job (0, 0, 17) finished\n",
      "03:06:00 DISPATCHER: register_result: lock acquired\n",
      "03:06:00 DISPATCHER: job (0, 0, 17) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064 finished\n",
      "03:06:01 job_id: (0, 0, 17)\n",
      "kwargs: {'config': {'dropout1_rate': 0.47955964076404806, 'dropout2_rate': 0.21422353214408393, 'lr': 4.363499868999658e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 126, 'dense1_units': 78, 'sgd_momentum': 0.3784332014223267}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.0992836952209473, 'info': {'train_score': {0: 2.0231966972351074}, 'val_score': {0: 2.099522829055786}, 'test_score': {0: 2.0992836952209473}}}\n",
      "exception: None\n",
      "\n",
      "03:06:01 job_callback for (0, 0, 17) started\n",
      "03:06:01 DISPATCHER: Trying to submit another job.\n",
      "03:06:01 job_callback for (0, 0, 17) got condition\n",
      "03:06:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:06:01 HBMASTER: Trying to run another job!\n",
      "03:06:01 job_callback for (0, 0, 17) finished\n",
      "03:06:01 start sampling a new configuration.\n",
      "03:06:01 done sampling a new configuration.\n",
      "03:06:01 HBMASTER: schedule new run for iteration 0\n",
      "03:06:01 HBMASTER: trying submitting job (0, 0, 25) to dispatcher\n",
      "03:06:01 HBMASTER: submitting job (0, 0, 25) to dispatcher\n",
      "03:06:01 DISPATCHER: trying to submit job (0, 0, 25)\n",
      "03:06:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:01 HBMASTER: job (0, 0, 25) submitted to dispatcher\n",
      "03:06:01 DISPATCHER: Trying to submit another job.\n",
      "03:06:01 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:06:01 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:06:01 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:06:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:06:01 WORKER: start processing job (0, 0, 25)\n",
      "03:06:01 WORKER: args: ()\n",
      "03:06:01 WORKER: kwargs: {'config': {'dropout1_rate': 0.6030757187008675, 'dropout2_rate': 0.6306531584987108, 'lr': 1.2410985231215934e-06, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 144, 'sgd_momentum': 0.23556671934060788}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:06:01 WORKER: done with job (0, 0, 12), trying to register it.\n",
      "03:06:02 WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "03:06:02 DISPATCHER: job (0, 0, 12) finished\n",
      "03:06:02 DISPATCHER: register_result: lock acquired\n",
      "03:06:02 DISPATCHER: job (0, 0, 12) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064 finished\n",
      "03:06:02 job_id: (0, 0, 12)\n",
      "kwargs: {'config': {'dropout1_rate': 0.1718208214209649, 'dropout2_rate': 0.31895400296122667, 'lr': 0.0002090746530280218, 'num_dense_layers': 2, 'optimizer': 'Adam', 'start_neurons_units': 33, 'dense1_units': 22}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.57535719871521, 'info': {'train_score': {0: 0.3957100808620453}, 'val_score': {0: 4.2116193771362305}, 'test_score': {0: 2.57535719871521}}}\n",
      "exception: None\n",
      "\n",
      "03:06:02 job_callback for (0, 0, 12) started\n",
      "03:06:02 DISPATCHER: Trying to submit another job.\n",
      "03:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:06:02 job_callback for (0, 0, 12) got condition\n",
      "03:06:02 HBMASTER: Trying to run another job!\n",
      "03:06:02 job_callback for (0, 0, 12) finished\n",
      "03:06:02 start sampling a new configuration.\n",
      "03:06:02 done sampling a new configuration.\n",
      "03:06:02 HBMASTER: schedule new run for iteration 0\n",
      "03:06:02 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "03:06:02 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "03:06:02 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "03:06:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:02 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "03:06:02 HBMASTER: running jobs: 12, queue sizes: (11, 12) -> wait\n",
      "03:06:02 DISPATCHER: Trying to submit another job.\n",
      "03:06:02 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:06:02 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "03:06:03 WORKER: start processing job (0, 0, 26)\n",
      "03:06:03 WORKER: args: ()\n",
      "03:06:03 WORKER: kwargs: {'config': {'dropout1_rate': 0.25312057034179186, 'dropout2_rate': 0.3051966103430892, 'lr': 7.986140487401547e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 88}, 'budget': 9.0, 'working_directory': '.'}\n",
      "03:06:04 DISPATCHER: Starting worker discovery\n",
      "03:06:04 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:06:05 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:07 WORKER: done with job (0, 0, 15), trying to register it.\n",
      "03:06:08 WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "03:06:08 DISPATCHER: job (0, 0, 15) finished\n",
      "03:06:08 DISPATCHER: register_result: lock acquired\n",
      "03:06:08 DISPATCHER: job (0, 0, 15) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064 finished\n",
      "03:06:08 job_id: (0, 0, 15)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2658707926403801, 'dropout2_rate': 0.6694248038712984, 'lr': 6.8728806579344335e-06, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 418, 'dense1_units': 66, 'dense2_units': 24}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.8564738035202026, 'info': {'train_score': {0: 1.5453819036483765}, 'val_score': {0: 2.0270745754241943}, 'test_score': {0: 1.8564738035202026}}}\n",
      "exception: None\n",
      "\n",
      "03:06:08 job_callback for (0, 0, 15) started\n",
      "03:06:08 DISPATCHER: Trying to submit another job.\n",
      "03:06:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "03:06:08 job_callback for (0, 0, 15) got condition\n",
      "03:06:08 HBMASTER: Trying to run another job!\n",
      "03:06:08 job_callback for (0, 0, 15) finished\n",
      "03:06:13 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "03:06:13 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "03:06:13 DISPATCHER: job (0, 0, 19) finished\n",
      "03:06:13 DISPATCHER: register_result: lock acquired\n",
      "03:06:13 DISPATCHER: job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064 finished\n",
      "03:06:13 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.7475074529647827, 'info': {'train_score': {0: 1.4048486948013306}, 'val_score': {0: 1.929212212562561}, 'test_score': {0: 1.7475074529647827}}}\n",
      "exception: None\n",
      "\n",
      "03:06:13 job_callback for (0, 0, 19) started\n",
      "03:06:13 DISPATCHER: Trying to submit another job.\n",
      "03:06:13 job_callback for (0, 0, 19) got condition\n",
      "03:06:13 DISPATCHER: jobs to submit = 0, number of idle workers = 2 -> waiting!\n",
      "03:06:13 HBMASTER: Trying to run another job!\n",
      "03:06:13 job_callback for (0, 0, 19) finished\n",
      "03:06:14 WORKER: done with job (0, 0, 14), trying to register it.\n",
      "03:06:14 WORKER: registered result for job (0, 0, 14) with dispatcher\n",
      "03:06:14 DISPATCHER: job (0, 0, 14) finished\n",
      "03:06:14 DISPATCHER: register_result: lock acquired\n",
      "03:06:14 DISPATCHER: job (0, 0, 14) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064 finished\n",
      "03:06:14 job_id: (0, 0, 14)\n",
      "kwargs: {'config': {'dropout1_rate': 0.677073356730952, 'dropout2_rate': 0.583699508683521, 'lr': 0.01002492827889681, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 144, 'dense1_units': 8, 'sgd_momentum': 0.9557495175319882}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.7993282079696655, 'info': {'train_score': {0: 0.7006604075431824}, 'val_score': {0: 3.423222303390503}, 'test_score': {0: 1.7993282079696655}}}\n",
      "exception: None\n",
      "\n",
      "03:06:14 job_callback for (0, 0, 14) started\n",
      "03:06:14 job_callback for (0, 0, 14) got condition\n",
      "03:06:14 DISPATCHER: Trying to submit another job.\n",
      "03:06:14 DISPATCHER: jobs to submit = 0, number of idle workers = 3 -> waiting!\n",
      "03:06:14 HBMASTER: Trying to run another job!\n",
      "03:06:14 job_callback for (0, 0, 14) finished\n",
      "03:06:15 WORKER: done with job (0, 0, 21), trying to register it.\n",
      "03:06:15 WORKER: registered result for job (0, 0, 21) with dispatcher\n",
      "03:06:15 DISPATCHER: job (0, 0, 21) finished\n",
      "03:06:15 DISPATCHER: register_result: lock acquired\n",
      "03:06:15 DISPATCHER: job (0, 0, 21) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064 finished\n",
      "03:06:15 job_id: (0, 0, 21)\n",
      "kwargs: {'config': {'dropout1_rate': 0.10982361449576163, 'dropout2_rate': 0.8535354738774755, 'lr': 1.2504755970780503e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 128, 'dense1_units': 17, 'sgd_momentum': 0.7291925767839834}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.093019485473633, 'info': {'train_score': {0: 2.0974369049072266}, 'val_score': {0: 2.116049289703369}, 'test_score': {0: 2.093019485473633}}}\n",
      "exception: None\n",
      "\n",
      "03:06:15 job_callback for (0, 0, 21) started\n",
      "03:06:15 DISPATCHER: Trying to submit another job.\n",
      "03:06:15 job_callback for (0, 0, 21) got condition\n",
      "03:06:15 DISPATCHER: jobs to submit = 0, number of idle workers = 4 -> waiting!\n",
      "03:06:15 HBMASTER: Trying to run another job!\n",
      "03:06:15 job_callback for (0, 0, 21) finished\n",
      "03:06:16 WORKER: done with job (0, 0, 18), trying to register it.\n",
      "03:06:16 WORKER: registered result for job (0, 0, 18) with dispatcher\n",
      "03:06:16 DISPATCHER: job (0, 0, 18) finished\n",
      "03:06:16 DISPATCHER: register_result: lock acquired\n",
      "03:06:16 DISPATCHER: job (0, 0, 18) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064 finished\n",
      "03:06:16 job_id: (0, 0, 18)\n",
      "kwargs: {'config': {'dropout1_rate': 0.39298666907123103, 'dropout2_rate': 0.413969287882117, 'lr': 0.013797724343189554, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 37}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 6.865258693695068, 'info': {'train_score': {0: 0.32911035418510437}, 'val_score': {0: 13.795695304870605}, 'test_score': {0: 6.865258693695068}}}\n",
      "exception: None\n",
      "\n",
      "03:06:16 job_callback for (0, 0, 18) started\n",
      "03:06:16 job_callback for (0, 0, 18) got condition\n",
      "03:06:16 DISPATCHER: Trying to submit another job.\n",
      "03:06:16 DISPATCHER: jobs to submit = 0, number of idle workers = 5 -> waiting!\n",
      "03:06:16 done building a new model for budget 9.000000 based on 10/17 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:16 HBMASTER: Trying to run another job!\n",
      "03:06:16 job_callback for (0, 0, 18) finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:20 WORKER: done with job (0, 0, 16), trying to register it.\n",
      "03:06:20 WORKER: registered result for job (0, 0, 16) with dispatcher\n",
      "03:06:20 DISPATCHER: job (0, 0, 16) finished\n",
      "03:06:20 DISPATCHER: register_result: lock acquired\n",
      "03:06:20 DISPATCHER: job (0, 0, 16) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064 finished\n",
      "03:06:20 job_id: (0, 0, 16)\n",
      "kwargs: {'config': {'dropout1_rate': 0.19373867663113675, 'dropout2_rate': 0.17747063361100654, 'lr': 0.0023522921483048686, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 164, 'dense1_units': 14, 'sgd_momentum': 0.5463312841632599}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.7708873748779297, 'info': {'train_score': {0: 0.7319050431251526}, 'val_score': {0: 3.017957925796509}, 'test_score': {0: 1.7708873748779297}}}\n",
      "exception: None\n",
      "\n",
      "03:06:20 job_callback for (0, 0, 16) started\n",
      "03:06:20 DISPATCHER: Trying to submit another job.\n",
      "03:06:20 DISPATCHER: jobs to submit = 0, number of idle workers = 6 -> waiting!\n",
      "03:06:20 job_callback for (0, 0, 16) got condition\n",
      "03:06:20 done building a new model for budget 9.000000 based on 10/17 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:20 HBMASTER: Trying to run another job!\n",
      "03:06:20 job_callback for (0, 0, 16) finished\n",
      "03:06:23 WORKER: done with job (0, 0, 20), trying to register it.\n",
      "03:06:23 WORKER: registered result for job (0, 0, 20) with dispatcher\n",
      "03:06:23 DISPATCHER: job (0, 0, 20) finished\n",
      "03:06:23 DISPATCHER: register_result: lock acquired\n",
      "03:06:23 DISPATCHER: job (0, 0, 20) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064 finished\n",
      "03:06:23 job_id: (0, 0, 20)\n",
      "kwargs: {'config': {'dropout1_rate': 0.4299894822575599, 'dropout2_rate': 0.6953353649250353, 'lr': 0.09607535038915281, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 60, 'sgd_momentum': 0.5883115623139403}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 6.081953525543213, 'info': {'train_score': {0: 0.08640581369400024}, 'val_score': {0: 7.827593803405762}, 'test_score': {0: 6.081953525543213}}}\n",
      "exception: None\n",
      "\n",
      "03:06:23 job_callback for (0, 0, 20) started\n",
      "03:06:23 job_callback for (0, 0, 20) got condition\n",
      "03:06:23 DISPATCHER: Trying to submit another job.\n",
      "03:06:23 DISPATCHER: jobs to submit = 0, number of idle workers = 7 -> waiting!\n",
      "03:06:23 done building a new model for budget 9.000000 based on 10/18 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:23 HBMASTER: Trying to run another job!\n",
      "03:06:23 job_callback for (0, 0, 20) finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:29 WORKER: done with job (0, 0, 22), trying to register it.\n",
      "03:06:29 WORKER: registered result for job (0, 0, 22) with dispatcher\n",
      "03:06:29 DISPATCHER: job (0, 0, 22) finished\n",
      "03:06:29 DISPATCHER: register_result: lock acquired\n",
      "03:06:29 DISPATCHER: job (0, 0, 22) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064 finished\n",
      "03:06:29 job_id: (0, 0, 22)\n",
      "kwargs: {'config': {'dropout1_rate': 0.4462281291753331, 'dropout2_rate': 0.3403209823427116, 'lr': 6.569625001299828e-05, 'num_dense_layers': 2, 'optimizer': 'Adam', 'start_neurons_units': 62, 'dense1_units': 60}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.2366175651550293, 'info': {'train_score': {0: 0.5269241333007812}, 'val_score': {0: 3.615421772003174}, 'test_score': {0: 2.2366175651550293}}}\n",
      "exception: None\n",
      "\n",
      "03:06:29 job_callback for (0, 0, 22) started\n",
      "03:06:29 DISPATCHER: Trying to submit another job.\n",
      "03:06:29 job_callback for (0, 0, 22) got condition\n",
      "03:06:29 DISPATCHER: jobs to submit = 0, number of idle workers = 8 -> waiting!\n",
      "03:06:29 done building a new model for budget 9.000000 based on 10/19 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:29 HBMASTER: Trying to run another job!\n",
      "03:06:29 job_callback for (0, 0, 22) finished\n",
      "03:06:31 WORKER: done with job (0, 0, 24), trying to register it.\n",
      "03:06:31 WORKER: registered result for job (0, 0, 24) with dispatcher\n",
      "03:06:31 DISPATCHER: job (0, 0, 24) finished\n",
      "03:06:31 DISPATCHER: register_result: lock acquired\n",
      "03:06:31 DISPATCHER: job (0, 0, 24) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064 finished\n",
      "03:06:31 job_id: (0, 0, 24)\n",
      "kwargs: {'config': {'dropout1_rate': 0.5311178348095051, 'dropout2_rate': 0.5424385870606458, 'lr': 0.08343787975024503, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 41, 'dense1_units': 82, 'dense2_units': 7}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.9965176582336426, 'info': {'train_score': {0: 1.9515799283981323}, 'val_score': {0: 1.9515924453735352}, 'test_score': {0: 1.9965176582336426}}}\n",
      "exception: None\n",
      "\n",
      "03:06:31 job_callback for (0, 0, 24) started\n",
      "03:06:31 DISPATCHER: Trying to submit another job.\n",
      "03:06:31 DISPATCHER: jobs to submit = 0, number of idle workers = 9 -> waiting!\n",
      "03:06:31 job_callback for (0, 0, 24) got condition\n",
      "03:06:31 done building a new model for budget 9.000000 based on 10/20 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:31 HBMASTER: Trying to run another job!\n",
      "03:06:31 job_callback for (0, 0, 24) finished\n",
      "03:06:31 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "03:06:31 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "03:06:31 DISPATCHER: job (0, 0, 23) finished\n",
      "03:06:31 DISPATCHER: register_result: lock acquired\n",
      "03:06:31 DISPATCHER: job (0, 0, 23) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064 finished\n",
      "03:06:32 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2767239625501162, 'dropout2_rate': 0.3186810451349372, 'lr': 7.302761679724997e-05, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 78, 'dense1_units': 65, 'dense2_units': 7}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.7729865312576294, 'info': {'train_score': {0: 0.647270143032074}, 'val_score': {0: 3.3296525478363037}, 'test_score': {0: 1.7729865312576294}}}\n",
      "exception: None\n",
      "\n",
      "03:06:32 job_callback for (0, 0, 23) started\n",
      "03:06:32 DISPATCHER: Trying to submit another job.\n",
      "03:06:32 job_callback for (0, 0, 23) got condition\n",
      "03:06:32 DISPATCHER: jobs to submit = 0, number of idle workers = 10 -> waiting!\n",
      "03:06:32 done building a new model for budget 9.000000 based on 10/21 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:32 HBMASTER: Trying to run another job!\n",
      "03:06:32 job_callback for (0, 0, 23) finished\n",
      "03:06:32 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "03:06:32 WORKER: registered result for job (0, 0, 26) with dispatcher\n",
      "03:06:32 DISPATCHER: job (0, 0, 26) finished\n",
      "03:06:32 DISPATCHER: register_result: lock acquired\n",
      "03:06:32 DISPATCHER: job (0, 0, 26) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064 finished\n",
      "03:06:32 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'dropout1_rate': 0.25312057034179186, 'dropout2_rate': 0.3051966103430892, 'lr': 7.986140487401547e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 88}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.7436403036117554, 'info': {'train_score': {0: 1.2122622728347778}, 'val_score': {0: 1.9227278232574463}, 'test_score': {0: 1.7436403036117554}}}\n",
      "exception: None\n",
      "\n",
      "03:06:32 job_callback for (0, 0, 26) started\n",
      "03:06:32 DISPATCHER: Trying to submit another job.\n",
      "03:06:32 job_callback for (0, 0, 26) got condition\n",
      "03:06:32 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:06:32 done building a new model for budget 9.000000 based on 10/22 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:32 HBMASTER: Trying to run another job!\n",
      "03:06:32 job_callback for (0, 0, 26) finished\n",
      "03:06:33 WORKER: done with job (0, 0, 25), trying to register it.\n",
      "03:06:33 WORKER: registered result for job (0, 0, 25) with dispatcher\n",
      "03:06:33 DISPATCHER: job (0, 0, 25) finished\n",
      "03:06:33 DISPATCHER: register_result: lock acquired\n",
      "03:06:33 DISPATCHER: job (0, 0, 25) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064 finished\n",
      "03:06:33 job_id: (0, 0, 25)\n",
      "kwargs: {'config': {'dropout1_rate': 0.6030757187008675, 'dropout2_rate': 0.6306531584987108, 'lr': 1.2410985231215934e-06, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 144, 'sgd_momentum': 0.23556671934060788}, 'budget': 9.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.2583627700805664, 'info': {'train_score': {0: 2.200460910797119}, 'val_score': {0: 2.206852436065674}, 'test_score': {0: 2.2583627700805664}}}\n",
      "exception: None\n",
      "\n",
      "03:06:33 job_callback for (0, 0, 25) started\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 job_callback for (0, 0, 25) got condition\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 12 -> waiting!\n",
      "03:06:33 done building a new model for budget 9.000000 based on 10/22 split\n",
      "Best loss for this budget:1.699830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "03:06:33 HBMASTER: Trying to run another job!\n",
      "03:06:33 job_callback for (0, 0, 25) finished\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 2) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 5) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 10) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 13) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 14) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 16) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 19) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 23) to next budget 27.000000\n",
      "03:06:33 ITERATION: Advancing config (0, 0, 26) to next budget 27.000000\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "03:06:33 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064\n",
      "03:06:33 WORKER: start processing job (0, 0, 2)\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 WORKER: kwargs: {'config': {'dropout1_rate': 0.14771813360964037, 'dropout2_rate': 0.7362432574402716, 'lr': 0.0003805934843190477, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 140, 'dense1_units': 65, 'sgd_momentum': 0.8624740407267049}, 'budget': 27.0, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:33 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "03:06:33 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064\n",
      "03:06:33 WORKER: start processing job (0, 0, 5)\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 10 -> waiting!\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 WORKER: kwargs: {'config': {'dropout1_rate': 0.8246339575153093, 'dropout2_rate': 0.871763439121914, 'lr': 9.179744630693924e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 259}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 13) to dispatcher\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 13) to dispatcher\n",
      "03:06:33 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064\n",
      "03:06:33 WORKER: start processing job (0, 0, 10)\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 13)\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 9 -> waiting!\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 WORKER: kwargs: {'config': {'dropout1_rate': 0.8195178175748332, 'dropout2_rate': 0.42695679197067304, 'lr': 0.010248348545451586, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 105, 'dense1_units': 48, 'sgd_momentum': 0.3581326048964492}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:33 HBMASTER: job (0, 0, 13) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 14) to dispatcher\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 14) to dispatcher\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 14)\n",
      "03:06:33 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 8 -> waiting!\n",
      "03:06:33 WORKER: start processing job (0, 0, 13)\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 HBMASTER: job (0, 0, 14) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 WORKER: kwargs: {'config': {'dropout1_rate': 0.8470504741144611, 'dropout2_rate': 0.6235575138453934, 'lr': 0.0011028145452650958, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 175, 'sgd_momentum': 0.331482424701076}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 16) to dispatcher\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 16) to dispatcher\n",
      "03:06:33 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 16)\n",
      "03:06:33 WORKER: start processing job (0, 0, 14)\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 7 -> waiting!\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 WORKER: kwargs: {'config': {'dropout1_rate': 0.677073356730952, 'dropout2_rate': 0.583699508683521, 'lr': 0.01002492827889681, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 144, 'dense1_units': 8, 'sgd_momentum': 0.9557495175319882}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:33 HBMASTER: job (0, 0, 16) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "03:06:33 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "03:06:33 WORKER: start processing job (0, 0, 16)\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 6 -> waiting!\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:33 WORKER: kwargs: {'config': {'dropout1_rate': 0.19373867663113675, 'dropout2_rate': 0.17747063361100654, 'lr': 0.0023522921483048686, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 164, 'dense1_units': 14, 'sgd_momentum': 0.5463312841632599}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:33 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "03:06:33 DISPATCHER: Trying to submit another job.\n",
      "03:06:33 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n",
      "03:06:33 HBMASTER: schedule new run for iteration 0\n",
      "03:06:33 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "03:06:33 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064\n",
      "03:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 5 -> waiting!\n",
      "03:06:33 WORKER: start processing job (0, 0, 19)\n",
      "03:06:33 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "03:06:33 WORKER: args: ()\n",
      "03:06:33 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "03:06:34 WORKER: kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:34 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "03:06:34 HBMASTER: schedule new run for iteration 0\n",
      "03:06:34 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "03:06:34 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "03:06:34 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "03:06:34 DISPATCHER: Trying to submit another job.\n",
      "03:06:34 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:06:34 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 4 -> waiting!\n",
      "03:06:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:06:34 WORKER: start processing job (0, 0, 23)\n",
      "03:06:34 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "03:06:34 DISPATCHER: Trying to submit another job.\n",
      "03:06:34 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n",
      "03:06:34 WORKER: args: ()\n",
      "03:06:34 WORKER: kwargs: {'config': {'dropout1_rate': 0.2767239625501162, 'dropout2_rate': 0.3186810451349372, 'lr': 7.302761679724997e-05, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 78, 'dense1_units': 65, 'dense2_units': 7}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:06:34 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:34 WORKER: start processing job (0, 0, 26)\n",
      "03:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 3 -> waiting!\n",
      "03:06:34 WORKER: args: ()\n",
      "03:06:34 WORKER: kwargs: {'config': {'dropout1_rate': 0.25312057034179186, 'dropout2_rate': 0.3051966103430892, 'lr': 7.986140487401547e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 88}, 'budget': 27.0, 'working_directory': '.'}\n",
      "03:07:05 DISPATCHER: Starting worker discovery\n",
      "03:07:05 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:07:05 DISPATCHER: Finished worker discovery\n",
      "03:08:05 DISPATCHER: Starting worker discovery\n",
      "03:08:05 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:08:05 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 27\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 27\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 25\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 27\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 1\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 27\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:09:02 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "03:09:02 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "03:09:02 DISPATCHER: job (0, 0, 19) finished\n",
      "03:09:02 DISPATCHER: register_result: lock acquired\n",
      "03:09:02 DISPATCHER: job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.8139977732192064 finished\n",
      "03:09:02 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.7202972173690796, 'info': {'train_score': {0: 1.0915805101394653}, 'val_score': {0: 2.057162046432495}, 'test_score': {0: 1.7202972173690796}}}\n",
      "exception: None\n",
      "\n",
      "03:09:02 job_callback for (0, 0, 19) started\n",
      "03:09:02 DISPATCHER: Trying to submit another job.\n",
      "03:09:02 job_callback for (0, 0, 19) got condition\n",
      "03:09:02 DISPATCHER: jobs to submit = 0, number of idle workers = 4 -> waiting!\n",
      "03:09:02 Only 1 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:09:02 HBMASTER: Trying to run another job!\n",
      "03:09:02 job_callback for (0, 0, 19) finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 27\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:09:05 DISPATCHER: Starting worker discovery\n",
      "03:09:05 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:09:06 DISPATCHER: Finished worker discovery\n",
      "03:10:06 DISPATCHER: Starting worker discovery\n",
      "03:10:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:10:06 DISPATCHER: Finished worker discovery\n",
      "03:10:15 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "03:10:15 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "03:10:15 DISPATCHER: job (0, 0, 23) finished\n",
      "03:10:15 DISPATCHER: register_result: lock acquired\n",
      "03:10:15 DISPATCHER: job (0, 0, 23) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064 finished\n",
      "03:10:15 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2767239625501162, 'dropout2_rate': 0.3186810451349372, 'lr': 7.302761679724997e-05, 'num_dense_layers': 3, 'optimizer': 'Adam', 'start_neurons_units': 78, 'dense1_units': 65, 'dense2_units': 7}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 4.081730842590332, 'info': {'train_score': {0: 0.2504570186138153}, 'val_score': {0: 5.766443729400635}, 'test_score': {0: 4.081730842590332}}}\n",
      "exception: None\n",
      "\n",
      "03:10:15 job_callback for (0, 0, 23) started\n",
      "03:10:15 job_callback for (0, 0, 23) got condition\n",
      "03:10:15 DISPATCHER: Trying to submit another job.\n",
      "03:10:15 DISPATCHER: jobs to submit = 0, number of idle workers = 5 -> waiting!\n",
      "03:10:15 Only 2 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:10:15 HBMASTER: Trying to run another job!\n",
      "03:10:15 job_callback for (0, 0, 23) finished\n",
      "03:10:26 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "03:10:26 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "03:10:26 DISPATCHER: job (0, 0, 10) finished\n",
      "03:10:26 DISPATCHER: register_result: lock acquired\n",
      "03:10:26 DISPATCHER: job (0, 0, 10) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.10139977732192064 finished\n",
      "03:10:26 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8195178175748332, 'dropout2_rate': 0.42695679197067304, 'lr': 0.010248348545451586, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 105, 'dense1_units': 48, 'sgd_momentum': 0.3581326048964492}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 4.431107044219971, 'info': {'train_score': {0: 0.35089588165283203}, 'val_score': {0: 5.601900577545166}, 'test_score': {0: 4.431107044219971}}}\n",
      "exception: None\n",
      "\n",
      "03:10:26 job_callback for (0, 0, 10) started\n",
      "03:10:26 DISPATCHER: Trying to submit another job.\n",
      "03:10:26 job_callback for (0, 0, 10) got condition\n",
      "03:10:26 DISPATCHER: jobs to submit = 0, number of idle workers = 6 -> waiting!\n",
      "03:10:26 Only 3 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:10:26 HBMASTER: Trying to run another job!\n",
      "03:10:26 job_callback for (0, 0, 10) finished\n",
      "03:10:32 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "03:10:32 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "03:10:32 DISPATCHER: job (0, 0, 2) finished\n",
      "03:10:32 DISPATCHER: register_result: lock acquired\n",
      "03:10:32 DISPATCHER: job (0, 0, 2) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.3139977732192064 finished\n",
      "03:10:32 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'dropout1_rate': 0.14771813360964037, 'dropout2_rate': 0.7362432574402716, 'lr': 0.0003805934843190477, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 140, 'dense1_units': 65, 'sgd_momentum': 0.8624740407267049}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.179764986038208, 'info': {'train_score': {0: 0.5346102714538574}, 'val_score': {0: 3.4094202518463135}, 'test_score': {0: 2.179764986038208}}}\n",
      "exception: None\n",
      "\n",
      "03:10:32 job_callback for (0, 0, 2) started\n",
      "03:10:32 DISPATCHER: Trying to submit another job.\n",
      "03:10:32 job_callback for (0, 0, 2) got condition\n",
      "03:10:32 DISPATCHER: jobs to submit = 0, number of idle workers = 7 -> waiting!\n",
      "03:10:32 Only 4 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:10:32 HBMASTER: Trying to run another job!\n",
      "03:10:32 job_callback for (0, 0, 2) finished\n",
      "03:10:34 WORKER: done with job (0, 0, 13), trying to register it.\n",
      "03:10:34 WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "03:10:34 DISPATCHER: job (0, 0, 13) finished\n",
      "03:10:34 DISPATCHER: register_result: lock acquired\n",
      "03:10:34 DISPATCHER: job (0, 0, 13) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.4139977732192064 finished\n",
      "03:10:34 job_id: (0, 0, 13)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8470504741144611, 'dropout2_rate': 0.6235575138453934, 'lr': 0.0011028145452650958, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 175, 'sgd_momentum': 0.331482424701076}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.8954564332962036, 'info': {'train_score': {0: 0.7851276993751526}, 'val_score': {0: 2.4399750232696533}, 'test_score': {0: 1.8954564332962036}}}\n",
      "exception: None\n",
      "\n",
      "03:10:34 job_callback for (0, 0, 13) started\n",
      "03:10:34 DISPATCHER: Trying to submit another job.\n",
      "03:10:34 job_callback for (0, 0, 13) got condition\n",
      "03:10:34 DISPATCHER: jobs to submit = 0, number of idle workers = 8 -> waiting!\n",
      "03:10:34 Only 5 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:10:34 HBMASTER: Trying to run another job!\n",
      "03:10:34 job_callback for (0, 0, 13) finished\n",
      "03:10:34 WORKER: done with job (0, 0, 16), trying to register it.\n",
      "03:10:34 WORKER: registered result for job (0, 0, 16) with dispatcher\n",
      "03:10:34 DISPATCHER: job (0, 0, 16) finished\n",
      "03:10:34 DISPATCHER: register_result: lock acquired\n",
      "03:10:34 DISPATCHER: job (0, 0, 16) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.5139977732192064 finished\n",
      "03:10:34 job_id: (0, 0, 16)\n",
      "kwargs: {'config': {'dropout1_rate': 0.19373867663113675, 'dropout2_rate': 0.17747063361100654, 'lr': 0.0023522921483048686, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 164, 'dense1_units': 14, 'sgd_momentum': 0.5463312841632599}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.386274576187134, 'info': {'train_score': {0: 0.46895134449005127}, 'val_score': {0: 4.4239654541015625}, 'test_score': {0: 2.386274576187134}}}\n",
      "exception: None\n",
      "\n",
      "03:10:34 job_callback for (0, 0, 16) started\n",
      "03:10:34 DISPATCHER: Trying to submit another job.\n",
      "03:10:34 job_callback for (0, 0, 16) got condition\n",
      "03:10:34 DISPATCHER: jobs to submit = 0, number of idle workers = 9 -> waiting!\n",
      "03:10:34 Only 6 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:10:34 HBMASTER: Trying to run another job!\n",
      "03:10:34 job_callback for (0, 0, 16) finished\n",
      "03:10:38 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "03:10:38 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "03:10:38 DISPATCHER: job (0, 0, 5) finished\n",
      "03:10:38 DISPATCHER: register_result: lock acquired\n",
      "03:10:38 DISPATCHER: job (0, 0, 5) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.9139977732192064 finished\n",
      "03:10:38 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8246339575153093, 'dropout2_rate': 0.871763439121914, 'lr': 9.179744630693924e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 259}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.0155773162841797, 'info': {'train_score': {0: 0.5933408141136169}, 'val_score': {0: 2.9191009998321533}, 'test_score': {0: 2.0155773162841797}}}\n",
      "exception: None\n",
      "\n",
      "03:10:38 job_callback for (0, 0, 5) started\n",
      "03:10:38 DISPATCHER: Trying to submit another job.\n",
      "03:10:38 job_callback for (0, 0, 5) got condition\n",
      "03:10:38 DISPATCHER: jobs to submit = 0, number of idle workers = 10 -> waiting!\n",
      "03:10:38 Only 7 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:10:38 HBMASTER: Trying to run another job!\n",
      "03:10:38 job_callback for (0, 0, 5) finished\n",
      "03:11:06 DISPATCHER: Starting worker discovery\n",
      "03:11:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:11:06 DISPATCHER: Finished worker discovery\n",
      "03:11:11 WORKER: done with job (0, 0, 14), trying to register it.\n",
      "03:11:11 WORKER: registered result for job (0, 0, 14) with dispatcher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:11:11 DISPATCHER: job (0, 0, 14) finished\n",
      "03:11:11 DISPATCHER: register_result: lock acquired\n",
      "03:11:11 DISPATCHER: job (0, 0, 14) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.6139977732192064 finished\n",
      "03:11:11 job_id: (0, 0, 14)\n",
      "kwargs: {'config': {'dropout1_rate': 0.677073356730952, 'dropout2_rate': 0.583699508683521, 'lr': 0.01002492827889681, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 144, 'dense1_units': 8, 'sgd_momentum': 0.9557495175319882}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.3444626331329346, 'info': {'train_score': {0: 0.917401909828186}, 'val_score': {0: 4.595603942871094}, 'test_score': {0: 2.3444626331329346}}}\n",
      "exception: None\n",
      "\n",
      "03:11:11 job_callback for (0, 0, 14) started\n",
      "03:11:11 DISPATCHER: Trying to submit another job.\n",
      "03:11:11 job_callback for (0, 0, 14) got condition\n",
      "03:11:11 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:11:11 Only 8 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:11:11 HBMASTER: Trying to run another job!\n",
      "03:11:11 job_callback for (0, 0, 14) finished\n",
      "03:11:27 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "03:11:27 WORKER: registered result for job (0, 0, 26) with dispatcher\n",
      "03:11:27 DISPATCHER: job (0, 0, 26) finished\n",
      "03:11:27 DISPATCHER: register_result: lock acquired\n",
      "03:11:27 DISPATCHER: job (0, 0, 26) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.2139977732192064 finished\n",
      "03:11:27 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'dropout1_rate': 0.25312057034179186, 'dropout2_rate': 0.3051966103430892, 'lr': 7.986140487401547e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 88}, 'budget': 27.0, 'working_directory': '.'}\n",
      "result: {'loss': 1.8722388744354248, 'info': {'train_score': {0: 0.7692680954933167}, 'val_score': {0: 2.491415500640869}, 'test_score': {0: 1.8722388744354248}}}\n",
      "exception: None\n",
      "\n",
      "03:11:27 job_callback for (0, 0, 26) started\n",
      "03:11:27 DISPATCHER: Trying to submit another job.\n",
      "03:11:27 job_callback for (0, 0, 26) got condition\n",
      "03:11:27 DISPATCHER: jobs to submit = 0, number of idle workers = 12 -> waiting!\n",
      "03:11:27 Only 9 run(s) for budget 27.000000 available, need more than 11 -> can't build model!\n",
      "03:11:27 HBMASTER: Trying to run another job!\n",
      "03:11:27 job_callback for (0, 0, 26) finished\n",
      "03:11:27 ITERATION: Advancing config (0, 0, 13) to next budget 81.000000\n",
      "03:11:27 ITERATION: Advancing config (0, 0, 19) to next budget 81.000000\n",
      "03:11:27 ITERATION: Advancing config (0, 0, 26) to next budget 81.000000\n",
      "03:11:27 HBMASTER: schedule new run for iteration 0\n",
      "03:11:27 HBMASTER: trying submitting job (0, 0, 13) to dispatcher\n",
      "03:11:27 HBMASTER: submitting job (0, 0, 13) to dispatcher\n",
      "03:11:27 DISPATCHER: trying to submit job (0, 0, 13)\n",
      "03:11:27 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:11:27 HBMASTER: job (0, 0, 13) submitted to dispatcher\n",
      "03:11:27 DISPATCHER: Trying to submit another job.\n",
      "03:11:27 HBMASTER: schedule new run for iteration 0\n",
      "03:11:27 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:11:27 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "03:11:27 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064\n",
      "03:11:27 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "03:11:27 WORKER: start processing job (0, 0, 13)\n",
      "03:11:27 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:11:27 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "03:11:27 WORKER: args: ()\n",
      "03:11:27 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:11:27 WORKER: kwargs: {'config': {'dropout1_rate': 0.8470504741144611, 'dropout2_rate': 0.6235575138453934, 'lr': 0.0011028145452650958, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 175, 'sgd_momentum': 0.331482424701076}, 'budget': 81.0, 'working_directory': '.'}\n",
      "03:11:27 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "03:11:27 DISPATCHER: Trying to submit another job.\n",
      "03:11:27 HBMASTER: schedule new run for iteration 0\n",
      "03:11:27 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:11:27 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "03:11:27 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064\n",
      "03:11:27 WORKER: start processing job (0, 0, 19)\n",
      "03:11:27 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "03:11:27 DISPATCHER: jobs to submit = 0, number of idle workers = 10 -> waiting!\n",
      "03:11:27 WORKER: args: ()\n",
      "03:11:27 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "03:11:27 WORKER: kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 81.0, 'working_directory': '.'}\n",
      "03:11:27 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:11:27 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "03:11:27 DISPATCHER: Trying to submit another job.\n",
      "03:11:27 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:11:27 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064\n",
      "03:11:27 DISPATCHER: jobs to submit = 0, number of idle workers = 9 -> waiting!\n",
      "03:11:27 WORKER: start processing job (0, 0, 26)\n",
      "03:11:27 WORKER: args: ()\n",
      "03:11:27 WORKER: kwargs: {'config': {'dropout1_rate': 0.25312057034179186, 'dropout2_rate': 0.3051966103430892, 'lr': 7.986140487401547e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 88}, 'budget': 81.0, 'working_directory': '.'}\n",
      "03:12:06 DISPATCHER: Starting worker discovery\n",
      "03:12:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:12:06 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:13:06 DISPATCHER: Starting worker discovery\n",
      "03:13:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:13:06 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 81\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:14:06 DISPATCHER: Starting worker discovery\n",
      "03:14:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:14:06 DISPATCHER: Finished worker discovery\n",
      "03:14:23 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "03:14:23 WORKER: registered result for job (0, 0, 26) with dispatcher\n",
      "03:14:23 DISPATCHER: job (0, 0, 26) finished\n",
      "03:14:23 DISPATCHER: register_result: lock acquired\n",
      "03:14:23 DISPATCHER: job (0, 0, 26) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.1139977732192064 finished\n",
      "03:14:23 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'dropout1_rate': 0.25312057034179186, 'dropout2_rate': 0.3051966103430892, 'lr': 7.986140487401547e-06, 'num_dense_layers': 1, 'optimizer': 'Adam', 'start_neurons_units': 88}, 'budget': 81.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.2022740840911865, 'info': {'train_score': {0: 0.4919147491455078}, 'val_score': {0: 3.412670135498047}, 'test_score': {0: 2.2022740840911865}}}\n",
      "exception: None\n",
      "\n",
      "03:14:23 job_callback for (0, 0, 26) started\n",
      "03:14:23 DISPATCHER: Trying to submit another job.\n",
      "03:14:23 job_callback for (0, 0, 26) got condition\n",
      "03:14:23 DISPATCHER: jobs to submit = 0, number of idle workers = 10 -> waiting!\n",
      "03:14:23 Only 1 run(s) for budget 81.000000 available, need more than 11 -> can't build model!\n",
      "03:14:23 HBMASTER: Trying to run another job!\n",
      "03:14:23 job_callback for (0, 0, 26) finished\n",
      "03:14:47 WORKER: done with job (0, 0, 13), trying to register it.\n",
      "03:14:47 WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "03:14:47 DISPATCHER: job (0, 0, 13) finished\n",
      "03:14:47 DISPATCHER: register_result: lock acquired\n",
      "03:14:47 DISPATCHER: job (0, 0, 13) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.0139977732192064 finished\n",
      "03:14:47 job_id: (0, 0, 13)\n",
      "kwargs: {'config': {'dropout1_rate': 0.8470504741144611, 'dropout2_rate': 0.6235575138453934, 'lr': 0.0011028145452650958, 'num_dense_layers': 1, 'optimizer': 'SGD', 'start_neurons_units': 175, 'sgd_momentum': 0.331482424701076}, 'budget': 81.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.2771472930908203, 'info': {'train_score': {0: 0.5102913975715637}, 'val_score': {0: 3.3586297035217285}, 'test_score': {0: 2.2771472930908203}}}\n",
      "exception: None\n",
      "\n",
      "03:14:47 job_callback for (0, 0, 13) started\n",
      "03:14:47 DISPATCHER: Trying to submit another job.\n",
      "03:14:47 job_callback for (0, 0, 13) got condition\n",
      "03:14:47 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:14:47 Only 2 run(s) for budget 81.000000 available, need more than 11 -> can't build model!\n",
      "03:14:47 HBMASTER: Trying to run another job!\n",
      "03:14:47 job_callback for (0, 0, 13) finished\n",
      "03:14:50 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "03:14:50 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "03:14:50 DISPATCHER: job (0, 0, 19) finished\n",
      "03:14:50 DISPATCHER: register_result: lock acquired\n",
      "03:14:50 DISPATCHER: job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.7139977732192064 finished\n",
      "03:14:50 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 81.0, 'working_directory': '.'}\n",
      "result: {'loss': 2.1231532096862793, 'info': {'train_score': {0: 0.5553443431854248}, 'val_score': {0: 3.5689620971679688}, 'test_score': {0: 2.1231532096862793}}}\n",
      "exception: None\n",
      "\n",
      "03:14:50 job_callback for (0, 0, 19) started\n",
      "03:14:50 DISPATCHER: Trying to submit another job.\n",
      "03:14:50 job_callback for (0, 0, 19) got condition\n",
      "03:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 12 -> waiting!\n",
      "03:14:50 Only 3 run(s) for budget 81.000000 available, need more than 11 -> can't build model!\n",
      "03:14:50 HBMASTER: Trying to run another job!\n",
      "03:14:50 job_callback for (0, 0, 19) finished\n",
      "03:14:50 ITERATION: Advancing config (0, 0, 19) to next budget 243.000000\n",
      "03:14:50 HBMASTER: schedule new run for iteration 0\n",
      "03:14:50 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "03:14:50 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "03:14:50 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "03:14:50 DISPATCHER: trying to notify the job_runner thread.\n",
      "03:14:50 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "03:14:50 DISPATCHER: Trying to submit another job.\n",
      "03:14:50 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:14:50 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064\n",
      "03:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 11 -> waiting!\n",
      "03:14:50 WORKER: start processing job (0, 0, 19)\n",
      "03:14:50 WORKER: args: ()\n",
      "03:14:50 WORKER: kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 243.0, 'working_directory': '.'}\n",
      "03:15:06 DISPATCHER: Starting worker discovery\n",
      "03:15:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:15:06 DISPATCHER: Finished worker discovery\n",
      "03:16:06 DISPATCHER: Starting worker discovery\n",
      "03:16:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:16:06 DISPATCHER: Finished worker discovery\n",
      "03:17:06 DISPATCHER: Starting worker discovery\n",
      "03:17:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:17:06 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n",
      "Best epoch: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:18:06 DISPATCHER: Starting worker discovery\n",
      "03:18:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:18:06 DISPATCHER: Finished worker discovery\n",
      "03:19:06 DISPATCHER: Starting worker discovery\n",
      "03:19:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:19:06 DISPATCHER: Finished worker discovery\n",
      "03:20:06 DISPATCHER: Starting worker discovery\n",
      "03:20:06 DISPATCHER: Found 12 potential workers, 12 currently in the pool.\n",
      "03:20:06 DISPATCHER: Finished worker discovery\n",
      "03:20:15 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "03:20:15 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "03:20:15 DISPATCHER: job (0, 0, 19) finished\n",
      "03:20:15 DISPATCHER: register_result: lock acquired\n",
      "03:20:15 DISPATCHER: job (0, 0, 19) on hpbandster.run_rgb_classification_9_5_conc_0.worker.sharifa-ProArt.11933.11139977732192064 finished\n",
      "03:20:15 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}, 'budget': 243.0, 'working_directory': '.'}\n",
      "result: {'loss': 3.8952476978302, 'info': {'train_score': {0: 0.1719006896018982}, 'val_score': {0: 5.022670269012451}, 'test_score': {0: 3.8952476978302}}}\n",
      "exception: None\n",
      "\n",
      "03:20:15 job_callback for (0, 0, 19) started\n",
      "03:20:15 job_callback for (0, 0, 19) got condition\n",
      "03:20:15 DISPATCHER: Trying to submit another job.\n",
      "03:20:15 Only 1 run(s) for budget 243.000000 available, need more than 11 -> can't build model!\n",
      "03:20:15 DISPATCHER: jobs to submit = 0, number of idle workers = 12 -> waiting!\n",
      "03:20:15 HBMASTER: Trying to run another job!\n",
      "03:20:15 job_callback for (0, 0, 19) finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found configuration: {'dropout1_rate': 0.2818801186040096, 'dropout2_rate': 0.3316644022439695, 'lr': 9.701638808469587e-05, 'num_dense_layers': 2, 'optimizer': 'SGD', 'start_neurons_units': 130, 'dense1_units': 83, 'sgd_momentum': 0.9026140679195418}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11933/3696172365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mresult_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatureType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprblemType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_lvls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfusionType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mcreate_modlling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprblemType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_lvls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, divide,fusionType)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11933/656997571.py\u001b[0m in \u001b[0;36mcreate_modlling\u001b[0;34m(label_folder, feature_folder, result_folder, prblemType, featureType, num_classes)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# store results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# shutdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "prblemTypes = ['classification', 'regression']\n",
    "featureTypes = ['rgb','flow', 'twostream']\n",
    "classes = [9,5,3]\n",
    "# divides = [2.5, 5]\n",
    "fusionTypes = ['none', 'conc','avg']\n",
    "\n",
    "permutations=[ prblemTypes, featureTypes, classes, fusionTypes]\n",
    "all_permutations = list(itertools.product(*permutations))\n",
    "print(len(all_permutations))\n",
    "for this_permutation in all_permutations:\n",
    "    (prblemType, featureType, eng_lvls, fusionType) = this_permutation\n",
    "    classType = 'round_avg_eng_level' if prblemType == 'classification' else 'avg_eng_level'\n",
    "    divide = 2.5 if fusionType == 'none' else 5\n",
    "    \n",
    "    print('Working on: ',prblemType, featureType, eng_lvls, divide, fusionType)\n",
    "    \n",
    "    label_folder = os.path.join(lables_path,'_'.join([classType,'eng_lvl',prblemType,str(eng_lvls),str(divide)]))\n",
    "\n",
    "    \n",
    "    if divide == 5:\n",
    "        extra_txt = '_'.join([fusionType,str(divide)]) \n",
    "        feature_folder = os.path.join(features_path,'_'.join(['i3d',featureType,'features',extra_txt]))\n",
    "    else:\n",
    "        feature_folder = os.path.join(features_path,'_'.join(['i3d',featureType,'features']))\n",
    "        \n",
    "    \n",
    "    #save results like: rgb_classification_9_2.5_none\n",
    "    result_folder = os.path.join(results_path,'_'.join([featureType,prblemType,str(eng_lvls),str(divide),fusionType]))\n",
    "\n",
    "    create_modlling(label_folder,feature_folder,result_folder, prblemType, featureType, eng_lvls)#, divide,fusionType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381fa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
