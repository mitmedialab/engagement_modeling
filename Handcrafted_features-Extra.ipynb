{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9b1868",
   "metadata": {},
   "source": [
    "# Extarct handcrafted features \n",
    "- for each person, for x frames, calculate the nonverbal features from head and body landmarks \n",
    "- the x frames are: 64 frames (\\~2.5s), 64\\*2 (\\~5s) and 5*30(=5s)\n",
    "- the first two are to be compared with the deep features, the last is for the actual labeling \n",
    "\n",
    "- raw data --> low-level --> high-level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cbe40",
   "metadata": {},
   "source": [
    "### imports and vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b8ed156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from outliers import smirnov_grubbs as grubbs\n",
    "from statistics import mean, stdev, variance\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import medfilt, find_peaks\n",
    "\n",
    "base_path = '/home/sharifa/speedDating/'\n",
    "raw_features_path = os.path.join(base_path,'speedDating_Detectron_named_3D_with_gazeFollow/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146362c",
   "metadata": {},
   "source": [
    "### help functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b796032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformations import euler_from_matrix #local file\n",
    "\n",
    "def rigid_transform_3D(A, B):\n",
    "    assert len(A) == len(B)\n",
    "\n",
    "    N = A.shape[0]  # total points\n",
    "\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "\n",
    "    # centre the points\n",
    "    AA = A - np.tile(centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "\n",
    "    # dot is matrix multiplication for array\n",
    "    H = np.transpose(AA) * BB\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "\n",
    "    R = Vt.T * U.T\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        # print(\"Reflection detected\")\n",
    "        Vt[2, :] *= -1\n",
    "        R = Vt.T * U.T\n",
    "\n",
    "    t = -R * centroid_A.T + centroid_B.T\n",
    "\n",
    "    # print(t)\n",
    "\n",
    "    return R, t\n",
    "\n",
    "\n",
    "\n",
    "def get_relative_orientation(point_set1, point_set2):\n",
    "    ret_R, ret_t = rigid_transform_3D(np.mat(point_set1), np.mat(point_set2))\n",
    "    b_pitch, b_roll, b_yaw = 0, 0, 0\n",
    "    euler_angles = euler_from_matrix(ret_R)\n",
    "    if euler_angles:\n",
    "        #print('THEY SHOULD BE LOOKING AT EACH OTHER')\n",
    "        b_pitch, b_roll, b_yaw = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "        \n",
    "    return b_pitch, b_roll, b_yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0973074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MidHip = 0\n",
    "RHip = 1\n",
    "RKnee = 2\n",
    "RAnkle = 3\n",
    "LHip = 4\n",
    "LKnee = 5\n",
    "LAnkle = 6\n",
    "MidBack = 7\n",
    "Neck = 8\n",
    "Nose = 9\n",
    "forehead =10\n",
    "LShoulder = 11\n",
    "LElbow = 12\n",
    "LWrist = 13\n",
    "RShoulder = 14\n",
    "RElbow = 15\n",
    "RWrist = 16\n",
    "\n",
    "\n",
    "def body_get_headers():\n",
    "    body_features_heads =['body_pitch', 'body_roll', 'body_yaw',\n",
    "                         'lhand_face', 'rhand_face', \n",
    "                         'lhand_body', 'rhand_body', \n",
    "                         'rhand_lhand',\n",
    "                         'head_body_pitch', 'head_body_roll', 'head_body_yaw']\n",
    "    return body_features_heads\n",
    "\n",
    "\n",
    "\n",
    "def head_get_headers():\n",
    "    head_features_heads = ['head_pitch', 'head_roll', 'head_yaw']\n",
    "\n",
    "    return head_features_heads\n",
    "\n",
    "def sync_get_headers():\n",
    "    sync_features_heads = [\n",
    "        # body oriantion, distances in relation to others\n",
    "        # hands distance to others' face, body, hands: left and right \n",
    "        # head oriantion and distances in relation to others' head\n",
    "        # min, max , avg\n",
    "        'min_other_body_pitch', 'min_other_body_roll', 'min_other_body_yaw','min_other_body_dist',\n",
    "        'min_lhand_other_face', 'min_lhand_other_body', 'min_lhand_other_lhand', 'min_lhand_other_rhand',\n",
    "        'min_rhand_other_face', 'min_rhand_other_body', 'min_rhand_other_lhand', 'min_rhand_other_rhand', \n",
    "        'min_other_head_pitch', 'min_other_head_roll', 'min_other_head_yaw','min_other_head_dist', \n",
    "        \n",
    "        'max_other_body_pitch', 'max_other_body_roll', 'max_other_body_yaw', 'max_other_body_dist',\n",
    "        'max_lhand_other_face', 'max_lhand_other_body', 'max_lhand_other_lhand', 'max_lhand_other_rhand',\n",
    "        'max_rhand_other_face', 'max_rhand_other_body','max_rhand_other_lhand', 'max_rhand_other_rhand', \n",
    "        'max_other_head_pitch', 'max_other_head_roll', 'max_other_head_yaw','max_other_head_dist',\n",
    "        \n",
    "        'avg_other_body_pitch', 'avg_other_body_roll', 'avg_other_body_yaw', 'avg_other_body_dist',\n",
    "        'avg_lhand_other_face', 'avg_lhand_other_body', 'avg_lhand_other_lhand', 'avg_lhand_other_rhand', \n",
    "        'avg_rhand_other_face', 'avg_rhand_other_body', 'avg_rhand_other_lhand', 'avg_rhand_other_rhand', \n",
    "        'avg_other_head_pitch', 'avg_other_head_roll', 'avg_other_head_yaw','avg_other_head_dist',\n",
    "    ]\n",
    "\n",
    "    return sync_features_heads\n",
    "\n",
    "def get_stat_headers(features_heads):\n",
    "    # return stat_features\n",
    "    stats_features = [\n",
    "        'f_min', 'f_max', 'f_rang', 'f_mean', 'f_std', 'f_var', 'f_skew', 'f_kurt', 'f_peaks', 'f_valys',\n",
    "        'd1_min', 'd1_max', 'd1_rang', 'd1_mean', 'd1_std', 'd1_var', 'd1_skew', 'd1_kurt', 'd1_peaks', 'd1_valys',\n",
    "        'd2_min', 'd2_max', 'd2_rang', 'd2_mean', 'd2_std', 'd2_var', 'd2_skew', 'd2_kurt', 'd2_peaks', 'd2_valys'\n",
    "    ]\n",
    "\n",
    "    high_feature_headers = []\n",
    "    for i in range(len(features_heads)):\n",
    "        for j in range(len(stats_features)):\n",
    "            high_feature_headers.append(features_heads[i] + '-' + stats_features[j])\n",
    "\n",
    "    return high_feature_headers\n",
    "\n",
    "\n",
    "def body_sync_one(pose):\n",
    "    if len(pose) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    nose = pose[Nose]\n",
    "    center = pose[Neck]\n",
    "    rhand = pose[RWrist]\n",
    "    lhand = pose[LWrist]\n",
    "\n",
    "    lhand_face, rhand_face = None, None\n",
    "    lhand_body, rhand_body = None, None\n",
    "    lhand_rhand = None\n",
    "\n",
    "    if type(nose) != type(None):\n",
    "        if type(lhand) != type(None):\n",
    "            lhand_face = np.linalg.norm(lhand - nose)\n",
    "        if type(rhand) != type(None):\n",
    "            rhand_face = np.linalg.norm(rhand - nose)\n",
    "\n",
    "    if type(center) != type(None):\n",
    "        if type(lhand) != type(None):\n",
    "            lhand_body = np.linalg.norm(lhand - center)\n",
    "        if type(rhand) != type(None):\n",
    "            rhand_body = np.linalg.norm(rhand - center)\n",
    "\n",
    "    if type(lhand) != type(None):\n",
    "        if type(rhand) != type(None):\n",
    "            lhand_rhand = np.linalg.norm(lhand - rhand)\n",
    "\n",
    "    body_points = np.array([pose[Neck], pose[MidBack], pose[MidHip]])\n",
    "    head_points = np.array([pose[forehead], pose[Nose], pose[Neck]])\n",
    "    head_body_pitch, head_body_roll, head_body_yaw = get_relative_orientation(body_points, head_points)\n",
    "    \n",
    "    body_feature = [lhand_face, rhand_face,\n",
    "                    lhand_body, rhand_body,\n",
    "                    lhand_rhand,\n",
    "                   head_body_pitch, head_body_roll, head_body_yaw]\n",
    "    return np.array(body_feature)\n",
    "\n",
    "def get_sync_all(all_this_frame_keypoints_3D):\n",
    "    sync_raw_featuers = {}\n",
    "    for person in all_this_frame_keypoints_3D.keys():\n",
    "        sync_raw_featuers[person]=[]\n",
    "    \n",
    "    for this_outer_person in all_this_frame_keypoints_3D.keys():\n",
    "        this_outer_person_keypoints_3D=all_this_frame_keypoints_3D[this_outer_person]\n",
    "        if len(this_outer_person_keypoints_3D) == 0:\n",
    "            continue\n",
    "        outer_person_body_points = np.array([this_outer_person_keypoints_3D[Neck], \n",
    "                                             this_outer_person_keypoints_3D[RShoulder], \n",
    "                                             this_outer_person_keypoints_3D[LShoulder], \n",
    "                                             this_outer_person_keypoints_3D[MidHip]])\n",
    "        \n",
    "        outer_person_head_points = np.array([this_outer_person_keypoints_3D[forehead], \n",
    "                                             this_outer_person_keypoints_3D[Nose], \n",
    "                                             this_outer_person_keypoints_3D[Neck]])\n",
    "        \n",
    "        outer_person_center_points = np.array([this_outer_person_keypoints_3D[Neck]])\n",
    "        outer_person_face_points = np.array([this_outer_person_keypoints_3D[Nose]])\n",
    "        outer_person_lhand_points = np.array([this_outer_person_keypoints_3D[LWrist]])\n",
    "        outer_person_rhand_points = np.array([this_outer_person_keypoints_3D[RWrist]])\n",
    "\n",
    "        synced_features = []\n",
    "        \n",
    "        for this_inner_person in all_this_frame_keypoints_3D.keys():\n",
    "            if this_outer_person == this_inner_person:\n",
    "                continue \n",
    "        \n",
    "            this_inner_person_keypoints_3D=all_this_frame_keypoints_3D[this_inner_person]\n",
    "            if len(this_inner_person_keypoints_3D) == 0:\n",
    "                continue\n",
    "            # body oriantion in relation to others\n",
    "            inner_person_body_points = np.array([this_inner_person_keypoints_3D[Neck], \n",
    "                                                 this_inner_person_keypoints_3D[RShoulder], \n",
    "                                                 this_inner_person_keypoints_3D[LShoulder], \n",
    "                                                 this_inner_person_keypoints_3D[MidHip]])\n",
    "        \n",
    "            inner_person_head_points = np.array([this_inner_person_keypoints_3D[forehead], \n",
    "                                                 this_inner_person_keypoints_3D[Nose], \n",
    "                                                 this_inner_person_keypoints_3D[Neck]])\n",
    "\n",
    "            inner_person_center_points = np.array([this_inner_person_keypoints_3D[Neck]])\n",
    "            inner_person_face_points = np.array([this_inner_person_keypoints_3D[Nose]])\n",
    "            inner_person_lhand_points = np.array([this_inner_person_keypoints_3D[LWrist]])\n",
    "            inner_person_rhand_points = np.array([this_inner_person_keypoints_3D[RWrist]])\n",
    "\n",
    "            # body oriantion in relation to others\n",
    "            b_pitch, b_roll, b_yaw = get_relative_orientation(outer_person_body_points, inner_person_body_points)\n",
    "            # body distances in relation to others\n",
    "            b_dist = np.linalg.norm(outer_person_center_points - inner_person_center_points)\n",
    "            \n",
    "            # touching \n",
    "            # left hand\n",
    "            l_face_dist = np.linalg.norm(outer_person_lhand_points - inner_person_face_points)\n",
    "            l_body_dist = np.linalg.norm(outer_person_lhand_points - inner_person_center_points)\n",
    "            l_lhand_dist = np.linalg.norm(outer_person_lhand_points - inner_person_lhand_points)\n",
    "            l_rhand_dist = np.linalg.norm(outer_person_lhand_points - inner_person_rhand_points)\n",
    "            #  right hand\n",
    "            r_face_dist = np.linalg.norm(outer_person_rhand_points - inner_person_face_points)\n",
    "            r_body_dist = np.linalg.norm(outer_person_rhand_points - inner_person_center_points)\n",
    "            r_lhand_dist = np.linalg.norm(outer_person_rhand_points - inner_person_lhand_points)\n",
    "            r_rhand_dist = np.linalg.norm(outer_person_rhand_points - inner_person_rhand_points)\n",
    "            \n",
    "            # head\n",
    "            # head oriantion in relation to others' head\n",
    "            h_pitch, h_roll, h_yaw = get_relative_orientation(outer_person_head_points, inner_person_head_points)\n",
    "            # head distances in relation to others' head\n",
    "            h_dist = np.linalg.norm(outer_person_face_points - inner_person_face_points)\n",
    "\n",
    "            synced_features.append([b_pitch, b_roll, b_yaw, b_dist, \n",
    "                                    l_face_dist, l_body_dist, l_lhand_dist,l_rhand_dist,\n",
    "                                    r_face_dist, r_body_dist, r_lhand_dist,r_rhand_dist,\n",
    "                                    h_pitch, h_roll, h_yaw, h_dist, \n",
    "                                   ])\n",
    "\n",
    "        if len(synced_features) > 0:\n",
    "            #get the min, max and avg, \n",
    "            sync_raw_featuers[this_outer_person]= np.append(np.min(synced_features, axis=0),\n",
    "                                                    np.append(np.max(synced_features, axis=0),\n",
    "                                                              np.mean(synced_features, axis=0)))\n",
    "        else:\n",
    "            sync_raw_featuers[this_outer_person]= synced_features\n",
    "\n",
    "    return sync_raw_featuers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994cc63",
   "metadata": {},
   "source": [
    "### step 1 -- extract and save low-level features (raw data --> low-level)\n",
    "- raw data are saved per frame for every one in the frame\n",
    "- wants to make low-level files one for each person\n",
    "- coloumns = low-level features\n",
    "- raws = each frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9e38e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw(points_folder, people_list):\n",
    "    fix_F17 = os.path.basename(points_folder).startswith('F17_Interaction_1')\n",
    "    files_total = len(os.listdir(points_folder))\n",
    "    all_raw_features = {}\n",
    "    all_this_frame_keypoints_3D = {}\n",
    "    all_this_frame_body_pose = {}\n",
    "    all_this_frame_head_pose = {}\n",
    "    \n",
    "    for person in people_list:\n",
    "        all_raw_features[person]=[]\n",
    "        all_this_frame_keypoints_3D[person]=[]\n",
    "        all_this_frame_body_pose[person]=[]\n",
    "        all_this_frame_head_pose[person]=[]\n",
    "    \n",
    "    # keep looping infinitely\n",
    "    for i in tqdm(range(files_total)):\n",
    "#         if i >=10:\n",
    "#             break\n",
    "        point_file = os.path.join(points_folder, '{}.npy'.format(str(i).zfill(6)))\n",
    "\n",
    "        if not os.path.exists(point_file):\n",
    "            for person in all_raw_features.keys():\n",
    "                all_raw_features[person].append([])\n",
    "            continue\n",
    "        im_res = np.load(point_file, allow_pickle=True)\n",
    "        \n",
    "        #plot BBox and name\n",
    "        this_frame_people = []\n",
    "        for human in im_res:\n",
    "            name = str(human['face_name'])\n",
    "            if not name.startswith('P'):\n",
    "                continue\n",
    "            \n",
    "            if fix_F17:\n",
    "                print('Fixing {} to {}'.format(name,'P37' if name=='P27' else name))\n",
    "                name = 'P37' if name=='P27' else name\n",
    "                \n",
    "            if name in this_frame_people:\n",
    "                continue\n",
    "            this_frame_people.append(name)\n",
    "            \n",
    "            if name not in all_raw_features.keys():\n",
    "                print('a new person named {} in {}'.format(name,points_folder))\n",
    "                all_raw_features[name] = []\n",
    "                all_this_frame_keypoints_3D[name]=[]\n",
    "                all_this_frame_body_pose[name]=[]\n",
    "                all_this_frame_head_pose[name]=[]\n",
    "            \n",
    "            # body joints\n",
    "            keypoints_3D = (human['3d_keypoints']).astype(np.float32)\n",
    "            body_pose = human['body_pose']\n",
    "            head_pose = human['head_pose']\n",
    "        \n",
    "\n",
    "            all_this_frame_keypoints_3D[name]=keypoints_3D\n",
    "            all_this_frame_body_pose[name]=body_pose\n",
    "            all_this_frame_head_pose[name]=head_pose\n",
    "            \n",
    "        sync_raw_featuers = get_sync_all(all_this_frame_keypoints_3D)\n",
    "        for this_person in all_this_frame_keypoints_3D.keys():\n",
    "            #low-level features\n",
    "            keypoints_3D = all_this_frame_keypoints_3D[this_person]\n",
    "            body_pose = all_this_frame_body_pose[this_person]\n",
    "            head_pose = all_this_frame_head_pose[this_person]\n",
    "            this_sync = sync_raw_featuers[this_person]\n",
    "            raw_features = np.append(body_pose, \n",
    "                                     np.append(body_sync_one(keypoints_3D),\n",
    "                                     np.append(head_pose, this_sync)))\n",
    "\n",
    "            all_raw_features[this_person].append(raw_features)\n",
    "            \n",
    "    return all_raw_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc2d791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed: /home/sharifa/speedDating/raw_features/F10_Interaction_1_P27_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F11_Interaction_1_P29_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F11_Interaction_2_P29_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F13_Interaction_1_P32_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F17_Interaction_1_P37_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F17_Interaction_2_P37_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F1_Interaction_1_P2_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F1_Interaction_2_P2_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F2_Interaction_1_P4_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F2_Interaction_2_P4_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F3_Interaction_1_P8_low_level_extra.csv\n",
      "Already processed: /home/sharifa/speedDating/raw_features/F3_Interaction_2_P6_low_level_extra.csv\n",
      "Processing: F4_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 31808/31808 [07:09<00:00, 74.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F4_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                       | 2898/31823 [00:28<04:54, 98.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a new person named P14 in /home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/F4_Interaction_2.mp4/F4_Interaction_2_frame-json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 31823/31823 [07:03<00:00, 75.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F5_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:55<00:00, 571.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F5_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:55<00:00, 573.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F6_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31823/31823 [01:52<00:00, 283.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F6_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31808/31808 [01:55<00:00, 276.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F7_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31809/31809 [03:15<00:00, 163.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F8_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:55<00:00, 572.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F8_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:55<00:00, 573.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F8_Interaction_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:55<00:00, 569.95it/s]\n"
     ]
    }
   ],
   "source": [
    "person_order = {\n",
    "    'F1_Interaction_1.mp4':{'P2':'older girl','P1':'younger girl','P3':'mother'},\n",
    "    'F1_Interaction_2.mp4':{'P2':'older girl','P1':'younger girl','P3':'mother'},\n",
    "\n",
    "    'F2_Interaction_1.mp4':{'P4':'boy','P5':'father'},\n",
    "    'F2_Interaction_2.mp4':{'P4':'boy'},\n",
    "\n",
    "    'F3_Interaction_1.mp4':{'P8':'father','P6':'girl','P7':'boy'},\n",
    "    'F3_Interaction_2.mp4':{'P6':'girl','P7':'boy'},\n",
    "\n",
    "    'F4_Interaction_1.mp4':{'P14':'mother','P12':'older girl','P11':'younger girl','P10':'older boy','P9':'younger boy','P13':'father'},\n",
    "    'F4_Interaction_2.mp4':{'P12':'older girl','P11':'younger girl','P10':'older boy','P9':'younger boy','P13':'father'},\n",
    "\n",
    "    'F5_Interaction_1.mp4':{'P16':'mother','P15':'boy'},\n",
    "    'F5_Interaction_2.mp4':{'P16':'mother','P15':'boy'},\n",
    "\n",
    "    'F6_Interaction_1.mp4':{'P19':'father','P18':'girl','P17':'boy'},\n",
    "    'F6_Interaction_2.mp4':{'P19':'father','P18':'girl','P17':'boy'},\n",
    "\n",
    "    'F7_Interaction_1.mp4':{'P22':'father','P20':'younger boy','P21':'older boy','P23':'mother'},\n",
    "\n",
    "    'F8_Interaction_1.mp4':{'P24':'girl','P25':'father'},\n",
    "    'F8_Interaction_2.mp4':{'P24':'girl','P25':'father'},\n",
    "    'F8_Interaction_3.mp4':{'P24':'girl','P25':'father'},\n",
    "\n",
    "    'F10_Interaction_1.mp4': {'P27':'left girl (green top)', 'P28':'right girl (white top)'},\n",
    "\n",
    "    'F11_Interaction_1.mp4': {'P29':'boy', 'P30':'mother'},\n",
    "    'F11_Interaction_2.mp4':{'P29':'boy','P30':'mother'},\n",
    "\n",
    "    'F13_Interaction_1.mp4':{'P32':'girl','P33':'mother'},\n",
    "\n",
    "    'F17_Interaction_1.mp4': {'P37':'girl', 'P38':'mother'},\n",
    "    'F17_Interaction_2.mp4':{'P37':'girl','P38':'mother'}\n",
    "}\n",
    "\n",
    "\n",
    "low_csv_path = os.path.join(base_path,'raw_features/')\n",
    "    \n",
    "onlyfolders = [os.path.join(raw_features_path, f) for f in os.listdir(raw_features_path) if not\n",
    "                  os.path.isfile(os.path.join(raw_features_path, f)) and f.startswith('F')]\n",
    "onlyfolders.sort()\n",
    "\n",
    "for folder in onlyfolders:\n",
    "    save_folder = os.path.basename(folder).split('.')[0]\n",
    "    people_list = list(person_order[save_folder+'.mp4'].keys())\n",
    "    \n",
    "    person = people_list[0]\n",
    "    low_csv_file = os.path.join(low_csv_path,'_'.join([save_folder,person,'low_level','extra'])+'.csv')\n",
    "    if os.path.exists(low_csv_file):\n",
    "        print('Already processed:',low_csv_file)\n",
    "        continue\n",
    "    \n",
    "    readingpath = os.path.join(raw_features_path,\n",
    "                              '{}.mp4'.format(save_folder),\n",
    "                              '{}_frame-json'.format(save_folder))\n",
    "\n",
    "    print('Processing:',save_folder)\n",
    "    #print(people_list)\n",
    "    \n",
    "    #extract low-level for this folder for all people \n",
    "    this_group_low_level = extract_raw(readingpath,people_list)\n",
    "    \n",
    "    for this_person in this_group_low_level.keys():\n",
    "        low_data = this_group_low_level[this_person]\n",
    "        \n",
    "        #save low-level features for each person \n",
    "        low_csv_file = os.path.join(low_csv_path,'_'.join([save_folder,this_person,'low_level','extra'])+'.csv')\n",
    "        low_header = body_get_headers() + head_get_headers() + sync_get_headers()\n",
    "        \n",
    "        #np.savetxt(low_csv_file, low_data, delimiter=',', header=low_header)\n",
    "        low_data_df = pd.DataFrame(low_data)\n",
    "        low_data_df.to_csv(low_csv_file, header=low_header, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a35812a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:10<00:00, 3179.89it/s]\n"
     ]
    }
   ],
   "source": [
    "### in F17_1, P37 was mistikanely named as P27 this is to fix this\n",
    "# def extract_raw_f17(points_folder, people_list):\n",
    "#     files_total = len(os.listdir(points_folder))\n",
    "#     all_raw_features = {}\n",
    "#     for person in people_list:\n",
    "#         all_raw_features[person]=[]\n",
    "    \n",
    "#     # keep looping infinitely\n",
    "#     for i in tqdm(range(files_total)):\n",
    "# #         if i >=10:\n",
    "# #             break\n",
    "#         point_file = os.path.join(points_folder, '{}.npy'.format(str(i).zfill(6)))\n",
    "\n",
    "#         if not os.path.exists(point_file):\n",
    "#             for person in all_raw_features.keys():\n",
    "#                 all_raw_features[person].append([])\n",
    "#             continue\n",
    "#         im_res = np.load(point_file, allow_pickle=True)\n",
    "        \n",
    "#         #plot BBox and name\n",
    "#         this_frame_people = []\n",
    "#         for human in im_res:\n",
    "#             name = str(human['face_name'])\n",
    "#             if not name.startswith('P'):\n",
    "#                 continue\n",
    "#             if name in this_frame_people:\n",
    "#                 continue\n",
    "#             name = 'P37' if name=='P27' else name\n",
    "#             this_frame_people.append(name)\n",
    "            \n",
    "#             if name not in all_raw_features.keys():\n",
    "#                 print('a new person named {} in {}'.format(name,points_folder))\n",
    "#                 all_raw_features[name] = []\n",
    "            \n",
    "#             # body joints\n",
    "#             keypoints_3D = (human['3d_keypoints']).astype(np.float32)\n",
    "#             body_pose = human['body_pose']\n",
    "#             head_pose = human['head_pose']\n",
    "\n",
    "#             #low-level features\n",
    "#             raw_features = np.append(body_pose, np.append(body_sync_one(keypoints_3D),head_pose))\n",
    "\n",
    "#             all_raw_features[name].append(raw_features)\n",
    "#     return all_raw_features\n",
    "\n",
    "# save_folder = 'F17_Interaction_1'\n",
    "# people_list = list(person_order[save_folder+'.mp4'].keys())\n",
    "# readingpath = '/home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/F17_Interaction_1.mp4/F17_Interaction_1_frame-json'\n",
    "\n",
    "\n",
    "# this_group_low_level = extract_raw_f17(readingpath,people_list)\n",
    "\n",
    "# for this_person in this_group_low_level.keys():\n",
    "#     low_data = this_group_low_level[this_person]\n",
    "\n",
    "#     #save low-level features for each person \n",
    "#     low_csv_file = os.path.join(low_csv_path,'_'.join([save_folder,this_person,'low_level'])+'.csv')\n",
    "#     low_header = body_get_headers() + head_get_headers()\n",
    "#     #np.savetxt(low_csv_file, low_data, delimiter=',', header=low_header)\n",
    "#     low_data_df = pd.DataFrame(low_data)\n",
    "#     #print(low_data_df)\n",
    "#     low_data_df.to_csv(low_csv_file, header=low_header, index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd9b42",
   "metadata": {},
   "source": [
    "### step 2 -- extract and save high-level features (low-level --> high-level)\n",
    "- low-level features are merged for every x frames (explained above)\n",
    "- temporal features are extarcted for that window size and saved per person \n",
    "\n",
    "- coloumns = high-level features\n",
    "- raws = temporal features every x frame \n",
    "- saved in 3 variations:  64 frames (~2.5s), 64*2 (~5s) and 5*30(=5s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cf0091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def statstic_features(all_features, window_size):\n",
    "    all_features = np.array(all_features)\n",
    "    epsilon = np.float32(0.00001)\n",
    "    all_stats = np.array([])\n",
    "    #for each window size in rows \n",
    "    total_rows = all_features.shape[0]\n",
    "    total_cols = all_features.shape[1]\n",
    "    for this_step in range(0,total_rows,window_size):\n",
    "        end_win = window_size if this_step+window_size < total_rows else total_rows\n",
    "        this_sub_data = all_features[this_step:this_step+end_win,:]\n",
    "        if len(this_sub_data) <3:\n",
    "            print('less than 3 rows')\n",
    "            continue\n",
    "        \n",
    "        #for each feature/column\n",
    "        for ff in range(total_cols):\n",
    "            this_feature = this_sub_data[:,ff]\n",
    "\n",
    "            #find and remove outliers\n",
    "            this_feature = grubbs.test(this_feature, alpha=0.05)\n",
    "            #de-noise: smooth the signal - median filter\n",
    "            this_feature = medfilt(this_feature)\n",
    "\n",
    "            #extract the deltas\n",
    "            delta1_this_feature = np.append(this_feature[0], np.diff(this_feature))\n",
    "            delta2_this_feature = np.append(delta1_this_feature[0], np.diff(delta1_this_feature))\n",
    "\n",
    "            # extract stats\n",
    "            f_min = min(this_feature)\n",
    "            d1_min = min(delta1_this_feature)\n",
    "            d2_min = min(delta2_this_feature)\n",
    "\n",
    "            f_max = max(this_feature)\n",
    "            d1_max = max(delta1_this_feature)\n",
    "            d2_max = max(delta2_this_feature)\n",
    "\n",
    "            f_rang = f_max - f_min\n",
    "            d1_rang = d1_max - d1_min\n",
    "            d2_rang = d2_max - d2_min\n",
    "\n",
    "            f_mean = mean(this_feature)\n",
    "            try:\n",
    "                d1_mean = mean(delta1_this_feature)\n",
    "                d2_mean = mean(delta2_this_feature)\n",
    "            except:\n",
    "                print(\"SAD\")\n",
    "                print(delta1_this_feature)\n",
    "\n",
    "            f_std = stdev(this_feature)\n",
    "            d1_std = stdev(delta1_this_feature)\n",
    "            d2_std = stdev(delta2_this_feature)\n",
    "\n",
    "            f_var = variance(this_feature)\n",
    "            d1_var = variance(delta1_this_feature)\n",
    "            d2_var= variance(delta2_this_feature)\n",
    "\n",
    "            #extarct skewness and kurtosis\n",
    "            f_skew = skew(this_feature)\n",
    "            d1_skew = skew(delta1_this_feature)\n",
    "            d2_skew= skew(delta2_this_feature)\n",
    "\n",
    "            f_kurt = kurtosis(this_feature)\n",
    "            d1_kurt = kurtosis(delta1_this_feature)\n",
    "            d2_kurt= kurtosis(delta2_this_feature)\n",
    "\n",
    "            #extract peaks and valys\n",
    "\n",
    "            try:\n",
    "                test = (1 /delta1_this_feature)\n",
    "            except:\n",
    "                for i in range(len(delta1_this_feature)):\n",
    "                    if delta1_this_feature[i] == 0.0:\n",
    "                        delta1_this_feature[i] = epsilon\n",
    "\n",
    "\n",
    "            f_peaks = len(find_peaks(this_feature)[0])\n",
    "            d1_peaks = len(find_peaks(delta1_this_feature)[0])\n",
    "            d2_peaks = len(find_peaks(delta2_this_feature)[0])\n",
    "\n",
    "            f_valys = len(find_peaks(1 /this_feature)[0])\n",
    "            d1_valys = len(find_peaks(1 /delta1_this_feature)[0])\n",
    "            d2_valys = len(find_peaks(1 /delta2_this_feature)[0])\n",
    "\n",
    "            f_stats = np.array([f_min, f_max, f_rang, f_mean, f_std, f_var, f_skew, f_kurt, f_peaks, f_valys,\n",
    "                         d1_min, d1_max, d1_rang, d1_mean, d1_std, d1_var, d1_skew, d1_kurt, d1_peaks, d1_valys,\n",
    "                         d2_min, d2_max, d2_rang, d2_mean, d2_std, d2_var, d2_skew, d2_kurt, d2_peaks, d2_valys])\n",
    "\n",
    "            if ff == 0:\n",
    "                stats = f_stats\n",
    "            else:\n",
    "                stats = np.append(stats, f_stats, axis=0)\n",
    "        if len(all_stats) == 0:\n",
    "            all_stats = stats\n",
    "        else:\n",
    "            all_stats = np.vstack((all_stats,stats))\n",
    "    return all_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5d448",
   "metadata": {},
   "source": [
    "### loop through all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d000275d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F10_Interaction_1_P27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11844/3479857901.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  test = (1 /delta1_this_feature)\n",
      "/tmp/ipykernel_11844/3479857901.py:80: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f_valys = len(find_peaks(1 /this_feature)[0])\n",
      "/tmp/ipykernel_11844/3479857901.py:81: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  d1_valys = len(find_peaks(1 /delta1_this_feature)[0])\n",
      "/tmp/ipykernel_11844/3479857901.py:82: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  d2_valys = len(find_peaks(1 /delta2_this_feature)[0])\n",
      "/home/sharifa/engagement_modeling/eng_env/lib/python3.8/site-packages/outliers/smirnov_grubbs.py:105: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  g = value / data.std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F10_Interaction_1_P28\n",
      "Processing: F11_Interaction_1_P29\n",
      "Processing: F11_Interaction_1_P30\n",
      "Processing: F11_Interaction_2_P29\n",
      "Processing: F11_Interaction_2_P30\n",
      "Processing: F13_Interaction_1_P32\n",
      "Processing: F13_Interaction_1_P33\n",
      "Processing: F17_Interaction_1_P37\n",
      "Processing: F17_Interaction_1_P38\n",
      "Processing: F17_Interaction_2_P37\n",
      "Processing: F17_Interaction_2_P38\n",
      "Processing: F1_Interaction_1_P1\n",
      "Processing: F1_Interaction_1_P2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharifa/engagement_modeling/eng_env/lib/python3.8/site-packages/scipy/signal/signaltools.py:1531: UserWarning: kernel_size exceeds volume extent: the volume will be zero-padded.\n",
      "  warnings.warn('kernel_size exceeds volume extent: the volume will be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F1_Interaction_1_P3\n",
      "Processing: F1_Interaction_2_P1\n",
      "Processing: F1_Interaction_2_P2\n",
      "Processing: F1_Interaction_2_P3\n",
      "Processing: F2_Interaction_1_P4\n",
      "Processing: F2_Interaction_1_P5\n",
      "Processing: F2_Interaction_2_P4\n",
      "Processing: F2_Interaction_2_P5\n",
      "Processing: F3_Interaction_1_P6\n",
      "less than 3 rows\n",
      "Processing: F3_Interaction_1_P7\n",
      "less than 3 rows\n",
      "Processing: F3_Interaction_1_P8\n",
      "less than 3 rows\n",
      "Processing: F3_Interaction_2_P6\n",
      "Processing: F3_Interaction_2_P7\n",
      "Processing: F4_Interaction_1_P10\n",
      "Processing: F4_Interaction_1_P11\n",
      "Processing: F4_Interaction_1_P12\n",
      "Processing: F4_Interaction_1_P13\n",
      "Processing: F4_Interaction_1_P14\n",
      "Processing: F4_Interaction_1_P9\n",
      "Processing: F4_Interaction_2_P10\n",
      "Processing: F4_Interaction_2_P11\n",
      "Processing: F4_Interaction_2_P12\n",
      "Processing: F4_Interaction_2_P13\n",
      "Processing: F4_Interaction_2_P14\n",
      "Processing: F4_Interaction_2_P9\n",
      "Processing: F5_Interaction_1_P15\n",
      "Processing: F5_Interaction_1_P16\n",
      "Processing: F5_Interaction_2_P15\n",
      "Processing: F5_Interaction_2_P16\n",
      "Processing: F6_Interaction_1_P17\n",
      "Processing: F6_Interaction_1_P18\n",
      "Processing: F6_Interaction_1_P19\n",
      "Processing: F6_Interaction_2_P17\n",
      "Processing: F6_Interaction_2_P18\n",
      "Processing: F6_Interaction_2_P19\n",
      "Processing: F7_Interaction_1_P20\n",
      "less than 3 rows\n",
      "Processing: F7_Interaction_1_P21\n",
      "less than 3 rows\n",
      "Processing: F7_Interaction_1_P22\n",
      "less than 3 rows\n",
      "Processing: F7_Interaction_1_P23\n",
      "less than 3 rows\n",
      "Processing: F8_Interaction_1_P24\n",
      "Processing: F8_Interaction_1_P25\n",
      "Processing: F8_Interaction_2_P24\n",
      "Processing: F8_Interaction_2_P25\n",
      "Processing: F8_Interaction_3_P24\n",
      "Processing: F8_Interaction_3_P25\n"
     ]
    }
   ],
   "source": [
    "window_frames = [64, 64*2, 5*30]\n",
    "window_names = ['2.5','5','5s']\n",
    "\n",
    "low_csv_path = os.path.join(base_path,'raw_features/')\n",
    "only_low_csv_files = [os.path.join(low_csv_path, f) for f in os.listdir(low_csv_path) if \n",
    "                  os.path.isfile(os.path.join(low_csv_path, f)) and f.startswith('F')\n",
    "                     and f.endswith('_low_level_extra.csv')]\n",
    "only_low_csv_files.sort()\n",
    "\n",
    "for low_csv_file in only_low_csv_files:\n",
    "    save_file = os.path.basename(low_csv_file).replace('_low_level_extra.csv','')\n",
    "    print('Processing:',save_file)\n",
    "    \n",
    "    low_level_df = pd.read_csv(low_csv_file)\n",
    "    low_level_data = np.nan_to_num(low_level_df.values)\n",
    "    \n",
    "    for i in range(len(window_frames)):\n",
    "        window_size = window_frames[i]\n",
    "        window_name = window_names[i]\n",
    "    \n",
    "        high_npy_path = os.path.join('./features','handcrafted_extra_features_' + window_name)\n",
    "        os.makedirs(high_npy_path, exist_ok = True)\n",
    "        \n",
    "        high_npy_file = os.path.join(high_npy_path,'_'.join([save_file,'high_level'])+ '.npy')\n",
    "        if os.path.exists(high_npy_file):\n",
    "            print('Already Processed:{}-{}'.format(window_name,high_npy_file))\n",
    "            continue\n",
    "\n",
    "        #extarct high-level for each person/file \n",
    "        high_data = statstic_features(low_level_data, window_size)\n",
    "\n",
    "        #save high-level features for each person/file \n",
    "        np.save(high_npy_file, high_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e27653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
