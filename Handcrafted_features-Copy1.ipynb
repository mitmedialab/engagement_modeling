{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9b1868",
   "metadata": {},
   "source": [
    "# Extarct handcrafted features \n",
    "- for each person, for x frames, calculate the nonverbal features from head and body landmarks \n",
    "- the x frames are: 64 frames (\\~2.5s), 64\\*2 (\\~5s) and 5*30(=5s)\n",
    "- the first two are to be compared with the deep features, the last is for the actual labeling \n",
    "\n",
    "- raw data --> low-level --> high-level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cbe40",
   "metadata": {},
   "source": [
    "### imports and vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ed156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "raw_features_path = '/home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146362c",
   "metadata": {},
   "source": [
    "### help functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MidHip = 0\n",
    "RHip = 1\n",
    "RKnee = 2\n",
    "RAnkle = 3\n",
    "LHip = 4\n",
    "LKnee = 5\n",
    "LAnkle = 6\n",
    "MidBack = 7\n",
    "Neck = 8\n",
    "Nose = 9\n",
    "forehead =10\n",
    "LShoulder = 11\n",
    "LElbow = 12\n",
    "LWrist = 13\n",
    "RShoulder = 14\n",
    "RElbow = 15\n",
    "RWrist = 16\n",
    "\n",
    "def body_get_headers():\n",
    "    body_features_heads =['parent_body_pitch', 'parent_body_roll', 'parent_body_yaw',\n",
    "                          'child_body_pitch', 'child_body_roll', 'child_body_yaw',\n",
    "                          'both_body_pitch', 'both_body_roll', 'both_body_yaw',\n",
    "                         'both_body_dist', 'childlhand_childface', 'childlhand_parentface', 'parentlhand_childface',\n",
    "                         'parentlhand_parentface', 'childrhand_childface', 'childrhand_parentface', 'parentrhand_childface',\n",
    "                         'parentrhand_parentface', 'childlhand_childbody', 'childlhand_parentbody', 'parentlhand_childbody',\n",
    "                         'parentlhand_parentbody', 'childrhand_childbody', 'childrhand_parentbody', 'parentrhand_childbody',\n",
    "                         'parentrhand_parentbody', 'childlhand_childrhand', 'parentlhand_parentrhand', 'childlhand_parentlhand',\n",
    "                         'childlhand_parentrhand', 'childrhand_parentlhand', 'childrhand_parentrhand']\n",
    "    return body_features_heads\n",
    "\n",
    "\n",
    "\n",
    "def head_get_headers():\n",
    "    head_features_heads = ['parent_pitch', 'parent_roll', 'parent_yaw', 'child_pitch', 'child_roll', 'child_yaw', 'head_distances', 'gazes_pitch', 'gazes_roll', 'gazes_yaw']\n",
    "\n",
    "    return head_features_heads\n",
    "\n",
    "def get_stat_headers(features_heads):\n",
    "    # return stat_features\n",
    "    stats_features = ['f_min', 'f_max', 'f_rang', 'f_mean', 'f_std', 'f_var', 'f_skew', 'f_kurt', 'f_peaks', 'f_valys',\n",
    "                         'd1_min', 'd1_max', 'd1_rang', 'd1_mean', 'd1_std', 'd1_var', 'd1_skew', 'd1_kurt', 'd1_peaks', 'd1_valys',\n",
    "                         'd2_min', 'd2_max', 'd2_rang', 'd2_mean', 'd2_std', 'd2_var', 'd2_skew', 'd2_kurt', 'd2_peaks', 'd2_valys']\n",
    "\n",
    "    high_feature_headers = []\n",
    "    for i in range(len(features_heads)):\n",
    "        for j in range(len(stats_features)):\n",
    "            high_feature_headers.append(features_heads[i] + '-' + stats_features[j])\n",
    "\n",
    "    return high_feature_headers\n",
    "\n",
    "\n",
    "\n",
    "def chest_pose(chest_points, size):\n",
    "    # Camera internals\n",
    "    focal_length = size[1]\n",
    "    center = (size[1] / 2, size[0] / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n",
    "    d2_points = np.float64(chest_points[:, 0:2])\n",
    "\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(chest_points, d2_points, camera_matrix, dist_coeffs)\n",
    "    # flags=cv2.cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    return rotation_vector\n",
    "\n",
    "\n",
    "def head_pose(face_3d, size):\n",
    "\n",
    "    # Camera internals\n",
    "    focal_length = size[1]\n",
    "    center = (size[1] / 2, size[0] / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n",
    "    d2_points = np.float64(face_3d[:, 0:2])\n",
    "    rvec = np.zeros(3, dtype=np.float)\n",
    "    tvec = np.array([0, 0, 1], dtype=np.float)\n",
    "\n",
    "    (success, rotation_vector, translation_vector) =\\\n",
    "        cv2.solvePnP(face_3d, d2_points, camera_matrix, dist_coeffs,\\\n",
    "                     rvec, tvec, useExtrinsicGuess=True, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    return rotation_vector\n",
    "\n",
    "\n",
    "def body_sync(parent_body, child_body, frame_size):\n",
    "    body_features = []\n",
    "\n",
    "    if len(parent_body) == 0 or len(child_body) == 0:\n",
    "        #print(\"no parent and/or child were detected\")\n",
    "        return body_features\n",
    "\n",
    "    parent_chest = np.array([parent_body[Neck], parent_body[RShoulder], parent_body[LShoulder], parent_body[MidHip]])\n",
    "    child_chest = np.array([child_body[Neck], child_body[RShoulder], child_body[LShoulder], child_body[MidHip]])\n",
    "\n",
    "    p_rot = chest_pose(parent_chest, frame_size)\n",
    "    pb_pitch, pb_roll, pb_yaw = p_rot[0][0], p_rot[1][0], p_rot[1][0]\n",
    "\n",
    "    c_rot = chest_pose(child_body, frame_size)\n",
    "    cb_pitch, cb_roll, cb_yaw = c_rot[0][0], c_rot[1][0], c_rot[1][0]\n",
    "\n",
    "    ret_R, ret_t = rigid_transform_3D(np.mat(parent_chest), np.mat(child_chest))\n",
    "\n",
    "    b_pitch, b_roll, b_yaw = 0, 0, 0\n",
    "    euler_angles = euler_from_matrix(ret_R)\n",
    "    if euler_angles:\n",
    "        #print('THEY SHOULD BE LOOKING AT EACH OTHER')\n",
    "        b_pitch, b_roll, b_yaw = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "\n",
    "    p_nose, p_center, p_rhand, p_lhand = None, None, None, None\n",
    "    c_nose, c_center, c_rhand, c_lhand = None, None, None, None\n",
    "\n",
    "    # if parent_body[0][0] != 0.0 and parent_body[0][1] != 0.0 and parent_body[0][2] != 0.0:\n",
    "    p_nose = parent_body[Nose]\n",
    "    # if parent_body[1][0] != 0.0 and parent_body[1][1] != 0.0 and parent_body[1][2] != 0.0:\n",
    "    p_center = parent_body[Neck]\n",
    "    # if parent_body[4][0] != 0.0 and parent_body[4][1] != 0.0 and parent_body[4][2] != 0.0:\n",
    "    p_rhand = parent_body[RWrist]\n",
    "    # if parent_body[7][0] != 0.0 and parent_body[7][1] != 0.0 and parent_body[7][2] != 0.0:\n",
    "    p_lhand = parent_body[LWrist]\n",
    "\n",
    "    # if child_body[0][0] != 0.0 and child_body[0][1] != 0.0 and child_body[0][2] != 0.0:\n",
    "    c_nose = child_body[Nose]\n",
    "    # if child_body[1][0] != 0.0 and child_body[1][1] != 0.0 and child_body[1][2] != 0.0:\n",
    "    c_center = child_body[Neck]\n",
    "    # if child_body[4][0] != 0.0 and child_body[4][1] != 0.0 and child_body[4][2] != 0.0:\n",
    "    c_rhand = child_body[RWrist]\n",
    "    # if child_body[7][0] != 0.0 and child_body[7][1] != 0.0 and child_body[7][2] != 0.0:\n",
    "    c_lhand = child_body[LWrist]\n",
    "\n",
    "    b_dist = None\n",
    "    parentlhand_parentface, parentrhand_parentface, childlhand_parentface, childrhand_parentface = None, None, None, None\n",
    "    parentlhand_childface, parentrhand_childface, childlhand_childface, childrhand_childface = None, None, None, None\n",
    "    parentlhand_parentbody, parentrhand_parentbody, childlhand_parentbody, childrhand_parentbody = None, None, None, None\n",
    "    parentlhand_childbody, parentrhand_childbody, childlhand_childbody, childrhand_childbody = None, None, None, None\n",
    "    childlhand_childrhand, parentlhand_parentrhand, childlhand_parentlhand, childlhand_parentrhand, childrhand_parentlhand, childrhand_parentrhand = None, None, None, None, None, None\n",
    "\n",
    "    if type(p_center) != type(None) and type(c_center) != type(None):\n",
    "        b_dist = np.linalg.norm(p_center - c_center)\n",
    "\n",
    "    if type(p_nose) != type(None):\n",
    "        if type(p_lhand) != type(None):\n",
    "            parentlhand_parentface = np.linalg.norm(p_lhand - p_nose)\n",
    "        if type(p_rhand) != type(None):\n",
    "            parentrhand_parentface = np.linalg.norm(p_rhand - p_nose)\n",
    "        if type(c_lhand) != type(None):\n",
    "            childlhand_parentface = np.linalg.norm(c_lhand - p_nose)\n",
    "        if type(c_rhand) != type(None):\n",
    "            childrhand_parentface = np.linalg.norm(c_rhand - p_nose)\n",
    "\n",
    "    if type(c_nose) != type(None):\n",
    "        if type(p_lhand) != type(None):\n",
    "            parentlhand_childface = np.linalg.norm(p_lhand - c_nose)\n",
    "        if type(p_rhand) != type(None):\n",
    "            parentrhand_childface = np.linalg.norm(p_rhand - c_nose)\n",
    "        if type(c_lhand) != type(None):\n",
    "            childlhand_childface = np.linalg.norm(c_lhand - c_nose)\n",
    "        if type(c_rhand) != type(None):\n",
    "            childrhand_childface = np.linalg.norm(c_rhand - c_nose)\n",
    "\n",
    "    if type(p_center) != type(None):\n",
    "        if type(p_lhand) != type(None):\n",
    "            parentlhand_parentbody = np.linalg.norm(p_lhand - p_center)\n",
    "        if type(p_rhand) != type(None):\n",
    "            parentrhand_parentbody = np.linalg.norm(p_rhand - p_center)\n",
    "        if type(c_lhand) != type(None):\n",
    "            childlhand_parentbody = np.linalg.norm(c_lhand - p_center)\n",
    "        if type(c_rhand) != type(None):\n",
    "            childrhand_parentbody = np.linalg.norm(c_rhand - p_center)\n",
    "\n",
    "    if type(c_center) != type(None):\n",
    "        if type(p_lhand) != type(None):\n",
    "            parentlhand_childbody = np.linalg.norm(p_lhand - c_center)\n",
    "        if type(p_rhand) != type(None):\n",
    "            parentrhand_childbody = np.linalg.norm(p_rhand - c_center)\n",
    "        if type(c_lhand) != type(None):\n",
    "            childlhand_childbody = np.linalg.norm(c_lhand - c_center)\n",
    "        if type(c_rhand) != type(None):\n",
    "            childrhand_childbody = np.linalg.norm(c_rhand - c_center)\n",
    "\n",
    "    if type(p_lhand) != type(None):\n",
    "        if type(p_rhand) != type(None):\n",
    "            parentlhand_parentrhand = np.linalg.norm(p_lhand - p_rhand)\n",
    "        if type(c_lhand) != type(None):\n",
    "            childlhand_parentlhand = np.linalg.norm(c_lhand - p_lhand)\n",
    "        if type(c_rhand) != type(None):\n",
    "            childrhand_parentlhand = np.linalg.norm(c_rhand - p_lhand)\n",
    "\n",
    "    if type(c_lhand) != type(None):\n",
    "        if type(p_rhand) != type(None):\n",
    "            childlhand_parentrhand = np.linalg.norm(c_lhand - p_rhand)\n",
    "        if type(c_rhand) != type(None):\n",
    "            childlhand_childrhand = np.linalg.norm(c_lhand - c_rhand)\n",
    "\n",
    "    if type(p_rhand) != type(None) and type(c_rhand) != type(None):\n",
    "        childrhand_parentrhand = np.linalg.norm(c_rhand - p_rhand)\n",
    "\n",
    "    body_features = [pb_pitch, pb_roll, pb_yaw, cb_pitch, cb_roll, cb_yaw, b_pitch, b_roll, b_yaw,\n",
    "                     b_dist, childlhand_childface, childlhand_parentface, parentlhand_childface,\n",
    "                     parentlhand_parentface, childrhand_childface, childrhand_parentface, parentrhand_childface,\n",
    "                     parentrhand_parentface, childlhand_childbody, childlhand_parentbody, parentlhand_childbody,\n",
    "                     parentlhand_parentbody, childrhand_childbody, childrhand_parentbody, parentrhand_childbody,\n",
    "                     parentrhand_parentbody, childlhand_childrhand, parentlhand_parentrhand, childlhand_parentlhand,\n",
    "                     childlhand_parentrhand, childrhand_parentlhand, childrhand_parentrhand]\n",
    "\n",
    "    return body_features\n",
    "\n",
    "\n",
    "def head_sync(parent_body, child_body, frame_size):\n",
    "    head_features = []\n",
    "\n",
    "    parent_face = np.array([parent_body[forehead],parent_body[Nose],parent_body[Neck]])\n",
    "    child_face = np.array([child_body[forehead],child_body[Nose],child_body[Neck]])\n",
    "\n",
    "    if len(parent_face) == 0 or len(child_face) == 0:\n",
    "        # print(\"no parent or child were detected\")\n",
    "        return head_features\n",
    "    # print(pose_3d.shape)\n",
    "\n",
    "    # set the parent face and the child face based on location\n",
    "\n",
    "    nose = 1\n",
    "    x_axes = 0\n",
    "\n",
    "    # print(parent_face, child_face)\n",
    "\n",
    "    # extract feature: pitch, roll, yaw for each head\n",
    "    # parent head relative to origin\n",
    "    p_rot = head_pose(parent_face, frame_size)\n",
    "    p_pitch, p_roll, p_yaw = p_rot[0], p_rot[1], p_rot[1]\n",
    "    # child head relative to origin\n",
    "    c_rot = head_pose(child_face, frame_size)\n",
    "    c_pitch, c_roll, c_yaw = c_rot[0], c_rot[1], c_rot[1]\n",
    "\n",
    "    # extract distances between the two heads\n",
    "    dist = np.linalg.norm(parent_face[nose] - child_face[nose])\n",
    "\n",
    "    # print(dist)\n",
    "\n",
    "    # extract gaze rotation between the two heads\n",
    "    ret_R, ret_t = rigid_transform_3D(np.mat(parent_face), np.mat(child_face))\n",
    "\n",
    "    euler_angles = euler_from_matrix(ret_R)\n",
    "\n",
    "    g_pitch, g_roll, g_yaw = 0, 0, 0\n",
    "    if euler_angles:\n",
    "        g_pitch, g_roll, g_yaw = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "\n",
    "    head_features = [p_pitch, p_roll, p_yaw, c_pitch, c_roll, c_yaw, dist, g_pitch, g_roll, g_yaw]\n",
    "    return head_features\n",
    "\n",
    "\n",
    "def extract_raw(family, sess, video_file, csv_path, csv_file):\n",
    "    points_folder = os.path.join(conf.points_path_3D, family, sess, '{}_{}_mainvid.mp4'.format(family, sess),\n",
    "                                 '{}_{}_mainvid_frame-json'.format(family, sess))\n",
    "    files_total = len(os.listdir(points_folder))\n",
    "    all_raw_body = []\n",
    "    all_raw_head = []\n",
    "    # keep looping infinitely\n",
    "    # for i in tqdm(count()):\n",
    "    for i in tqdm(range(files_total)):\n",
    "        # if i >=100:\n",
    "        #     break\n",
    "        point_file = os.path.join(points_folder, '{}.npy'.format(str(i).zfill(6)))\n",
    "\n",
    "        if not os.path.exists(point_file):\n",
    "            all_raw_body.append([])\n",
    "            all_raw_head.append([])\n",
    "            continue\n",
    "        im_res = np.load(point_file, allow_pickle=True)\n",
    "        #plot BBox and name\n",
    "        parent_body, child_body = [], []\n",
    "        for human in im_res:\n",
    "            # body joints\n",
    "            joint3D_item = human['3d_keypoints']\n",
    "            if human['face_name'] == 'parent':\n",
    "                parent_body = joint3D_item\n",
    "            elif human['face_name'] == 'child':\n",
    "                child_body = joint3D_item\n",
    "\n",
    "        if len(parent_body) ==0 or len(child_body) == 0:\n",
    "            all_raw_body.append([])\n",
    "            all_raw_head.append([])\n",
    "            continue\n",
    "\n",
    "        #sync features\n",
    "        frame_size = (640 , 480)\n",
    "        raw_body = body_sync(parent_body, child_body, frame_size)\n",
    "        raw_head = head_sync(parent_body, child_body, frame_size)\n",
    "\n",
    "        all_raw_body.append(raw_body)\n",
    "        all_raw_head.append(raw_head)\n",
    "\n",
    "    #save the csv with header\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(all_raw_body)\n",
    "    df.columns = body_get_headers()\n",
    "    csv_file_body = 'Body_'+csv_file\n",
    "    df.to_csv(os.path.join(csv_path,csv_file_body),header=True,index=False)\n",
    "\n",
    "    #head file\n",
    "    df = pd.DataFrame(all_raw_head)\n",
    "    df.columns = head_get_headers()\n",
    "    csv_file_head = 'Head_'+csv_file\n",
    "    df.to_csv(os.path.join(csv_path,csv_file_head),header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994cc63",
   "metadata": {},
   "source": [
    "### step 1 -- extract and save low-level features (raw data --> low-level)\n",
    "- raw data are saved per frame for every one in the frame\n",
    "- wants to make low-level files one for each person\n",
    "- coloumns = low-level features\n",
    "- raws = each frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    read_folder = conf.video_path\n",
    "    family_folders = [f for f in os.listdir(read_folder) if f.startswith('p')]\n",
    "    family_folders.sort()\n",
    "\n",
    "    for family in family_folders:\n",
    "        family_fol_read = read_folder + family + '/'\n",
    "        session_folders = [f for f in os.listdir(family_fol_read) if f.startswith('s')]\n",
    "        session_folders.sort()\n",
    "        for sess in session_folders:\n",
    "            sess_fol_read = family_fol_read + sess + '/'\n",
    "            onlyvideofiles = [os.path.join(sess_fol_read, f) for f in os.listdir(sess_fol_read) if\n",
    "                              os.path.isfile(os.path.join(sess_fol_read, f)) and f.endswith('mainvid.mp4')]\n",
    "\n",
    "            for video in onlyvideofiles:\n",
    "                read_video_file = video\n",
    "                print('Processing:',read_video_file)\n",
    "\n",
    "                csv_path = '/home/sharifa/Family_dataset_features/raw_features/'\n",
    "                csv_file = os.path.basename(read_video_file).split('.')[0] + '.csv'\n",
    "\n",
    "                if os.path.exists(os.path.join(csv_path,'Body_'+csv_file)) and \\\n",
    "                        os.path.exists(os.path.join(csv_path, 'Head_' + csv_file)):\n",
    "                    print('Already processed.')\n",
    "                    continue\n",
    "\n",
    "                if family == 'p19' and sess == 's1':\n",
    "                    print('Skipping')\n",
    "                    continue\n",
    "                extract_raw(family, sess, read_video_file, csv_path, csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd9b42",
   "metadata": {},
   "source": [
    "### step 2 -- extract and save high-level features (low-level --> high-level)\n",
    "- low-level features are merged for every x frames (explained above)\n",
    "- temporal features are extarcted for that window size and saved per person \n",
    "\n",
    "- coloumns = high-level features\n",
    "- raws = temporal features every x frame \n",
    "- saved in 3 variations:  64 frames (~2.5s), 64*2 (~5s) and 5*30(=5s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def statstic_features(features):\n",
    "    features = np.array(features)\n",
    "    # stats = np.zeros((1,NUM_BODY_STATS))\n",
    "    epsilon = np.float32(0.00001)\n",
    "    #for each feature/column\n",
    "    for ff in tqdm(range(features.shape[1])):\n",
    "        this_feature = features[:,ff]\n",
    "\n",
    "        #find and remove outliers\n",
    "        this_feature = grubbs.test(this_feature, alpha=0.05)\n",
    "        #de-noise: smooth the signal - median filter\n",
    "        this_feature = medfilt(this_feature)\n",
    "\n",
    "        #extract the deltas\n",
    "        delta1_this_feature = np.append(this_feature[0], np.diff(this_feature))\n",
    "        delta2_this_feature = np.append(delta1_this_feature[0], np.diff(delta1_this_feature))\n",
    "\n",
    "        # extract stats\n",
    "        f_min = min(this_feature)\n",
    "        d1_min = min(delta1_this_feature)\n",
    "        d2_min = min(delta2_this_feature)\n",
    "\n",
    "        f_max = max(this_feature)\n",
    "        d1_max = max(delta1_this_feature)\n",
    "        d2_max = max(delta2_this_feature)\n",
    "\n",
    "        f_rang = f_max - f_min\n",
    "        d1_rang = d1_max - d1_min\n",
    "        d2_rang = d2_max - d2_min\n",
    "\n",
    "        f_mean = mean(this_feature)\n",
    "        try:\n",
    "            d1_mean = mean(delta1_this_feature)\n",
    "            d2_mean = mean(delta2_this_feature)\n",
    "        except:\n",
    "            print(\"SAD\")\n",
    "            print(delta1_this_feature)\n",
    "\n",
    "        f_std = stdev(this_feature)\n",
    "        d1_std = stdev(delta1_this_feature)\n",
    "        d2_std = stdev(delta2_this_feature)\n",
    "\n",
    "        f_var = variance(this_feature)\n",
    "        d1_var = variance(delta1_this_feature)\n",
    "        d2_var= variance(delta2_this_feature)\n",
    "\n",
    "        #extarct skewness and kurtosis\n",
    "        f_skew = skew(this_feature)\n",
    "        d1_skew = skew(delta1_this_feature)\n",
    "        d2_skew= skew(delta2_this_feature)\n",
    "\n",
    "        f_kurt = kurtosis(this_feature)\n",
    "        d1_kurt = kurtosis(delta1_this_feature)\n",
    "        d2_kurt= kurtosis(delta2_this_feature)\n",
    "\n",
    "        #extract peaks and valys\n",
    "\n",
    "        try:\n",
    "            test = (1 /delta1_this_feature)\n",
    "        except:\n",
    "            for i in range(len(delta1_this_feature)):\n",
    "                if delta1_this_feature[i] == 0.0:\n",
    "                    delta1_this_feature[i] = epsilon\n",
    "\n",
    "\n",
    "        f_peaks = len(find_peaks(this_feature)[0])\n",
    "        d1_peaks = len(find_peaks(delta1_this_feature)[0])\n",
    "        d2_peaks = len(find_peaks(delta2_this_feature)[0])\n",
    "\n",
    "        f_valys = len(find_peaks(1 /this_feature)[0])\n",
    "        d1_valys = len(find_peaks(1 /delta1_this_feature)[0])\n",
    "        d2_valys = len(find_peaks(1 /delta2_this_feature)[0])\n",
    "\n",
    "        f_stats = np.array([f_min, f_max, f_rang, f_mean, f_std, f_var, f_skew, f_kurt, f_peaks, f_valys,\n",
    "                     d1_min, d1_max, d1_rang, d1_mean, d1_std, d1_var, d1_skew, d1_kurt, d1_peaks, d1_valys,\n",
    "                     d2_min, d2_max, d2_rang, d2_mean, d2_std, d2_var, d2_skew, d2_kurt, d2_peaks, d2_valys])\n",
    "\n",
    "        if ff == 0:\n",
    "            stats = f_stats\n",
    "        else:\n",
    "            stats = np.append(stats, f_stats, axis=0)\n",
    "    return stats\n",
    "\n",
    "\n",
    "-----\n",
    "    read_folder = conf.compress_video_folder\n",
    "    families = ['F' + str(i) for i in range(1, 18)]\n",
    "    exclude_one_person = ['F' + str(i) for i in [9, 12, 14, 15, 16]]\n",
    "\n",
    "    for family in families:\n",
    "        if family in exclude_one_person:\n",
    "            print('Skipping Interaction .. {}'.format(family))\n",
    "            continue\n",
    "\n",
    "        onlyvideofiles = [os.path.join(read_folder, f) for f in os.listdir(read_folder) if\n",
    "                          os.path.isfile(os.path.join(read_folder, f)) and f.endswith('.mp4') and f.startswith(\n",
    "                              family + '_')]\n",
    "\n",
    "        for video in onlyvideofiles:\n",
    "            read_video_file = video\n",
    "            save_video_folder = os.path.basename(video).split('.')[0]\n",
    "\n",
    "    read_folder = conf.video_path\n",
    "    family_folders = [f for f in os.listdir(read_folder) if f.startswith('p')]\n",
    "    family_folders.sort()\n",
    "\n",
    "    id_header = ['FamilyID','Session']  + body_get_headers()\n",
    "    all_high_body = pd.DataFrame(columns=id_header)\n",
    "\n",
    "    id_header = ['FamilyID','Session']  + head_get_headers()\n",
    "    all_high_head = pd.DataFrame(columns=id_header)\n",
    "\n",
    "    for family in family_folders:\n",
    "        family_fol_read = read_folder + family + '/'\n",
    "        session_folders = [f for f in os.listdir(family_fol_read) if f.startswith('s')]\n",
    "        session_folders.sort()\n",
    "        for sess in session_folders:\n",
    "            sess_fol_read = family_fol_read + sess + '/'\n",
    "            onlyvideofiles = [os.path.join(sess_fol_read, f) for f in os.listdir(sess_fol_read) if\n",
    "                              os.path.isfile(os.path.join(sess_fol_read, f)) and f.endswith('mainvid.mp4')]\n",
    "\n",
    "            for video in onlyvideofiles:\n",
    "                read_video_file = video\n",
    "                print('Processing:',read_video_file)\n",
    "\n",
    "                low_csv_path = '/home/sharifa/Family_dataset_features/raw_features/'\n",
    "                high_csv_path = '/home/sharifa/Family_dataset_features/high_features/'\n",
    "                low_csv_file = os.path.basename(read_video_file).split('.')[0] + '.csv'\n",
    "\n",
    "                body_csv_file = os.path.join(low_csv_path,'Body_'+low_csv_file)\n",
    "                head_csv_file = os.path.join(low_csv_path,'Head_'+low_csv_file)\n",
    "                if os.path.exists(body_csv_file):\n",
    "                    body_low_data = pd.read_csv(body_csv_file)\n",
    "                    head_low_data = pd.read_csv(head_csv_file)\n",
    "                else:\n",
    "                    print('Empty')\n",
    "                    continue\n",
    "\n",
    "                this_body = statstic_features(body_low_data)\n",
    "                this_head = statstic_features(head_low_data)\n",
    "\n",
    "                this_id = np.array([family, sess])\n",
    "\n",
    "                all_high_body = all_high_body.append(pd.Series(np.concatenate((this_id,this_body)),\\\n",
    "                                                               index=all_high_body.columns), ignore_index=True)\n",
    "                all_high_head = all_high_head.append(pd.Series(np.concatenate((this_id,this_head)),\\\n",
    "                                                               index=all_high_head.columns),ignore_index=True)\n",
    "\n",
    "    # print(all_high_body.head(10))\n",
    "    # print(all_high_head.head(10))\n",
    "    all_high_body.to_csv(os.path.join(high_csv_path,'all_high_body.csv'))\n",
    "    all_high_head.to_csv(os.path.join(high_csv_path,'all_high_head.csv'))\n",
    "    # split: body_parent, body_child, body_sync\n",
    "    # splid array, header and save each\n",
    "    # split: head_parent, head_child, head_sync\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
