{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e42fc71",
   "metadata": {},
   "source": [
    "# Modlling for engagement \n",
    "\n",
    "now we have the features and the lables, we are ready for modelling \n",
    "- Classification vs regression\n",
    "- 9 vs 5 vs 3 scales lables \n",
    "- 2.5 vs 5 s window (as is features, average featuers and concatenate features)\n",
    "- Two-stream Fusion on RGB + Flow \n",
    "\n",
    "This should be done over:\n",
    "- different network artchictures\n",
    "- cross different familys cross-validation \n",
    "\n",
    "Later on:\n",
    "- Handcrafted features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243c294",
   "metadata": {},
   "source": [
    "### imports and vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dacd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "import smote_variants as sv\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from operator import itemgetter\n",
    "\n",
    "lables_path = './labels/'\n",
    "features_path = './features/'\n",
    "results_path = './modelling_results/'\n",
    "models_path = './models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2f46d",
   "metadata": {},
   "source": [
    "### Keras modeling class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83f4f9",
   "metadata": {},
   "source": [
    "### help functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cebbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "from hpbandster.core.worker import Worker\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "class KerasWorker(Worker):\n",
    "    def __init__(self, input_shape, output_shape, problemType,\n",
    "                 x_train, y_train, x_validation, y_validation,\n",
    "                 x_test, y_test, shared_directory, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.input_shape = (input_shape, )\n",
    "            self.num_classes = output_shape\n",
    "            self.batch_size = 64\n",
    "            self.save_dic = shared_directory\n",
    "            \n",
    "            self.problemType = problemType\n",
    "\n",
    "            self.x_train, self.y_train = x_train, y_train\n",
    "            self.x_validation, self.y_validation = x_validation, y_validation\n",
    "            self.x_test, self.y_test = x_test, y_test\n",
    "\n",
    "    def compute(self, config, budget, working_directory, *args, **kwargs):\n",
    "            model = Sequential()\n",
    "            model.add(Dense(units=config['start_neurons_units'],\n",
    "                            # activation=config['start_neurons_activation'],\n",
    "                            activation='relu',\n",
    "                            input_shape=self.input_shape))\n",
    "\n",
    "\n",
    "#             if config['num_dense_layers'] > 1:\n",
    "#                 model.add(Dense(units=config['dense1_units'],\n",
    "#                                 # activation=config['dense1_activation'],\n",
    "#                                 activation='relu',\n",
    "#                                 input_shape=self.input_shape))\n",
    "#                 model.add(Dropout(config['dropout1_rate']))\n",
    "\n",
    "#             if config['num_dense_layers'] > 2:\n",
    "#                 model.add(Dense(units=config['dense2_units'],\n",
    "#                                 # activation=config['dense2_activation'],\n",
    "#                                 activation='relu',\n",
    "#                                 input_shape=self.input_shape))\n",
    "#                 model.add(Dropout(config['dropout2_rate']))\n",
    "\n",
    "            model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "            if config['optimizer'] == 'Adam':\n",
    "                    optimizer = tf.keras.optimizers.Adam(lr=config['lr'])\n",
    "            else:\n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=config['lr'], momentum=config['sgd_momentum'])\n",
    "            \n",
    "            loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "            \n",
    "            METRICS = [\n",
    "                  tf.keras.metrics.TruePositives(name='tp'),\n",
    "                  tf.keras.metrics.FalsePositives(name='fp'),\n",
    "                  tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "                  tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "                  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                  tf.keras.metrics.Precision(name='precision'),\n",
    "                  tf.keras.metrics.Recall(name='recall'),\n",
    "                  tf.keras.metrics.AUC(name='auc'),\n",
    "                  tf.keras.metrics.BinaryCrossentropy(name='BinaryCrossentropy'),\n",
    "                  tfa.metrics.MatthewsCorrelationCoefficient(num_classes=self.num_classes)\n",
    "            ]\n",
    "\n",
    "            #METRICS.append(tfa.metrics.MatthewsCorrelationCoefficient(num_classes=self.num_classes))\n",
    "            \n",
    "            the_columns = ['thisloss','tp','fp','tn','fn','acc','prec','rec','auc','BC','MCC']\n",
    "            \n",
    "            model.compile(\n",
    "                loss=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                metrics=METRICS\n",
    "            )\n",
    "\n",
    "            # model.summary()\n",
    "            _history = model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=int(budget),\n",
    "                              verbose=0,\n",
    "                              validation_data=(self.x_validation, self.y_validation),\n",
    "#                               validation_split=0.33,\n",
    "                                )\n",
    "\n",
    "            val_acc_per_epoch = _history.history['val_accuracy']\n",
    "            best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "\n",
    "            model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=best_epoch,\n",
    "                              verbose=0,\n",
    "                              validation_data=(self.x_validation, self.y_validation)\n",
    "#                               validation_split=0.33,\n",
    "                     )\n",
    "\n",
    "            train_score = model.evaluate(self.x_train, self.y_train, verbose=0)\n",
    "            val_score = model.evaluate(self.x_validation, self.y_validation, verbose=0)\n",
    "            test_score = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "            \n",
    "            #print(test_score)\n",
    "\n",
    "            resultsDF = pd.DataFrame([train_score,val_score,test_score],\n",
    "                                     columns=the_columns,\n",
    "                                     index=[\"train_score\", \"val_score\", \"test_score\"],)\n",
    "            # print(resultsDF)\n",
    "            test_predictions_baseline = model.predict(self.x_test)\n",
    "            np.savetxt(os.path.join(self.save_dic,'testing_finalResults_true.out'), self.y_test, delimiter=',')\n",
    "            np.savetxt(os.path.join(self.save_dic,'testing_finalResults_pred.out'), test_predictions_baseline, delimiter=',')\n",
    "\n",
    "            \n",
    "            model.save(os.path.join(self.save_dic,str(kwargs['config_id'])))\n",
    "            return ({\n",
    "                'loss': test_score[0],  \n",
    "                'info':  resultsDF.to_dict('index')\n",
    "            })\n",
    "        \n",
    "#             #import IPython; IPython.embed()\n",
    "#             return ({\n",
    "#                 'loss': 1-val_score[1], # remember: HpBandSter always minimizes!\n",
    "#                 'info': {'test accuracy': test_score[1],\n",
    "#                             'train accuracy': train_score[1],\n",
    "#                             'validation accuracy': val_score[1],\n",
    "#                             'number of parameters': model.count_params(),\n",
    "#                         }\n",
    "\n",
    "#             })\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "            \"\"\"\n",
    "            It builds the configuration space with the needed hyperparameters.\n",
    "            It is easily possible to implement different types of hyperparameters.\n",
    "            Beside float-hyperparameters on a log scale, it is also able to handle categorical input parameter.\n",
    "            :return: ConfigurationsSpace-Object\n",
    "            \"\"\"\n",
    "            cs = CS.ConfigurationSpace()\n",
    "\n",
    "            lr = CSH.UniformFloatHyperparameter('lr', lower=1e-6, upper=1e-1, default_value='1e-2', log=True)\n",
    "\n",
    "            # For demonstration purposes, we add different optimizers as categorical hyperparameters.\n",
    "            # To show how to use conditional hyperparameters with ConfigSpace, we'll add the optimizers 'Adam' and 'SGD'.\n",
    "            # SGD has a different parameter 'momentum'.\n",
    "            optimizer = CSH.CategoricalHyperparameter('optimizer', ['Adam', 'SGD'])\n",
    "\n",
    "            sgd_momentum = CSH.UniformFloatHyperparameter('sgd_momentum', lower=0.0, upper=0.99, default_value=0.9, log=False)\n",
    "\n",
    "            cs.add_hyperparameters([lr, optimizer, sgd_momentum])\n",
    "\n",
    "\n",
    "\n",
    "#             num_dense_layers =  CSH.UniformIntegerHyperparameter('num_dense_layers', lower=1, upper=1, default_value=1)\n",
    "\n",
    "            start_neurons_units = CSH.UniformIntegerHyperparameter('start_neurons_units', lower=32, upper=512, default_value=32, log=True)\n",
    "#             dense1_units = CSH.UniformIntegerHyperparameter('dense1_units', lower=8, upper=128, default_value=16, log=True)\n",
    "#             dense2_units = CSH.UniformIntegerHyperparameter('dense2_units', lower=4, upper=64, default_value=8, log=True)\n",
    "\n",
    "#             cs.add_hyperparameters([num_dense_layers, start_neurons_units, dense1_units, dense2_units])\n",
    "            cs.add_hyperparameters([start_neurons_units])\n",
    "\n",
    "            # start_neurons_activation = CSH.CategoricalHyperparameter('start_neurons_activation', ['relu', 'tanh', 'sigmoid'])\n",
    "            # dense1_activation = CSH.CategoricalHyperparameter('dense1_activation', ['relu', 'tanh', 'sigmoid'])\n",
    "            # dense2_activation = CSH.CategoricalHyperparameter('dense2_activation', ['relu', 'tanh', 'sigmoid'])\n",
    "            # start_neurons_activation = CSH.CategoricalHyperparameter('start_neurons_activation', ['relu'])\n",
    "            # dense1_activation = CSH.CategoricalHyperparameter('dense1_activation', ['relu'])\n",
    "            # dense2_activation = CSH.CategoricalHyperparameter('dense2_activation', ['relu'])\n",
    "            #\n",
    "            # cs.add_hyperparameters([start_neurons_activation, dense1_activation, dense2_activation])\n",
    "\n",
    "#             dropout1_rate = CSH.UniformFloatHyperparameter('dropout1_rate', lower=0.0, upper=0.9, default_value=0.5, log=False)\n",
    "#             dropout2_rate = CSH.UniformFloatHyperparameter('dropout2_rate', lower=0.0, upper=0.9, default_value=0.5, log=False)\n",
    "\n",
    "#             cs.add_hyperparameters([dropout1_rate, dropout2_rate])\n",
    "\n",
    "\n",
    "            # The hyperparameter sgd_momentum will be used,if the configuration\n",
    "            # contains 'SGD' as optimizer.\n",
    "            cond = CS.EqualsCondition(sgd_momentum, optimizer, 'SGD')\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            # You can also use inequality conditions:\n",
    "#             cond = CS.GreaterThanCondition(dense1_units, num_dense_layers, 1)\n",
    "#             cs.add_condition(cond)\n",
    "\n",
    "#             cond = CS.GreaterThanCondition(dense2_units, num_dense_layers, 2)\n",
    "#             cs.add_condition(cond)\n",
    "\n",
    "            return cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1b61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub_dataset(familiesSet, label_folder, feature_folder, featureType):\n",
    "    # append all rows of subjects, and their lables\n",
    "    allFrames = np.array([])\n",
    "    allLables = np.array([])\n",
    "\n",
    "    for this_family in familiesSet:\n",
    "        # F10_Interaction_1_P27_rgb.npy\n",
    "        onlyfiles = [f for f in os.listdir(feature_folder) if\n",
    "                       os.path.isfile(os.path.join(feature_folder, f))\n",
    "                       and f.startswith(this_family + '_')]\n",
    "        onlyfiles.sort()\n",
    "\n",
    "        for this_file in onlyfiles:\n",
    "            currData = np.load(os.path.join(feature_folder,this_file))            \n",
    "            substr = '_'.join(this_file.split('_')[4:])\n",
    "            this_lable_file = this_file.replace('_'+substr,'')+'.npy'\n",
    "            currLabel = np.load(os.path.join(label_folder,this_lable_file))\n",
    "            cutoff = min(len(currData), len(currLabel))\n",
    "            currData = currData[:cutoff,:]\n",
    "            currLabel =currLabel[:cutoff]\n",
    "            \n",
    "            \n",
    "            if allFrames.shape[0] ==0:\n",
    "                allFrames = currData\n",
    "                allLables = currLabel\n",
    "            else:\n",
    "                allFrames = np.vstack((allFrames, currData))\n",
    "                allLables = np.hstack((allLables, currLabel))\n",
    "\n",
    "    return allFrames, allLables\n",
    "\n",
    "def fix_data(X, y, shuff=False):\n",
    "    c = Counter(y)\n",
    "    print('Before:',X.shape, c)\n",
    "    min_key, min_count = min(c.items(), key=itemgetter(1))\n",
    "    print(min_key, min_count)\n",
    "    if min_count<10:\n",
    "        indx = np.where(y == min_key)\n",
    "        dub = X[indx]\n",
    "#         print(dub.shape)\n",
    "        X = np.vstack((X, np.tile(dub, (10, 1))))\n",
    "        y = np.hstack((y, np.repeat(min_key,len(dub)*10)))\n",
    "        print('Dublicated :',X.shape, Counter(y))\n",
    "    \n",
    "        #     sm = resample(n_neighbors=max(min_count-1,1))\n",
    "    sm = sv.MulticlassOversampling(resample())\n",
    "    if shuff:\n",
    "        X, y = shuffle(X, y)\n",
    "        \n",
    "    #     X, trainy = sm.fit_resample(X, y)\n",
    "    X, y = sm.sample(X, y)\n",
    "    print('After:',X.shape, Counter(y))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_dataset_selectedSubj(trainSubjs, valSubjs, testSubjs, label_folder, feature_folder,\\\n",
    "                              prblemType, featureType, num_classes):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    #sampeling method: SMOTE, DeepSMOTE, DeepFake?\n",
    "    # load all train\n",
    "    trainX, trainy = load_sub_dataset(trainSubjs, label_folder, feature_folder, featureType)\n",
    "    trainX = scaler.fit_transform(trainX)\n",
    "    print('Train Data:')\n",
    "    trainX, trainy = fix_data(trainX, trainy, shuff=True)\n",
    "\n",
    "\n",
    "    # load validation\n",
    "    valX, valy = load_sub_dataset(valSubjs, label_folder, feature_folder, featureType)\n",
    "    valX = scaler.transform(valX)\n",
    "    print('Val Data:')\n",
    "    valX, valy = fix_data(valX, valy, shuff=True)\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_sub_dataset(testSubjs, label_folder, feature_folder, featureType)\n",
    "    testX = scaler.transform(testX)\n",
    "    print('Test Data:')\n",
    "    testX, testy = fix_data(testX, testy, shuff=False)\n",
    "\n",
    "    \n",
    "    return trainX, trainy, valX, valy , testX, testy, num_classes\n",
    "    \n",
    "def create_modlling(label_folder,feature_folder,result_folder, prblemType, featureType, num_classes):    \n",
    "    # repeat experiment\n",
    "    temp = {}\n",
    "    all_trainSubjs = [\n",
    "        ['F' + str(i) for i in [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 17]],\n",
    "    ]\n",
    "    all_valSubjs = [\n",
    "        ['F' + str(i) for i in [11, 17]],\n",
    "    ]\n",
    "    all_testSubjs = [\n",
    "        ['F' + str(i) for i in [7, 10, 13]],\n",
    "    ]\n",
    "    \n",
    "    min_budget = 9\n",
    "    max_budget = 243\n",
    "    n_iterations = 50\n",
    "    num_workers = 12\n",
    "    \n",
    "    n_folds = 10\n",
    "    X, y, _, _, testX, testy, num_classes = \\\n",
    "            load_dataset_selectedSubj(all_trainSubjs[0], all_trainSubjs[0], all_trainSubjs[0], \\\n",
    "                                      label_folder, feature_folder, prblemType, featureType, num_classes)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "#     print(y)\n",
    "    for r, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        shared_directory = result_folder + '_'+ str(r) \n",
    "#         if os.path.exists(shared_directory):\n",
    "#             print(shared_directory,' already processed')\n",
    "#             continue\n",
    "        \n",
    "        print(shared_directory,' under processing')\n",
    "        classType = os.path.basename(shared_directory)\n",
    "\n",
    "        # load data\n",
    "        trainX, trainy = X[train_index], y[train_index]\n",
    "        valX, valy = X[val_index], y[val_index]\n",
    "        testX, testy = X[val_index], y[val_index]\n",
    "        \n",
    "#         print('Train:',trainX.shape, Counter(trainy))\n",
    "#         print('Val:',valX.shape, Counter(valy))\n",
    "#         print('Test:',testX.shape)\n",
    "#         print('Test:',Counter(testy))\n",
    "        \n",
    "        # one hot encode y\n",
    "        trainy = tf.keras.utils.to_categorical(trainy,  num_classes=num_classes)\n",
    "        valy = tf.keras.utils.to_categorical(valy,  num_classes=num_classes)\n",
    "        testy = tf.keras.utils.to_categorical(testy,  num_classes=num_classes)\n",
    "    \n",
    "        n_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], num_classes    \n",
    "        \n",
    "#         continue \n",
    "        \n",
    "        host = hpns.nic_name_to_host('lo')\n",
    "        result_logger = hpres.json_result_logger(directory=shared_directory, overwrite=True)\n",
    "        NS = hpns.NameServer(run_id=classType, host=host, port=0, working_directory=shared_directory)\n",
    "        ns_host, ns_port = NS.start()\n",
    "    \n",
    "        workers = []\n",
    "        for i in range(num_workers):\n",
    "            worker = KerasWorker(n_features, n_outputs, prblemType, \\\n",
    "                                 trainX, trainy, valX, valy, testX, testy, \\\n",
    "                                 shared_directory,\n",
    "                                 run_id=classType,host=host, nameserver=ns_host, nameserver_port=ns_port,\n",
    "                                 id=i)\n",
    "            worker.run(background=True)\n",
    "            workers.append(worker)\n",
    "\n",
    "        bohb = BOHB(configspace=worker.get_configspace(),\n",
    "                  run_id=classType,\n",
    "                  host=host,\n",
    "                  nameserver=ns_host,\n",
    "                  nameserver_port=ns_port,\n",
    "                  result_logger=result_logger,\n",
    "                  min_budget=min_budget, max_budget=max_budget\n",
    "                    )\n",
    "        res = bohb.run(n_iterations=1,  min_n_workers=num_workers)\n",
    "        \n",
    "        # store results\n",
    "        with open(os.path.join(shared_directory, 'results.pkl'), 'wb') as fh:\n",
    "            pickle.dump(res, fh)\n",
    "\n",
    "        id2config = res.get_id2config_mapping()\n",
    "        incumbent = res.get_incumbent_id()\n",
    "        \n",
    "        if incumbent is not None and id2config is not None:\n",
    "        \n",
    "            print('Best found configuration:', id2config[incumbent]['config'])\n",
    "            # print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "            # print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "            # print('Total budget corresponds to %.1f full function evaluations.' % (\n",
    "            #             sum([r.budget for r in res.get_all_runs()]) / max_budget))\n",
    "\n",
    "\n",
    "            this_data = res[incumbent]\n",
    "            new_dic = dict(zip([key for key in this_data.results.keys()],\\\n",
    "                               [this_data.results[k]['loss'] for k in this_data.results.keys()]))\n",
    "            bugKey = min(new_dic, key=new_dic.get)\n",
    "            this_results = pd.DataFrame.from_dict(this_data.results[bugKey]['info']).T\n",
    "            print(this_results['MCC'])\n",
    "\n",
    "        # shutdown\n",
    "        bohb.shutdown(shutdown_workers=True)\n",
    "        NS.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0d843",
   "metadata": {},
   "source": [
    "### modeling handcrafted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881ad505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Working on:  classification handcrafted_extra 3 5s\n",
      "Train Data:\n",
      "Before: (10952, 1860) Counter({1.0: 9183, 0.0: 1574, -1.0: 195})\n",
      "-1.0 195\n",
      "After: (27987, 1860) Counter({0.0: 9444, -1.0: 9360, 1.0: 9183})\n",
      "Val Data:\n",
      "Before: (10952, 1860) Counter({1.0: 9183, 0.0: 1574, -1.0: 195})\n",
      "-1.0 195\n",
      "After: (27987, 1860) Counter({0.0: 9444, -1.0: 9360, 1.0: 9183})\n",
      "Test Data:\n",
      "Before: (10952, 1860) Counter({1.0: 9183, 0.0: 1574, -1.0: 195})\n",
      "-1.0 195\n",
      "After: (27987, 1860) Counter({0.0: 9444, -1.0: 9360, 1.0: 9183})\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_0  under processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 17:04:50.429590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 17:04:50.434406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sharifa/catkin_ws/devel/lib:/usr/local/cuda-11.0/lib64\n",
      "2021-11-25 17:04:50.435122: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sharifa/catkin_ws/devel/lib:/usr/local/cuda-11.0/lib64\n",
      "2021-11-25 17:04:50.435137: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-25 17:04:50.436641: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-25 17:04:52.238271: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-25 17:06:39.885389: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found configuration: {'lr': 0.00020981929814308466, 'optimizer': 'Adam', 'start_neurons_units': 401}\n",
      "train_score    1.000000\n",
      "val_score      0.940024\n",
      "test_score     0.940024\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_1  under processing\n",
      "Best found configuration: {'lr': 0.0007857293248275301, 'optimizer': 'Adam', 'start_neurons_units': 338}\n",
      "train_score    0.982517\n",
      "val_score      0.941104\n",
      "test_score     0.941104\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_2  under processing\n",
      "Best found configuration: {'lr': 0.00014725151514438526, 'optimizer': 'Adam', 'start_neurons_units': 58}\n",
      "train_score    0.965675\n",
      "val_score      0.924671\n",
      "test_score     0.924671\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_3  under processing\n",
      "Best found configuration: {'lr': 0.0001252073358968364, 'optimizer': 'Adam', 'start_neurons_units': 189}\n",
      "train_score    0.973634\n",
      "val_score      0.929534\n",
      "test_score     0.929534\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_4  under processing\n",
      "Best found configuration: {'lr': 0.0001173106069530708, 'optimizer': 'Adam', 'start_neurons_units': 136}\n",
      "train_score    0.980441\n",
      "val_score      0.926078\n",
      "test_score     0.926078\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_5  under processing\n",
      "Best found configuration: {'lr': 0.0018578809004181158, 'optimizer': 'Adam', 'start_neurons_units': 43}\n",
      "train_score    0.946714\n",
      "val_score      0.907282\n",
      "test_score     0.907282\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_6  under processing\n",
      "Best found configuration: {'lr': 0.00013430760746197706, 'optimizer': 'Adam', 'start_neurons_units': 489}\n",
      "train_score    0.990414\n",
      "val_score      0.931058\n",
      "test_score     0.931058\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_7  under processing\n",
      "Best found configuration: {'lr': 0.00010124969016536505, 'optimizer': 'Adam', 'start_neurons_units': 156}\n",
      "train_score    0.967476\n",
      "val_score      0.922710\n",
      "test_score     0.922710\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_8  under processing\n",
      "Best found configuration: {'lr': 0.0004032951995892948, 'optimizer': 'Adam', 'start_neurons_units': 120}\n",
      "train_score    0.977322\n",
      "val_score      0.934239\n",
      "test_score     0.934239\n",
      "Name: MCC, dtype: float64\n",
      "./modelling_results/handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_9  under processing\n",
      "Best found configuration: {'lr': 0.00010644437627935246, 'optimizer': 'Adam', 'start_neurons_units': 289}\n",
      "train_score    0.986402\n",
      "val_score      0.934124\n",
      "test_score     0.934124\n",
      "Name: MCC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "prblemTypes = ['classification']\n",
    "featureTypes = ['handcrafted_extra']\n",
    "classes = [3]\n",
    "fusionTypes = ['5s']\n",
    "sampling_methods = ['polynom_fit_SMOTE']\n",
    "\n",
    "permutations=[ prblemTypes, featureTypes, classes, fusionTypes]\n",
    "all_permutations = list(itertools.product(*permutations))\n",
    "print(len(all_permutations))\n",
    "for this_permutation in all_permutations:\n",
    "    (prblemType, featureType, eng_lvls, fusionType) = this_permutation\n",
    "    classType = 'round_avg_eng_level' if prblemType == 'classification' else 'avg_eng_level'\n",
    "\n",
    "    \n",
    "    print('Working on: ',prblemType, featureType, eng_lvls, fusionType)\n",
    "    \n",
    "    label_folder = os.path.join(lables_path,'_'.join([classType,'eng_lvl',prblemType,str(eng_lvls),str(fusionType)]))\n",
    "    feature_folder = os.path.join(features_path,'_'.join([featureType,'features',fusionType]))\n",
    "    \n",
    "    for sampling_method in sampling_methods:\n",
    "\n",
    "        resample = getattr(__import__(\"smote_variants\", globals(), locals(), [sampling_method], 0), sampling_method)\n",
    "\n",
    "        #save results like: rgb_classification_9_2.5_none\n",
    "        result_folder = os.path.join(results_path,'_'.join([featureType,prblemType,\n",
    "                                                            str(eng_lvls),fusionType,sampling_method,'final']))\n",
    "\n",
    "        create_modlling(label_folder,feature_folder,result_folder, prblemType, featureType, eng_lvls)#, divide,fusionType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046180da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                          thisloss  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats             \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.000834   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.125555   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.125555   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.031060   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.120139   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.120139   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.066618   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.131626   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.131626   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.053232   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.132304   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.132304   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.044905   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.130645   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.130645   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.094314   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.147717   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.147717   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.028197   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.105930   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.105930   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.060098   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.127091   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.127091   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.040831   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.132865   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.132865   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.033899   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.116925   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.116925   \n",
      "\n",
      "                                                                                                               tp  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats            \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        25188.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0         2687.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0         2687.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        24892.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1         2688.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1         2688.0   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        24603.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2         2655.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2         2655.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        24744.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3         2664.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3         2664.0   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        24858.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4         2659.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4         2659.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        24288.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5         2625.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5         2625.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        25027.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6         2670.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6         2670.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        24635.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7         2652.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7         2652.0   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        24806.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8         2675.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8         2675.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        24959.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9         2675.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9         2675.0   \n",
      "\n",
      "                                                                                                             fp  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats          \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0          0.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        112.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        112.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        295.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        110.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        110.0   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        566.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        140.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        140.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        444.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        132.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        132.0   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        327.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        138.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        138.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        893.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        169.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        169.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        161.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        128.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        128.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        548.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        142.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        142.0   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        382.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        123.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        123.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        228.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        123.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        123.0   \n",
      "\n",
      "                                                                                                               tn  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats            \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        50376.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0         5486.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0         5486.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        50081.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1         5488.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1         5488.0   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        49810.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2         5458.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2         5458.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        49932.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3         5466.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3         5466.0   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        50049.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4         5460.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4         5460.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        49483.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5         5429.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5         5429.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        50215.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6         5470.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6         5470.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        49830.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7         5454.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7         5454.0   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        49996.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8         5473.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8         5473.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        50150.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9         5473.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9         5473.0   \n",
      "\n",
      "                                                                                                             fn  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats          \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0          0.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        112.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        112.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        296.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        111.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        111.0   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        585.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        144.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        144.0   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        444.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        135.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        135.0   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        330.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        140.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        140.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        900.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        174.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        174.0   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        161.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        129.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        129.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        554.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        146.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        146.0   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        383.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        123.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        123.0   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        230.0   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        123.0   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        123.0   \n",
      "\n",
      "                                                                                                               acc  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats             \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        1.000000   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.973324   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.973324   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.992179   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.973681   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.973681   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.984768   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.966178   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.966178   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.988248   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.968203   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.968203   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.991305   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.966893   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.966893   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.976272   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.959152   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.959152   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.995739   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.969394   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.969394   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.985417   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.965690   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.965690   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.989876   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.970693   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.970693   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.993939   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.970693   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.970693   \n",
      "\n",
      "                                                                                                              prec  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats             \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        1.000000   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.959986   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.959986   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.988288   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.960686   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.960686   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.977512   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.949911   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.949911   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.982373   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.952790   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.952790   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.987016   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.950661   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.950661   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.964537   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.939513   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.939513   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.993608   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.954253   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.954253   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.978239   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.949177   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.949177   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.984834   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.956040   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.956040   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.990948   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.956040   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.956040   \n",
      "\n",
      "                                                                                                               rec  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats             \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        1.000000   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.959986   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.959986   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.988248   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.960343   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.960343   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.976775   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.948553   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.948553   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.982373   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.951769   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.951769   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.986899   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.949982   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.949982   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.964269   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.937835   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.937835   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.993608   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.953912   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.953912   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.978006   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.947820   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.947820   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.984795   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.956040   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.956040   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.990869   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.956040   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.956040   \n",
      "\n",
      "                                                                                                               auc  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats             \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        1.000000   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.995036   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.995036   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.999725   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.993887   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.993887   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.998811   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.994461   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.994461   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.999420   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.994446   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.994446   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.999555   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.994496   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.994496   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.997398   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.993189   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.993189   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.999872   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.996236   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.996236   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.999026   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.994745   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.994745   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.999431   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.993811   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.993811   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.999785   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.994925   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.994925   \n",
      "\n",
      "                                                                                                                BC  \\\n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats             \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.412079   \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.491814   \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.491814   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.245762   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.287069   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.287069   \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.118861   \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.143351   \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.143351   \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.250896   \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.281315   \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.281315   \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.116749   \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.157743   \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.157743   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        1.266130   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        1.300797   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        1.300797   \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.153863   \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.185097   \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.185097   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.176010   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.198869   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.198869   \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.227041   \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.265864   \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.265864   \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.252268   \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.287219   \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.287219   \n",
      "\n",
      "                                                                                                               MCC  \n",
      "            featureType       prblemType     confID     budget eng_lvls divide fusionType        repeats            \n",
      "train_score handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        1.000000  \n",
      "val_score   handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.940024  \n",
      "test_score  handcrafted_extra classification (0, 0, 12) 243.0  3        5s     polynom_fit_SMOTE 0        0.940024  \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.982517  \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.941104  \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 1        0.941104  \n",
      "train_score handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.965675  \n",
      "val_score   handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.924671  \n",
      "test_score  handcrafted_extra classification (0, 0, 13) 81.0   3        5s     polynom_fit_SMOTE 2        0.924671  \n",
      "train_score handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.973634  \n",
      "val_score   handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.929534  \n",
      "test_score  handcrafted_extra classification (0, 0, 6)  81.0   3        5s     polynom_fit_SMOTE 3        0.929534  \n",
      "train_score handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.980441  \n",
      "val_score   handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.926078  \n",
      "test_score  handcrafted_extra classification (0, 0, 8)  81.0   3        5s     polynom_fit_SMOTE 4        0.926078  \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.946714  \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.907282  \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 5        0.907282  \n",
      "train_score handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.990414  \n",
      "val_score   handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.931058  \n",
      "test_score  handcrafted_extra classification (0, 0, 24) 81.0   3        5s     polynom_fit_SMOTE 6        0.931058  \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.967476  \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.922710  \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 7        0.922710  \n",
      "train_score handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.977322  \n",
      "val_score   handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.934239  \n",
      "test_score  handcrafted_extra classification (0, 0, 0)  81.0   3        5s     polynom_fit_SMOTE 8        0.934239  \n",
      "train_score handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.986402  \n",
      "val_score   handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.934124  \n",
      "test_score  handcrafted_extra classification (0, 0, 22) 81.0   3        5s     polynom_fit_SMOTE 9        0.934124  \n"
     ]
    }
   ],
   "source": [
    "all_repeats = 10\n",
    "\n",
    "best_results = pd.DataFrame([])\n",
    "for repeats in range(all_repeats):\n",
    "    this_folder = 'handcrafted_extra_classification_3_5s_polynom_fit_SMOTE_final_'+str(repeats)\n",
    "\n",
    "    featureType1,featureType2,prblemType,eng_lvls,divide,fusionType1,fusionType2,fusionType3,f,repeats = this_folder.split('_')\n",
    "    featureType = '_'.join([featureType1,featureType2])\n",
    "    fusionType = '_'.join([fusionType1,fusionType2,fusionType3])\n",
    "\n",
    "    shared_directory = os.path.join(results_path,this_folder)\n",
    "\n",
    "    results_file = os.path.join(shared_directory,'results.pkl')\n",
    "    if not os.path.exists(results_file):\n",
    "        print('ERROR: file {} does not exsist'.format(results_file))\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        res = pickle.load(open(results_file, \"rb\" ))\n",
    "    except:\n",
    "        pass\n",
    "    id2config = res.get_id2config_mapping()\n",
    "    incumbent = res.get_incumbent_id()\n",
    "\n",
    "\n",
    "    this_data = res[incumbent]\n",
    "    new_dic = dict(zip([key for key in this_data.results.keys()],\\\n",
    "                       [this_data.results[k]['loss'] for k in this_data.results.keys()]))\n",
    "\n",
    "    bugKey = min(new_dic, key=new_dic.get)\n",
    "\n",
    "    this_results = pd.DataFrame.from_dict(this_data.results[bugKey]['info']).T\n",
    "    this_results['budget'] = str(bugKey)\n",
    "    this_results['confID'] = str(incumbent)\n",
    "    this_results['featureType'] = featureType\n",
    "    this_results['prblemType'] = prblemType\n",
    "    this_results['eng_lvls'] = eng_lvls\n",
    "    this_results['divide'] = divide\n",
    "    this_results['fusionType'] = fusionType\n",
    "    this_results['repeats'] = repeats\n",
    "\n",
    "    this_results.set_index(['featureType', 'prblemType', 'confID',\\\n",
    "                            'budget', 'eng_lvls', 'divide','fusionType','repeats'],\\\n",
    "                           append=True, inplace=True)\n",
    "    # cols = this_results.columns.tolist()\n",
    "\n",
    "    best_results = best_results if len(this_results) ==0 else best_results.append(this_results)\n",
    "print(best_results)\n",
    "#     print(new_dic)\n",
    "#     print(this_data)\n",
    "#     print(incumbent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2cd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
