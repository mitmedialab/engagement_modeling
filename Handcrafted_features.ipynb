{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9b1868",
   "metadata": {},
   "source": [
    "# Extarct handcrafted features \n",
    "- for each person, for x frames, calculate the nonverbal features from head and body landmarks \n",
    "- the x frames are: 64 frames (\\~2.5s), 64\\*2 (\\~5s) and 5*30(=5s)\n",
    "- the first two are to be compared with the deep features, the last is for the actual labeling \n",
    "\n",
    "- raw data --> low-level --> high-level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cbe40",
   "metadata": {},
   "source": [
    "### imports and vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8ed156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from outliers import smirnov_grubbs as grubbs\n",
    "from statistics import mean, stdev, variance\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import medfilt, find_peaks\n",
    "\n",
    "base_path = '/home/sharifa/speedDating/'\n",
    "raw_features_path = os.path.join(base_path,'speedDating_Detectron_named_3D_with_gazeFollow/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146362c",
   "metadata": {},
   "source": [
    "### help functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0973074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MidHip = 0\n",
    "RHip = 1\n",
    "RKnee = 2\n",
    "RAnkle = 3\n",
    "LHip = 4\n",
    "LKnee = 5\n",
    "LAnkle = 6\n",
    "MidBack = 7\n",
    "Neck = 8\n",
    "Nose = 9\n",
    "forehead =10\n",
    "LShoulder = 11\n",
    "LElbow = 12\n",
    "LWrist = 13\n",
    "RShoulder = 14\n",
    "RElbow = 15\n",
    "RWrist = 16\n",
    "\n",
    "def body_get_headers():\n",
    "    body_features_heads =['body_pitch', 'body_roll', 'body_yaw',\n",
    "                         'lhand_face', 'rhand_face', \n",
    "                         'lhand_body', 'rhand_body', \n",
    "                         'rhand_lhand']\n",
    "    return body_features_heads\n",
    "\n",
    "\n",
    "\n",
    "def head_get_headers():\n",
    "    head_features_heads = ['head_pitch', 'head_roll', 'head_yaw']\n",
    "\n",
    "    return head_features_heads\n",
    "\n",
    "def get_stat_headers(features_heads):\n",
    "    # return stat_features\n",
    "    stats_features = ['f_min', 'f_max', 'f_rang', 'f_mean', 'f_std', 'f_var', 'f_skew', 'f_kurt', 'f_peaks', 'f_valys',\n",
    "                         'd1_min', 'd1_max', 'd1_rang', 'd1_mean', 'd1_std', 'd1_var', 'd1_skew', 'd1_kurt', 'd1_peaks', 'd1_valys',\n",
    "                         'd2_min', 'd2_max', 'd2_rang', 'd2_mean', 'd2_std', 'd2_var', 'd2_skew', 'd2_kurt', 'd2_peaks', 'd2_valys']\n",
    "\n",
    "    high_feature_headers = []\n",
    "    for i in range(len(features_heads)):\n",
    "        for j in range(len(stats_features)):\n",
    "            high_feature_headers.append(features_heads[i] + '-' + stats_features[j])\n",
    "\n",
    "    return high_feature_headers\n",
    "\n",
    "\n",
    "def body_sync_one(pose):\n",
    "    \n",
    "    nose = pose[Nose]\n",
    "    center = pose[Neck]\n",
    "    rhand = pose[RWrist]\n",
    "    lhand = pose[LWrist]\n",
    "\n",
    "    lhand_face, rhand_face = None, None\n",
    "    lhand_body, rhand_body = None, None\n",
    "    lhand_rhand = None\n",
    "\n",
    "    if type(nose) != type(None):\n",
    "        if type(lhand) != type(None):\n",
    "            lhand_face = np.linalg.norm(lhand - nose)\n",
    "        if type(rhand) != type(None):\n",
    "            rhand_face = np.linalg.norm(rhand - nose)\n",
    "\n",
    "    if type(center) != type(None):\n",
    "        if type(lhand) != type(None):\n",
    "            lhand_body = np.linalg.norm(lhand - center)\n",
    "        if type(rhand) != type(None):\n",
    "            rhand_body = np.linalg.norm(rhand - center)\n",
    "\n",
    "    if type(lhand) != type(None):\n",
    "        if type(rhand) != type(None):\n",
    "            lhand_rhand = np.linalg.norm(lhand - rhand)\n",
    "\n",
    "    body_feature = [lhand_face, rhand_face,\n",
    "                    lhand_body, rhand_body,\n",
    "                    lhand_rhand]\n",
    "    return np.array(body_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994cc63",
   "metadata": {},
   "source": [
    "### step 1 -- extract and save low-level features (raw data --> low-level)\n",
    "- raw data are saved per frame for every one in the frame\n",
    "- wants to make low-level files one for each person\n",
    "- coloumns = low-level features\n",
    "- raws = each frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9e38e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw(points_folder, people_list):\n",
    "    files_total = len(os.listdir(points_folder))\n",
    "    all_raw_features = {}\n",
    "    for person in people_list:\n",
    "        all_raw_features[person]=[]\n",
    "    \n",
    "    # keep looping infinitely\n",
    "    for i in tqdm(range(files_total)):\n",
    "#         if i >=10:\n",
    "#             break\n",
    "        point_file = os.path.join(points_folder, '{}.npy'.format(str(i).zfill(6)))\n",
    "\n",
    "        if not os.path.exists(point_file):\n",
    "            for person in all_raw_features.keys():\n",
    "                all_raw_features[person].append([])\n",
    "            continue\n",
    "        im_res = np.load(point_file, allow_pickle=True)\n",
    "        \n",
    "        #plot BBox and name\n",
    "        this_frame_people = []\n",
    "        for human in im_res:\n",
    "            name = str(human['face_name'])\n",
    "            if not name.startswith('P'):\n",
    "                continue\n",
    "            if name in this_frame_people:\n",
    "                continue\n",
    "            this_frame_people.append(name)\n",
    "            \n",
    "            if name not in all_raw_features.keys():\n",
    "                print('a new person named {} in {}'.format(name,points_folder))\n",
    "                all_raw_features[name] = []\n",
    "            \n",
    "            # body joints\n",
    "            keypoints_3D = (human['3d_keypoints']).astype(np.float32)\n",
    "            body_pose = human['body_pose']\n",
    "            head_pose = human['head_pose']\n",
    "\n",
    "            #low-level features\n",
    "            raw_features = np.append(body_pose, np.append(body_sync_one(keypoints_3D),head_pose))\n",
    "\n",
    "            all_raw_features[name].append(raw_features)\n",
    "            \n",
    "    return all_raw_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc2d791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F10_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:10<00:00, 3065.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F11_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:13<00:00, 2301.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F11_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31142/31142 [00:12<00:00, 2573.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F13_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:12<00:00, 2491.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F17_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████████████████████████████▍                                                                                   | 14434/31823 [00:05<00:06, 2510.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a new person named P27 in /home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/F17_Interaction_1.mp4/F17_Interaction_1_frame-json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:12<00:00, 2552.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F17_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31567/31567 [00:11<00:00, 2655.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F1_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:12<00:00, 2644.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F1_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:15<00:00, 2098.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F2_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:12<00:00, 2475.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F2_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 9333/11036 [00:03<00:00, 2831.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a new person named P5 in /home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/F2_Interaction_2.mp4/F2_Interaction_2_frame-json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11036/11036 [00:03<00:00, 3018.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F3_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31809/31809 [00:14<00:00, 2255.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F3_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31814/31814 [00:13<00:00, 2274.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F4_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:20<00:00, 1589.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F4_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▉                                                                                                                                           | 3098/31823 [00:02<00:17, 1622.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a new person named P14 in /home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/F4_Interaction_2.mp4/F4_Interaction_2_frame-json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:18<00:00, 1709.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F5_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:14<00:00, 2238.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F5_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:12<00:00, 2471.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F6_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:14<00:00, 2124.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F6_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:14<00:00, 2185.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F7_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31809/31809 [00:16<00:00, 1928.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F8_Interaction_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31808/31808 [00:13<00:00, 2328.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F8_Interaction_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:12<00:00, 2461.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F8_Interaction_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:13<00:00, 2412.04it/s]\n"
     ]
    }
   ],
   "source": [
    "person_order = {\n",
    "    'F1_Interaction_1.mp4':{'P2':'older girl','P1':'younger girl','P3':'mother'},\n",
    "    'F1_Interaction_2.mp4':{'P2':'older girl','P1':'younger girl','P3':'mother'},\n",
    "\n",
    "    'F2_Interaction_1.mp4':{'P4':'boy','P5':'father'},\n",
    "    'F2_Interaction_2.mp4':{'P4':'boy'},\n",
    "\n",
    "    'F3_Interaction_1.mp4':{'P8':'father','P6':'girl','P7':'boy'},\n",
    "    'F3_Interaction_2.mp4':{'P6':'girl','P7':'boy'},\n",
    "\n",
    "    'F4_Interaction_1.mp4':{'P14':'mother','P12':'older girl','P11':'younger girl','P10':'older boy','P9':'younger boy','P13':'father'},\n",
    "    'F4_Interaction_2.mp4':{'P12':'older girl','P11':'younger girl','P10':'older boy','P9':'younger boy','P13':'father'},\n",
    "\n",
    "    'F5_Interaction_1.mp4':{'P16':'mother','P15':'boy'},\n",
    "    'F5_Interaction_2.mp4':{'P16':'mother','P15':'boy'},\n",
    "\n",
    "    'F6_Interaction_1.mp4':{'P19':'father','P18':'girl','P17':'boy'},\n",
    "    'F6_Interaction_2.mp4':{'P19':'father','P18':'girl','P17':'boy'},\n",
    "\n",
    "    'F7_Interaction_1.mp4':{'P22':'father','P20':'younger boy','P21':'older boy','P23':'mother'},\n",
    "\n",
    "    'F8_Interaction_1.mp4':{'P24':'girl','P25':'father'},\n",
    "    'F8_Interaction_2.mp4':{'P24':'girl','P25':'father'},\n",
    "    'F8_Interaction_3.mp4':{'P24':'girl','P25':'father'},\n",
    "\n",
    "    'F10_Interaction_1.mp4': {'P27':'left girl (green top)', 'P28':'right girl (white top)'},\n",
    "\n",
    "    'F11_Interaction_1.mp4': {'P29':'boy', 'P30':'mother'},\n",
    "    'F11_Interaction_2.mp4':{'P29':'boy','P30':'mother'},\n",
    "\n",
    "    'F13_Interaction_1.mp4':{'P32':'girl','P33':'mother'},\n",
    "\n",
    "    'F17_Interaction_1.mp4': {'P37':'girl', 'P38':'mother'},\n",
    "    'F17_Interaction_2.mp4':{'P37':'girl','P38':'mother'}\n",
    "}\n",
    "\n",
    "\n",
    "low_csv_path = os.path.join(base_path,'raw_features/')\n",
    "    \n",
    "onlyfolders = [os.path.join(raw_features_path, f) for f in os.listdir(raw_features_path) if not\n",
    "                  os.path.isfile(os.path.join(raw_features_path, f)) and f.startswith('F')]\n",
    "onlyfolders.sort()\n",
    "for folder in onlyfolders:\n",
    "    save_folder = os.path.basename(folder).split('.')[0]\n",
    "    people_list = list(person_order[save_folder+'.mp4'].keys())\n",
    "    \n",
    "    person = people_list[0]\n",
    "    low_csv_file = os.path.join(low_csv_path,'_'.join([save_folder,person,'low_level'])+'.csv')\n",
    "    if os.path.exists(low_csv_file):\n",
    "        print('Already processed:',low_csv_file)\n",
    "        continue\n",
    "    \n",
    "    readingpath = os.path.join(raw_features_path,\n",
    "                              '{}.mp4'.format(save_folder),\n",
    "                              '{}_frame-json'.format(save_folder))\n",
    "\n",
    "    print('Processing:',save_folder)\n",
    "    #print(people_list)\n",
    "    \n",
    "    #extract low-level for this folder for all people \n",
    "    this_group_low_level = extract_raw(readingpath,people_list)\n",
    "    \n",
    "    for this_person in this_group_low_level.keys():\n",
    "        low_data = this_group_low_level[this_person]\n",
    "        \n",
    "        #save low-level features for each person \n",
    "        low_csv_file = os.path.join(low_csv_path,'_'.join([save_folder,this_person,'low_level'])+'.csv')\n",
    "        low_header = body_get_headers() + head_get_headers()\n",
    "        #np.savetxt(low_csv_file, low_data, delimiter=',', header=low_header)\n",
    "        low_data_df = pd.DataFrame(low_data)\n",
    "        low_data_df.to_csv(low_csv_file, header=low_header, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a35812a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31823/31823 [00:10<00:00, 3179.89it/s]\n"
     ]
    }
   ],
   "source": [
    "### in F17_1, P37 was mistikanely named as P27 this is to fix this\n",
    "def extract_raw_f17(points_folder, people_list):\n",
    "    files_total = len(os.listdir(points_folder))\n",
    "    all_raw_features = {}\n",
    "    for person in people_list:\n",
    "        all_raw_features[person]=[]\n",
    "    \n",
    "    # keep looping infinitely\n",
    "    for i in tqdm(range(files_total)):\n",
    "#         if i >=10:\n",
    "#             break\n",
    "        point_file = os.path.join(points_folder, '{}.npy'.format(str(i).zfill(6)))\n",
    "\n",
    "        if not os.path.exists(point_file):\n",
    "            for person in all_raw_features.keys():\n",
    "                all_raw_features[person].append([])\n",
    "            continue\n",
    "        im_res = np.load(point_file, allow_pickle=True)\n",
    "        \n",
    "        #plot BBox and name\n",
    "        this_frame_people = []\n",
    "        for human in im_res:\n",
    "            name = str(human['face_name'])\n",
    "            if not name.startswith('P'):\n",
    "                continue\n",
    "            if name in this_frame_people:\n",
    "                continue\n",
    "            name = 'P37' if name=='P27' else name\n",
    "            this_frame_people.append(name)\n",
    "            \n",
    "            if name not in all_raw_features.keys():\n",
    "                print('a new person named {} in {}'.format(name,points_folder))\n",
    "                all_raw_features[name] = []\n",
    "            \n",
    "            # body joints\n",
    "            keypoints_3D = (human['3d_keypoints']).astype(np.float32)\n",
    "            body_pose = human['body_pose']\n",
    "            head_pose = human['head_pose']\n",
    "\n",
    "            #low-level features\n",
    "            raw_features = np.append(body_pose, np.append(body_sync_one(keypoints_3D),head_pose))\n",
    "\n",
    "            all_raw_features[name].append(raw_features)\n",
    "    return all_raw_features\n",
    "\n",
    "save_folder = 'F17_Interaction_1'\n",
    "people_list = list(person_order[save_folder+'.mp4'].keys())\n",
    "readingpath = '/home/sharifa/speedDating/speedDating_Detectron_named_3D_with_gazeFollow/F17_Interaction_1.mp4/F17_Interaction_1_frame-json'\n",
    "\n",
    "\n",
    "this_group_low_level = extract_raw_f17(readingpath,people_list)\n",
    "\n",
    "for this_person in this_group_low_level.keys():\n",
    "    low_data = this_group_low_level[this_person]\n",
    "\n",
    "    #save low-level features for each person \n",
    "    low_csv_file = os.path.join(low_csv_path,'_'.join([save_folder,this_person,'low_level'])+'.csv')\n",
    "    low_header = body_get_headers() + head_get_headers()\n",
    "    #np.savetxt(low_csv_file, low_data, delimiter=',', header=low_header)\n",
    "    low_data_df = pd.DataFrame(low_data)\n",
    "    #print(low_data_df)\n",
    "    low_data_df.to_csv(low_csv_file, header=low_header, index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd9b42",
   "metadata": {},
   "source": [
    "### step 2 -- extract and save high-level features (low-level --> high-level)\n",
    "- low-level features are merged for every x frames (explained above)\n",
    "- temporal features are extarcted for that window size and saved per person \n",
    "\n",
    "- coloumns = high-level features\n",
    "- raws = temporal features every x frame \n",
    "- saved in 3 variations:  64 frames (~2.5s), 64*2 (~5s) and 5*30(=5s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf0091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def statstic_features(all_features, window_size):\n",
    "    all_features = np.array(all_features)\n",
    "    epsilon = np.float32(0.00001)\n",
    "    all_stats = np.array([])\n",
    "    #for each window size in rows \n",
    "    total_rows = all_features.shape[0]\n",
    "    total_cols = all_features.shape[1]\n",
    "    for this_step in range(0,total_rows,window_size):\n",
    "        end_win = window_size if this_step+window_size < total_rows else total_rows\n",
    "        this_sub_data = all_features[this_step:this_step+end_win,:]\n",
    "        if len(this_sub_data) <3:\n",
    "            print('less than 3 rows')\n",
    "            continue\n",
    "        \n",
    "        #for each feature/column\n",
    "        for ff in range(total_cols):\n",
    "            this_feature = this_sub_data[:,ff]\n",
    "\n",
    "            #find and remove outliers\n",
    "            this_feature = grubbs.test(this_feature, alpha=0.05)\n",
    "            #de-noise: smooth the signal - median filter\n",
    "            this_feature = medfilt(this_feature)\n",
    "\n",
    "            #extract the deltas\n",
    "            delta1_this_feature = np.append(this_feature[0], np.diff(this_feature))\n",
    "            delta2_this_feature = np.append(delta1_this_feature[0], np.diff(delta1_this_feature))\n",
    "\n",
    "            # extract stats\n",
    "            f_min = min(this_feature)\n",
    "            d1_min = min(delta1_this_feature)\n",
    "            d2_min = min(delta2_this_feature)\n",
    "\n",
    "            f_max = max(this_feature)\n",
    "            d1_max = max(delta1_this_feature)\n",
    "            d2_max = max(delta2_this_feature)\n",
    "\n",
    "            f_rang = f_max - f_min\n",
    "            d1_rang = d1_max - d1_min\n",
    "            d2_rang = d2_max - d2_min\n",
    "\n",
    "            f_mean = mean(this_feature)\n",
    "            try:\n",
    "                d1_mean = mean(delta1_this_feature)\n",
    "                d2_mean = mean(delta2_this_feature)\n",
    "            except:\n",
    "                print(\"SAD\")\n",
    "                print(delta1_this_feature)\n",
    "\n",
    "            f_std = stdev(this_feature)\n",
    "            d1_std = stdev(delta1_this_feature)\n",
    "            d2_std = stdev(delta2_this_feature)\n",
    "\n",
    "            f_var = variance(this_feature)\n",
    "            d1_var = variance(delta1_this_feature)\n",
    "            d2_var= variance(delta2_this_feature)\n",
    "\n",
    "            #extarct skewness and kurtosis\n",
    "            f_skew = skew(this_feature)\n",
    "            d1_skew = skew(delta1_this_feature)\n",
    "            d2_skew= skew(delta2_this_feature)\n",
    "\n",
    "            f_kurt = kurtosis(this_feature)\n",
    "            d1_kurt = kurtosis(delta1_this_feature)\n",
    "            d2_kurt= kurtosis(delta2_this_feature)\n",
    "\n",
    "            #extract peaks and valys\n",
    "\n",
    "            try:\n",
    "                test = (1 /delta1_this_feature)\n",
    "            except:\n",
    "                for i in range(len(delta1_this_feature)):\n",
    "                    if delta1_this_feature[i] == 0.0:\n",
    "                        delta1_this_feature[i] = epsilon\n",
    "\n",
    "\n",
    "            f_peaks = len(find_peaks(this_feature)[0])\n",
    "            d1_peaks = len(find_peaks(delta1_this_feature)[0])\n",
    "            d2_peaks = len(find_peaks(delta2_this_feature)[0])\n",
    "\n",
    "            f_valys = len(find_peaks(1 /this_feature)[0])\n",
    "            d1_valys = len(find_peaks(1 /delta1_this_feature)[0])\n",
    "            d2_valys = len(find_peaks(1 /delta2_this_feature)[0])\n",
    "\n",
    "            f_stats = np.array([f_min, f_max, f_rang, f_mean, f_std, f_var, f_skew, f_kurt, f_peaks, f_valys,\n",
    "                         d1_min, d1_max, d1_rang, d1_mean, d1_std, d1_var, d1_skew, d1_kurt, d1_peaks, d1_valys,\n",
    "                         d2_min, d2_max, d2_rang, d2_mean, d2_std, d2_var, d2_skew, d2_kurt, d2_peaks, d2_valys])\n",
    "\n",
    "            if ff == 0:\n",
    "                stats = f_stats\n",
    "            else:\n",
    "                stats = np.append(stats, f_stats, axis=0)\n",
    "        if len(all_stats) == 0:\n",
    "            all_stats = stats\n",
    "        else:\n",
    "            all_stats = np.vstack((all_stats,stats))\n",
    "    return all_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5d448",
   "metadata": {},
   "source": [
    "### loop through all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d000275d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F10_Interaction_1_P27\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F10_Interaction_1_P27_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F10_Interaction_1_P27_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F10_Interaction_1_P27_high_level.npy\n",
      "Processing: F10_Interaction_1_P28\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F10_Interaction_1_P28_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F10_Interaction_1_P28_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F10_Interaction_1_P28_high_level.npy\n",
      "Processing: F11_Interaction_1_P29\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F11_Interaction_1_P29_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F11_Interaction_1_P29_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F11_Interaction_1_P29_high_level.npy\n",
      "Processing: F11_Interaction_1_P30\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F11_Interaction_1_P30_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F11_Interaction_1_P30_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F11_Interaction_1_P30_high_level.npy\n",
      "Processing: F11_Interaction_2_P29\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F11_Interaction_2_P29_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F11_Interaction_2_P29_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F11_Interaction_2_P29_high_level.npy\n",
      "Processing: F11_Interaction_2_P30\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F11_Interaction_2_P30_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F11_Interaction_2_P30_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F11_Interaction_2_P30_high_level.npy\n",
      "Processing: F13_Interaction_1_P32\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F13_Interaction_1_P32_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F13_Interaction_1_P32_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F13_Interaction_1_P32_high_level.npy\n",
      "Processing: F13_Interaction_1_P33\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F13_Interaction_1_P33_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F13_Interaction_1_P33_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F13_Interaction_1_P33_high_level.npy\n",
      "Processing: F17_Interaction_1_P37\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F17_Interaction_1_P37_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F17_Interaction_1_P37_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F17_Interaction_1_P37_high_level.npy\n",
      "Processing: F17_Interaction_1_P38\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F17_Interaction_1_P38_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F17_Interaction_1_P38_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F17_Interaction_1_P38_high_level.npy\n",
      "Processing: F17_Interaction_2_P37\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F17_Interaction_2_P37_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F17_Interaction_2_P37_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F17_Interaction_2_P37_high_level.npy\n",
      "Processing: F17_Interaction_2_P38\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F17_Interaction_2_P38_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F17_Interaction_2_P38_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F17_Interaction_2_P38_high_level.npy\n",
      "Processing: F1_Interaction_1_P1\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F1_Interaction_1_P1_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F1_Interaction_1_P1_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F1_Interaction_1_P1_high_level.npy\n",
      "Processing: F1_Interaction_1_P2\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F1_Interaction_1_P2_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F1_Interaction_1_P2_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F1_Interaction_1_P2_high_level.npy\n",
      "Processing: F1_Interaction_1_P3\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F1_Interaction_1_P3_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F1_Interaction_1_P3_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F1_Interaction_1_P3_high_level.npy\n",
      "Processing: F1_Interaction_2_P1\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F1_Interaction_2_P1_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F1_Interaction_2_P1_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F1_Interaction_2_P1_high_level.npy\n",
      "Processing: F1_Interaction_2_P2\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F1_Interaction_2_P2_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F1_Interaction_2_P2_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F1_Interaction_2_P2_high_level.npy\n",
      "Processing: F1_Interaction_2_P3\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F1_Interaction_2_P3_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F1_Interaction_2_P3_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F1_Interaction_2_P3_high_level.npy\n",
      "Processing: F2_Interaction_1_P4\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F2_Interaction_1_P4_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F2_Interaction_1_P4_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F2_Interaction_1_P4_high_level.npy\n",
      "Processing: F2_Interaction_1_P5\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F2_Interaction_1_P5_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F2_Interaction_1_P5_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F2_Interaction_1_P5_high_level.npy\n",
      "Processing: F2_Interaction_2_P4\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F2_Interaction_2_P4_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F2_Interaction_2_P4_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F2_Interaction_2_P4_high_level.npy\n",
      "Processing: F2_Interaction_2_P5\n",
      "Already Processed:2.5-./features/handcrafted_features_2.5/F2_Interaction_2_P5_high_level.npy\n",
      "Already Processed:5-./features/handcrafted_features_5/F2_Interaction_2_P5_high_level.npy\n",
      "Already Processed:5s-./features/handcrafted_features_5s/F2_Interaction_2_P5_high_level.npy\n",
      "Processing: F3_Interaction_1_P6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17051/3479857901.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  test = (1 /delta1_this_feature)\n",
      "/tmp/ipykernel_17051/3479857901.py:80: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f_valys = len(find_peaks(1 /this_feature)[0])\n",
      "/tmp/ipykernel_17051/3479857901.py:81: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  d1_valys = len(find_peaks(1 /delta1_this_feature)[0])\n",
      "/tmp/ipykernel_17051/3479857901.py:82: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  d2_valys = len(find_peaks(1 /delta2_this_feature)[0])\n",
      "/home/sharifa/engagement_modeling/eng_env/lib/python3.8/site-packages/outliers/smirnov_grubbs.py:105: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  g = value / data.std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 3 rows\n",
      "Processing: F3_Interaction_1_P7\n",
      "less than 3 rows\n",
      "Processing: F3_Interaction_1_P8\n",
      "Processing: F3_Interaction_2_P6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharifa/engagement_modeling/eng_env/lib/python3.8/site-packages/scipy/signal/signaltools.py:1531: UserWarning: kernel_size exceeds volume extent: the volume will be zero-padded.\n",
      "  warnings.warn('kernel_size exceeds volume extent: the volume will be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: F3_Interaction_2_P7\n",
      "Processing: F4_Interaction_1_P10\n",
      "Processing: F4_Interaction_1_P11\n",
      "Processing: F4_Interaction_1_P12\n",
      "Processing: F4_Interaction_1_P13\n",
      "Processing: F4_Interaction_1_P14\n",
      "Processing: F4_Interaction_1_P9\n",
      "Processing: F4_Interaction_2_P10\n",
      "Processing: F4_Interaction_2_P11\n",
      "Processing: F4_Interaction_2_P12\n",
      "Processing: F4_Interaction_2_P13\n",
      "less than 3 rows\n",
      "Processing: F4_Interaction_2_P14\n",
      "Processing: F4_Interaction_2_P9\n",
      "Processing: F5_Interaction_1_P15\n",
      "Processing: F5_Interaction_1_P16\n",
      "Processing: F5_Interaction_2_P15\n",
      "Processing: F5_Interaction_2_P16\n",
      "Processing: F6_Interaction_1_P17\n",
      "Processing: F6_Interaction_1_P18\n",
      "Processing: F6_Interaction_1_P19\n",
      "Processing: F6_Interaction_2_P17\n",
      "Processing: F6_Interaction_2_P18\n",
      "Processing: F6_Interaction_2_P19\n",
      "Processing: F7_Interaction_1_P20\n",
      "Processing: F7_Interaction_1_P21\n",
      "Processing: F7_Interaction_1_P22\n",
      "less than 3 rows\n",
      "Processing: F7_Interaction_1_P23\n",
      "Processing: F8_Interaction_1_P24\n",
      "Processing: F8_Interaction_1_P25\n",
      "Processing: F8_Interaction_2_P24\n",
      "Processing: F8_Interaction_2_P25\n",
      "Processing: F8_Interaction_3_P24\n",
      "Processing: F8_Interaction_3_P25\n"
     ]
    }
   ],
   "source": [
    "window_frames = [64, 64*2, 5*30]\n",
    "window_names = ['2.5','5','5s']\n",
    "\n",
    "low_csv_path = os.path.join(base_path,'raw_features/')\n",
    "only_low_csv_files = [os.path.join(low_csv_path, f) for f in os.listdir(low_csv_path) if \n",
    "                  os.path.isfile(os.path.join(low_csv_path, f)) and f.startswith('F')]\n",
    "only_low_csv_files.sort()\n",
    "\n",
    "for low_csv_file in only_low_csv_files:\n",
    "    save_file = os.path.basename(low_csv_file).replace('_low_level.csv','')\n",
    "    print('Processing:',save_file)\n",
    "    \n",
    "    low_level_df = pd.read_csv(low_csv_file)\n",
    "    low_level_data = np.nan_to_num(low_level_df.values)\n",
    "    \n",
    "    for i in range(len(window_frames)):\n",
    "        window_size = window_frames[i]\n",
    "        window_name = window_names[i]\n",
    "    \n",
    "        high_npy_path = os.path.join('./features','handcrafted_features_' + window_name)\n",
    "        os.makedirs(high_npy_path, exist_ok = True)\n",
    "        \n",
    "        high_npy_file = os.path.join(high_npy_path,'_'.join([save_file,'high_level'])+ '.npy')\n",
    "        if os.path.exists(high_npy_file):\n",
    "            print('Already Processed:{}-{}'.format(window_name,high_npy_file))\n",
    "            continue\n",
    "\n",
    "        #extarct high-level for each person/file \n",
    "        high_data = statstic_features(low_level_data, window_size)\n",
    "\n",
    "        #save high-level features for each person/file \n",
    "        np.save(high_npy_file, high_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e27653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
